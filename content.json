{"meta":{"title":"Never Meet Blog","subtitle":"","description":"","author":"ZSC","url":"https://zsc-cloud.github.io","root":"/"},"pages":[{"title":"所有分类","date":"2021-06-01T09:23:56.444Z","updated":"2021-06-01T09:23:56.444Z","comments":true,"path":"categories/index.html","permalink":"https://zsc-cloud.github.io/categories/index.html","excerpt":"","text":""},{"title":"","date":"2021-06-28T08:46:02.058Z","updated":"2021-06-28T08:46:02.058Z","comments":true,"path":"about/index.html","permalink":"https://zsc-cloud.github.io/about/index.html","excerpt":"","text":"这些年我一直提醒自己一件事，千万不要自己感动自己。大多数看似的努力，不过是愚蠢导致的。什么熬夜看书到天亮，连续几天只睡几小时，如果这些东西也值得夸耀，那么富士康流水线上任何一个人都比你努力多了。人难免天生有自怜的情绪，唯有时刻保持清醒，才能看清真正的价值在哪里"},{"title":"friends","date":"2021-06-01T09:28:56.000Z","updated":"2021-06-01T09:28:56.429Z","comments":true,"path":"friends/index.html","permalink":"https://zsc-cloud.github.io/friends/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2021-06-01T09:24:52.912Z","updated":"2021-06-01T09:24:52.912Z","comments":true,"path":"tags/index.html","permalink":"https://zsc-cloud.github.io/tags/index.html","excerpt":"","text":""},{"title":"","date":"2021-06-01T09:25:39.964Z","updated":"2021-06-01T09:25:39.964Z","comments":true,"path":"mylist/index.html","permalink":"https://zsc-cloud.github.io/mylist/index.html","excerpt":"","text":""}],"posts":[{"title":"Git常用命令","slug":"Git常用命令","date":"2023-07-09T04:43:35.000Z","updated":"2023-07-08T11:59:06.570Z","comments":true,"path":"2023/07/08/Git常用命令/","link":"","permalink":"https://zsc-cloud.github.io/2023/07/08/Git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"","text":"git cherry-pickcherry-pick可以理解为”挑拣”提交，它会获取某一个分支的单笔提交，并作为一个新的提交引入到你当前分支上。 当我们需要在本地合入其他分支的提交时，如果我们不想对整个分支进行合并，而是只想将某一次提交合入到本地当前分支上，那么就要使用git cherry-pick了。 cherry-pick 命令可以在一个分支上选择性地应用另一个分支或提交中的一个或多个提交。这对于合并单独的 bug 修复或其他小型改动非常有用。 使用方法 对于 commit-id 的操作，都只需要使用前五位就可以了。 合并单个提交 1234git cherry-pick &lt;commit-id&gt;##不自动提交，只更新工作区和暂存区，不产生新的提交。(其他options见下文)git cherry-pick -n &lt;commit_id&gt; 合并多个提交 12# commitid之间空格分开git cherry-pick commit_id1 commit_id2 commit_id3 合并连续多个提交 1git cherry_pick &lt;start-commit-ids&gt;..&lt;end-commit-id&gt; 可以看到，它的范围就是 start-commit-id 到 end-commit-id 之间所有的 commit，但是它这是一个 (左开，右闭] 的区间，也就是说，它将不会包含 start-commit-id 的 commit。 而如果想要包含 start-commit-id 的话，就需要使用 ^ 标记一下，就会变成一个 [左闭，右闭] 的区间，具体命令如下。 1git cherry-pick &lt;start-commit-id&gt;^..&lt;end-commit-id&gt; 无论是对单个 commit 进行 cherry-pick ，还是批量处理，注意一定要根据时间线，依照 commit 的先后顺序来处理，否者会有意想不到的问题。 常用options 12345678910git cherry-pick [&lt;options&gt;] &lt;commit-ish&gt;...--quit 退出当前的chery-pick序列--continue 继续当前的chery-pick序列--abort 取消当前的chery-pick序列，恢复当前分支-n, --no-commit 不自动提交-e, --edit 编辑提交信息-x, 在原来的提交信息下，增加一行额外说明信息（cherry picked from commit …），用来说明该次commit是从哪里cherry-pick的。如果是从自己的私人分支之间做这个操作，就不要使用这个，这样的信息是无用的。如果是cherry-pick别的同事的提交，可以使用这个参数，这个额外信息将非常有用。 Idea操作 切换到合并的目标分支 在git log面板显示中，找到要合并到的commit信息 右键点击 Cherry-Pick 查看本地的目标分支的log记录，这个时候可以看到想要合并的某一个commit记录已经存在了 git push 即可 git config该命令将分别设置提交代码的用户名和电子邮件地址 12git config –global user.name “name”git config –global user.email “email” git reset使用方法 git reset 命令用于回退版本，可以指定退回某一次提交的版本 1git reset [--soft | --mixed | --hard] [HEAD] –mixed为默认的，可以不用带该参数恢复成未add的状态 –soft用于回退到某个版本已经add了，未commit –hard 参数撤销工作区中所有未提交的修改内容，直接把回滚的内容在本地仓库中抹去 Idea操作 选择要回滚到哪个commit 右键点击 reset current（注意：被选中的版本号不会被回滚） 选择对应的回滚模式 git push -f 强制提交一下 显示全部历史提交 1git reflog 误删恢复 如果回滚代码之后发现复制错了 commit_id，或者误删了某次 commit 记录，也可以通过下方代码恢复 1git reset --hard commit—id git revert解释 git revert是用于“反做”某一个版本，以达到撤销该版本的修改的目的。比如，我们commit了三个版本（版本一、版本二、 版本三），突然发现版本二不行（如：有bug），想要撤销版本二，但又不想影响撤销版本三的提交，就可以用 git revert 命令来反做版本二，生成新的版本四，这个版本四里会保留版本三的东西，但撤销了版本二的东西。如下图所示： 使用方法 1234# revert一个commitgit revert -n commit-id# revert多个commit (注意这是一个前开后闭区间)git revert -n f7742cd..551c408 适用场景： 如果我们想撤销之前的某一版本，但是又想保留该目标版本后面的版本，记录下这整个版本变动流程，就可以用这种方法。 Idea操作 git reset 和 git revert 的区别 git revert 后多出一条 commit ，提醒同事，这里有回撤操作。 git reset直接版之前 commit 删掉，非 git reset --hard 的操作是不会删掉修改代码，如果远程已经有之前代码，需要强推 git push -f 查看一个文件的历史提交记录点击文件 –&gt; Git –&gt; show History 合并多个commit 先选中最早的那条记录，右击选择Interactivity Rebase from Here… 把除了第一条记录的Action改成squash，点击Start Rebasing pick：保留该commit（缩写:p）reword：保留该commit，但我需要修改该commit的注释（缩写:r）edit：保留该commit, 但我要停下来修改该提交(不仅仅修改注释)（缩写:e）squash：将该commit和前一个commit合并（缩写:s）fixup：将该commit和前一个commit合并，但我不要保留该提交的注释信息（缩写:f）exec：执行shell命令（缩写:x）drop：我要丢弃该commit（缩写:d） 修改提交的日志，点击Continue Rebasing git push -f 强制提交一下 git使用http形式免密执行命令首次输入密码之后执行以下命令 1git config --global credential.helper store Git :fatal: refusing to merge unrelated histories解决本地创建了一个仓库，把本地仓库和Gitee上关联以后发现git pull/git push，git feach提醒fatal: refusing to merge unrelated histories 原因是两个分支是两个不同的版本，具有不同的提交历史 拉取远程代码的时候执行 1$git pull origin master --allow-unrelated-histories 可以允许不相关历史提交，强制合并","categories":[{"name":"Git","slug":"Git","permalink":"https://zsc-cloud.github.io/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://zsc-cloud.github.io/tags/Git/"}]},{"title":"","slug":"todo/计划","date":"2023-07-02T10:33:55.874Z","updated":"2023-07-08T04:42:24.330Z","comments":true,"path":"2023/07/02/todo/计划/","link":"","permalink":"https://zsc-cloud.github.io/2023/07/02/todo/%E8%AE%A1%E5%88%92/","excerpt":"","text":"计划 git常见命令说明 kafka Hbase 大数据分析 流式计算 golang","categories":[],"tags":[]},{"title":"未命名","slug":"未命名","date":"2021-07-01T08:00:50.000Z","updated":"2021-07-02T09:19:30.335Z","comments":true,"path":"2021/07/01/未命名/","link":"","permalink":"https://zsc-cloud.github.io/2021/07/01/%E6%9C%AA%E5%91%BD%E5%90%8D/","excerpt":"","text":"我们总是设想，假如生活能够重来一遍，人生就会打开新的篇章，其实每个现在都是一个新的开始。与其对过去望眼欲穿，还不如从现在开始，对未来充满希望。人不能一直活在过去，而毫无顾忌的抛弃现在和未来。或许你现在正在经历前所未有的艰难，或许在悬崖边上摇摇欲坠，或许在低谷里咬牙坚持，或许在海浪中逆风漂流，因此才会渴望乘上一台时光机，打开一扇任意门。但是 重来一次，你还是会后悔。人生就是取经的过程，苦难无处不在，像野花一样长在你的必经路旁。","categories":[{"name":"鸡汤语录","slug":"鸡汤语录","permalink":"https://zsc-cloud.github.io/categories/%E9%B8%A1%E6%B1%A4%E8%AF%AD%E5%BD%95/"}],"tags":[]},{"title":"MyCat(一)---简介","slug":"MyCat(一)---简介","date":"2021-06-28T20:41:11.000Z","updated":"2022-03-26T03:42:17.218Z","comments":true,"path":"2021/06/28/MyCat(一)---简介/","link":"","permalink":"https://zsc-cloud.github.io/2021/06/28/MyCat(%E4%B8%80)---%E7%AE%80%E4%BB%8B/","excerpt":"","text":"1. MyCat引入如今随着互联网的发展，数据的量级也是成指数式的增长，从GB到TB到PB。对数据的各种操作也是愈加的困难，传统的关系型数据库已经无法满足快速查询与插入数据的需求，这个时候NoSQL的出现暂时解决了这一危机，它通过降低数据的安全性，减少对事务的支持，减少对复杂查询的支持，来获取性能上的提升，但是，在有一些场合NOSQL是无法满足使用场景的，就比如有些场景是绝对要有事务和安全指标的，这个时候NoSQL肯定是无法满足的，所以还是需要使用关系型数据库，如何使用关系型数据库存储海量的数据，此时就需要做数据库集群，为了提高查询性能讲一个数据库分散到不同的数据库中存储，为应对此问题就出现了MyCat MyCat的目标就是：低成本的将现有的单机数据库和应用平滑的迁移到云端，解决海量数据存储和业务规模迅速增长情况下数据存储和访问的瓶颈问题。 2. MyCat历史1). Mycat 背后是阿里曾经开源的知名产品——Cobar。Cobar 的核心功能和优势是 MySQL 数据库分片，此产品曾经广为流传，据说最早的发起者对 Mysql 很精通，后来从阿里跳槽了，阿里随后开源的 Cobar，并维持到 2013 年年初，然后，就没有然后了。 Cobar 的思路和实现路径的确不错。基于 Java 开发的，实现了 MySQL 公开的二进制传输协议，巧妙地将自己伪装成一个 MySQL Server，目前市面上绝大多数 MySQL 客户端工具和应用都能兼容。比自己实现一个新的数据库协议要明智的多，因为生态环境在哪里摆着。 2). Mycat 是基于 cobar 演变而来，相对于cobar来说 , 有两个显著优势 : ①. 对 cobar 的代码进行了彻底的重构，Mycat在I/O方面进行了重大改进,将原来的BIO改成了NIO, 并发量有大幅提高 ; ②. 增加了对Order By、Group By、limit等聚合功能的支持，同时兼容绝大多数数据库成为通用的数据库中间件 。 3). 简单的说，MyCAT就是：一个新颖的数据库中间件产品支持mysql集群，或者 mariadb cluster，提供高可用性数据分片集群。你可以像使用mysql一样使用 mycat 。对于开发人员来说根本感觉不到mycat的存在。、 3. MyCat的优势MyCat 是一个彻底开源的，面向企业应用数据库中间件 , 支持事务， 可以视为MySQL集群的企业级数据库，用来替代昂贵的Oracle集群, 在MyCat 中融合内存缓存技术、NoSQL技术、HDFS大数据的新型SQL Server , 并结合传统数据库和新型分布式数据仓库的新一代企业级数据库中间件产品 。 并具有优势: 1). 性能可靠稳定 基于阿里开源的Cobar产品而研发，Cobar的稳定性、可靠性、优秀的架构和性能以及众多成熟的使用案例使得MYCAT一开始就拥有一个很好的起点，站在巨人的肩膀上，我们能看到更远。业界优秀的开源项目和创新思路被广泛融入到MYCAT的基因中，使得MYCAT在很多方面都领先于目前其他一些同类的开源项目，甚至超越某些商业产品。 2). 强大的技术团队 MyCat 现在由一支强大的技术团队维护 , 吸引和聚集了一大批业内大数据和云计算方面的资深工程师、架构师、DBA，优秀的团队保障了MyCat的稳定高效运行。而且MyCat不依托于任何商业公司，而且得到大批开源爱好者的支持。 3). 体系完善 MyCat已经形成了一系列的周边产品,比较有名的是 Mycat-web、Mycat-NIO、Mycat-Balance等,已经形成了一个比较完整的解决方案,而不仅仅是一个中间件。 4). 社区活跃 与MyCat数据库中间件类似的产品还有 TDDL、Amoeba、Cobar 。 ①. TDDL（Taobao Distributed Data Layer）不同于其它几款产品，并非独立的中间件，只能算作中间层，是以Jar包方式提供给应用调用 ，属于JDBC Shard的思想 。 ②. Amoeba是作为一个真正的独立中间件提供服务,应用去连接Amoeba操作MySQL集群，就像操作单个MySQL一样。Amoeba算中间件中的早期产品,后端还在使用JDBC Driver。 ③. Cobar是在Amoeba基础上进化的版本，一个显著变化是把后端JDBC Driver改为原生的MySQL通信协议层。 ④. MyCat又是在Cobar基础上发展的版本, 性能优良, 功能强大, 社区活跃 。 4. MyCat 使用场合要想用好MyCat，就需要了解其适用场景，以下几个场景适合适用MyCat。 1). 高可用性与MySQL读写分离 高可用：利用MyCat可以轻松实现热备份，当一台服务器停机时，可以由集群中的另一台服务器自动接管业务，无需人工干预，从而保证高可用。 读写分离：通过MySQL数据库的binlog日志完成主从复制，并可以通过MyCat轻松实现读写分离，实现insert、update、delete走主库，而在select时走从库，从而缓解单台服务器的访问压力。 2). 业务数据分级存储保障 企业的数据量总是无休止的增长，这些数据的格式不一样，访问效率不一样，重要性也不一样。可以针对不同级别的数据，采用不同的存储设备，通过分级存储管理软件实现数据客体在存储设备之间自动迁移及自动访问切换。 3). 大表水平拆分，集群并行计算 数据切分是MyCat的核心功能，是指通过某种特定的条件，将存放在同一个数据库的数据，分散存储在多个数据库中，以达到分散单台设备负载的效果。当数据库量超过800万行且需要做分片时，就可以考虑使用MyCat实现数据切分。 4). 数据库路由器 MyCat基于MySQL实例的连接池复用机制，可以让每个应用最大程度共享一个MySQL实例的所有连接池，让数据库的并发访问能力大大提升。 5). 整合多种数据源 当一个项目中使用了多个数据库（Oracle，MySQL，SQL Server,PostgreSQL），并配置了多个数据源，操作起来就比较烦锁，这时就可以使用MyCat进行整合，最终我们的应用程序只需要访问一个数据源即可。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://zsc-cloud.github.io/categories/MySQL/"},{"name":"MyCat","slug":"MySQL/MyCat","permalink":"https://zsc-cloud.github.io/categories/MySQL/MyCat/"}],"tags":[{"name":"MyCat","slug":"MyCat","permalink":"https://zsc-cloud.github.io/tags/MyCat/"},{"name":"分库分表","slug":"分库分表","permalink":"https://zsc-cloud.github.io/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"}]},{"title":"MyCat(二)---入门","slug":"MyCat(二)---入门","date":"2021-06-27T20:41:11.000Z","updated":"2022-03-26T03:42:17.272Z","comments":true,"path":"2021/06/27/MyCat(二)---入门/","link":"","permalink":"https://zsc-cloud.github.io/2021/06/27/MyCat(%E4%BA%8C)---%E5%85%A5%E9%97%A8/","excerpt":"","text":"1. 环境搭建MyCat是采用Java语言开发的开源数据库中间件，支持win和linux运行环境，下面介绍MyCat的linux的环境搭建 MySQL JDK MyCat 1.1 安装配置MySQL1234567891011121314151617181920212223242526272829303132333435363738A). 卸载 centos 中预安装的 mysql rpm -qa | grep -i mysql rpm -e mysql-libs-5.1.71-1.el6.x86_64 --nodeps B). 上传 mysql 的安装包 alt + p -------&gt; put E:/test/MySQL-5.6.22-1.el6.i686.rpm-bundle.tarC). 解压 mysql 的安装包 mkdir mysql tar -xvf MySQL-5.6.22-1.el6.i686.rpm-bundle.tar -C /root/mysql D). 安装依赖包 yum -y install libaio.so.1 libgcc_s.so.1 libstdc++.so.6 libncurses.so.5 --setopt=protected_multilib=false yum update libstdc++-4.4.7-4.el6.x86_64 E). 安装 mysql-client rpm -ivh MySQL-client-5.6.22-1.el6.i686.rpm F). 安装 mysql-server rpm -ivh MySQL-server-5.6.22-1.el6.i686.rpm -----------------------------------------service mysql startservice mysql stopservice mysql statusservice mysql restart 1.2 配置JDK环境123配置PATH环境变量 , 在该配置文件(/etc/profile)的最后加入如下配置 export JAVA_HOME=/usr/share/jdk1.8.0_181 export PATH=$PATH:$JAVA_HOME/bin 1.3 MyCat 2. MyCat核心概念2.1 分片简单来说，就是指通过某种特定的条件，将我们存放在同一个数据库中的数据分散存放到多个数据库或者主机上面，已达到分散单台设备负载的效果。数据的切分，根据其切分规则的类型，可以分为两种切分模式。 一种是按照不同的表（或者Schema）来切分到不同的数据库智商，这种切分已经称之为数据的垂直切分 另外一种则是根据表中的数据的逻辑关系，将同一个表中的数据按照某种条件拆分到多台数据库上面，这种切分称之为水平切分 MyCat分片策略 虚线以辑结构图，虚线之下是物理结构图 2.2 逻辑库SchemaMyCat是一个数据库中间件，通常对实际应用来说，并不需要指定中间件的存在，业务开发人员只需要知道数据库的概念，所以数据库中间件可以被看做一个或者多个数据库集群构成的逻辑表 2.3 逻辑表既然有了逻辑库，那么就会有逻辑表，分布式数据库中，对应用来说，读写数据的表的逻辑表。逻辑表可以是数据切分后，分布在一个或者多个分片库中，也可以不做数据切分，不分片，只有一个表构成。 分片表 是指那些原有很大数据的表，需要切分到多个数据库中的表，这样，每个分片都有一部分数据，所有分片构成了完整的数据。总而言之就是需要进行分片的表，如：tb_order表是一个分片表，数据按照规则被切分到dn1，dn2两个节点。 非分片表 一个数据库中国并不是所有的表都很大，某些表是不用进行切分的，非分片是相对分片表来说的，就是那些不需要进行数据切分的表，如一个数据库中的字典表，city表等 ER表 关系型数据库是基于实体关系模型（Entity Relationship Model）的，MyCat中的ER表便来源如此，MyCat提出基于ER关系的数据分片策略，字表的记录与其关联父表的记录存放在一个数据分片中，通过表分组保证数据关联查询不会跨库操作。 全局表 在一个大型的项目中，会存在一部分字典表（码表），在其中存储的是项目中的一些基础的数据，而这些基础的数据，数据量都不大，在各个业务表中可能都存在关联。当业务表由于数据量大而分片之后，业务表与附属的数据字典表之间的关联查询就变成了比较棘手的问题，在MyCat中可以通过数据冗余来解决这类表的关联查询，即所有分片都复制这一份数据，因此可以把这些冗余数据的表定义为全局表。 2.4 分片节点（dataNode）数据切分之后，一个大表分到不同的数据库上面，每个表分片所在的数据库就是分片节点 2.5 节点主机（dataHost）数据切分之后，每个分片节点（dataNode）不一定都会独占一台机器，同一机器上面可以有多个分片数据库，这样一个或者多个分片节点所在的机器就是节点主机，为了规避单节点主机的并发数限制，尽量将读写压力高的分片节点均衡的放在不同的节点主机 2.6 分片规则（rule）前面讲了数据切分，一个大表被分成若干个分片表，就需要一定的规则。这样按照某种业务规则把数据分到某个分片的规则就是分片规则，数据切分选择合适的分片规则是非常重要的。将极大的避免后续数据处理的难度。 3. 分片配置测试3.1 需求由于TB_TEST表中的数据很大，现在需要对TB_TEST表进行数据分片，分为三个节点，每一个节点主机位于不同的服务器上，具体的结构，参考下图： 3.2 环境准备准备三台虚拟机，并且按照好MySQL，并配置好： 1234IP 地址列表 : 192.168.192.157 192.168.192.158 192.168.192.159 3.3 配置schema.xmlschema.xml作为MyCat中重要的配置文件之一，管理着MyCat的逻辑表，逻辑库以及对应的分片规则，DataNode,弄懂这些配置，是正确使用MyCat的前提，这里就是一层层对该文件进行解析 属性 含义 schema 标签用于定义MyCat实例中的逻辑库 table 标签定义了MyCat中的逻辑表, rule用于指定分片规则，auto-sharding-long的分片规则是按ID值的范围进行分片 1-5000000 为第1片 5000001-10000000 为第2片…. 具体设置我们会在第四节中讲解。 dataNode 标签定义了MyCat中的数据节点，也就是我们通常说所的数据分片。 dataHost 标签在mycat逻辑库中也是作为最底层的标签存在，直接定义了具体的数据库实例、读写分离配置和心跳语句。 在服务器中创建三个数据库，命名为db1 修改schema.xml如下： 12345678910111213141516171819202122232425262728293031323334&lt;?xml version=&quot;1.0&quot;?&gt;&lt;!DOCTYPE mycat:schema SYSTEM &quot;schema.dtd&quot;&gt;&lt;mycat:schema xmlns:mycat=&quot;http://io.mycat/&quot;&gt; &lt;!-- 逻辑库配置 --&gt; &lt;schema name=&quot;ITCAST&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot;&gt; &lt;!-- 逻辑表配置 --&gt; &lt;table name=&quot;TB_TEST&quot; dataNode=&quot;dn1,dn2,dn3&quot; rule=&quot;auto-sharding-long&quot; /&gt; &lt;/schema&gt; &lt;!-- 数据节点配置 --&gt; &lt;dataNode name=&quot;dn1&quot; dataHost=&quot;host1&quot; database=&quot;db1&quot; /&gt; &lt;dataNode name=&quot;dn2&quot; dataHost=&quot;host2&quot; database=&quot;db1&quot; /&gt; &lt;dataNode name=&quot;dn3&quot; dataHost=&quot;host3&quot; database=&quot;db1&quot; /&gt; &lt;!-- 节点主机配置 --&gt; &lt;dataHost name=&quot;host1&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=&quot;hostM1&quot; url=&quot;192.168.192.157:3306&quot; user=&quot;root&quot; password=&quot;itcast&quot;&gt;&lt;/writeHost&gt; &lt;/dataHost&gt; &lt;dataHost name=&quot;host2&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=&quot;hostM1&quot; url=&quot;192.168.192.158:3306&quot; user=&quot;root&quot; password=&quot;itcast&quot;&gt;&lt;/writeHost&gt; &lt;/dataHost&gt; &lt;dataHost name=&quot;host3&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=&quot;hostM1&quot; url=&quot;192.168.192.159:3306&quot; user=&quot;root&quot; password=&quot;itcast&quot;&gt;&lt;/writeHost&gt; &lt;/dataHost&gt; &lt;/mycat:schema&gt; 3.4 配置server.xmlserver.xml几乎保存了所有MyCat需要的系统配置信息，最常用的是在此配置用户名，密码以及权限，在system中添加utf8字符集设置，否则存储中文会出现乱码问题 1&lt;property name=&quot;charset&quot;&gt;utf8&lt;/property&gt; 修改user的配置，我们这里为ITCAST设置了两个用户 123456789&lt;user name=&quot;root&quot;&gt; &lt;property name=&quot;password&quot;&gt;123456&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;ITCAST&lt;/property&gt;&lt;/user&gt;&lt;user name=&quot;test&quot;&gt; &lt;property name=&quot;password&quot;&gt;123456&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;ITCAST&lt;/property&gt;&lt;/user&gt; 并且需要将原来的逻辑库的配置，替换为ITCAST逻辑库 3.5 启动MyCat123bin/mycat startbin/mycat stopbin/mycat status 查看MyCat: 连接端口号 8066 1). 通过命令行 1mysql -h 127.0.0.1 -P 8066 -u root -p 3.6 MyCat分片测试进入MyCat，执行下列语句创建一个表 12345CREATE TABLE TB_TEST ( id BIGINT(20) NOT NULL, title VARCHAR(100) NOT NULL , PRIMARY KEY (id)) ENGINE=INNODB DEFAULT CHARSET=utf8 ; 我们再查看MySQL的3个库，发现表都自动创建好啦。好神奇。 接下来是插入表数据，注意，在写 INSERT 语句时一定要写把字段列表写出来，否则会出现下列错误提示： 错误代码： 1064 partition table, insert must provide ColumnList 我们试着插入一些数据： 123INSERT INTO TB_TEST(ID,TITLE) VALUES(1,&#x27;goods1&#x27;);INSERT INTO TB_TEST(ID,TITLE) VALUES(2,&#x27;goods2&#x27;);INSERT INTO TB_TEST(ID,TITLE) VALUES(3,&#x27;goods3&#x27;); 我们会发现这些数据被写入到第一个节点中了，那什么时候数据会写到第二个节点中呢？ 我们插入下面的数据就可以插入第二个节点了 1INSERT INTO TB_TEST(ID,TITLE) VALUES(5000001,&#x27;goods5000001&#x27;); 因为我们采用的分片规则是每节点存储500万条数据，所以当ID大于5000000则会存储到第二个节点上。 目前只设置了两个节点，如果数据大于1000万条，会怎么样呢？执行下列语句测试一下 1INSERT INTO TB_TEST(ID,TITLE) VALUES(10000001,&#x27;goods10000001&#x27;); 4. 原理介绍MyCat原理中最重要的一个动词就是“拦截”，它拦截了用户发送过来的SQL语句，首先对SQL语句做了一些特定的分析，如分片分析，路由分析，读写分离分析，缓存分析等，然后将此SQL语句发往后端真实的数据库中，并将返回的结果做适当的处理，最终在返回给用户。如图所示。 在图中，user表被分为三个分片节点dn1,dn2,dn3。他们分布在三个MySQLServer上，因此可以使用1-n台服务器来分片，分片规则为典型的字符串枚举分片，一个规则的定义是分片字段+分片函数，这是的分片字段为status，分片函数则为字符串枚举方式 MyCat收到一条SQL语句时，首先解析SQL语句涉及到的表，接着查看此表的定义，如果该表存在分片规则，则获取SQL语句里的分片字段的值，并匹配分片函数，得到该SQL语句对应的分片列表，然后将SQL语句发送到相对应的分片去执行，最好处理所有分片返回的数据并返回给客户端，以 ‘select * from user where status = ‘0’;为例，查询status=0，按照分片函数，0值存放在dn1,于是SQL语句被发送到了第一个节点中执行，然后再将查询返回的结果返回的用户 如果发送的SQL条件为 where status in (0,1),那么SQL语句会被发送到dn1,dn2对应的主机上执行，然后将结果集合并后输出给用户","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://zsc-cloud.github.io/categories/MySQL/"},{"name":"MyCat","slug":"MySQL/MyCat","permalink":"https://zsc-cloud.github.io/categories/MySQL/MyCat/"}],"tags":[{"name":"MyCat","slug":"MyCat","permalink":"https://zsc-cloud.github.io/tags/MyCat/"},{"name":"分库分表","slug":"分库分表","permalink":"https://zsc-cloud.github.io/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"}]},{"title":"MyCat(三)---配置文件","slug":"MyCat(三)---配置文件","date":"2021-06-26T20:41:11.000Z","updated":"2022-03-26T03:42:17.302Z","comments":true,"path":"2021/06/26/MyCat(三)---配置文件/","link":"","permalink":"https://zsc-cloud.github.io/2021/06/26/MyCat(%E4%B8%89)---%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/","excerpt":"","text":"1. serer.xml1.1 system标签 属性 取值 含义 charset utf8 设置Mycat的字符集, 字符集需要与MySQL的字符集保持一致 nonePasswordLogin 0,1 0为需要密码登陆、1为不需要密码登陆 ,默认为0，设置为1则需要指定默认账户 useHandshakeV10 0,1 使用该选项主要的目的是为了能够兼容高版本的jdbc驱动, 是否采用HandshakeV10Packet来与client进行通信, 1:是, 0:否 useSqlStat 0,1 开启SQL实时统计, 1 为开启 , 0 为关闭 ;开启之后, MyCat会自动统计SQL语句的执行情况 ;mysql -h 127.0.0.1 -P 9066 -u root -p查看MyCat执行的SQL, 执行效率比较低的SQL , SQL的整体执行情况、读写比例等 ;show @@sql ; show @@sql.slow ; show @@sql.sum ; useGlobleTableCheck 0,1 是否开启全局表的一致性检测。1为开启 ，0为关闭 。 sqlExecuteTimeout 1000 SQL语句执行的超时时间 , 单位为 s ; sequnceHandlerType 0,1,2 用来指定Mycat全局序列类型，0 为本地文件，1 为数据库方式，2 为时间戳列方式，默认使用本地文件方式，文件方式主要用于测试 sequnceHandlerPattern 正则表达式 必须带有MYCATSEQ_或者 mycatseq_进入序列匹配流程 注意MYCATSEQ_有空格的情况 subqueryRelationshipCheck true,false 子查询中存在关联查询的情况下,检查关联字段中是否有分片字段 .默认 false useCompression 0,1 开启mysql压缩协议 , 0 : 关闭, 1 : 开启 fakeMySQLVersion 5.5,5.6 设置模拟的MySQL版本号 defaultSqlParser 由于MyCat的最初版本使用了FoundationDB的SQL解析器, 在MyCat1.3后增加了Druid解析器, 所以要设置defaultSqlParser属性来指定默认的解析器; 解析器有两个 : druidparser 和 fdbparser, 在MyCat1.4之后,默认是druidparser, fdbparser已经废除了 processors 1,2…. 指定系统可用的线程数量, 默认值为CPU核心 x 每个核心运行线程数量; processors 会影响processorBufferPool, processorBufferLocalPercent, processorExecutor属性, 所有, 在性能调优时, 可以适当地修改processors值 processorBufferChunk 指定每次分配Socket Direct Buffer默认值为4096字节, 也会影响BufferPool长度, 如果一次性获取字节过多而导致buffer不够用, 则会出现警告, 可以调大该值 processorExecutor 指定NIOProcessor上共享 businessExecutor固定线程池的大小; MyCat把异步任务交给 businessExecutor线程池中, 在新版本的MyCat中这个连接池使用频次不高, 可以适当地把该值调小 packetHeaderSize 指定MySQL协议中的报文头长度, 默认4个字节 maxPacketSize 指定MySQL协议可以携带的数据最大大小, 默认值为16M idleTimeout 30 指定连接的空闲时间的超时长度;如果超时,将关闭资源并回收, 默认30分钟 txIsolation 1,2,3,4 初始化前端连接的事务隔离级别,默认为 REPEATED_READ , 对应数字为3READ_UNCOMMITED=1;READ_COMMITTED=2;REPEATED_READ=3;SERIALIZABLE=4; sqlExecuteTimeout 300 执行SQL的超时时间, 如果SQL语句执行超时,将关闭连接; 默认300秒; serverPort 8066 定义MyCat的使用端口, 默认8066 managerPort 9066 定义MyCat的管理端口, 默认9066 1.2 user标签1234567891011121314151617&lt;user name=&quot;root&quot; defaultAccount=&quot;true&quot;&gt; &lt;property name=&quot;password&quot;&gt;123456&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;ITCAST&lt;/property&gt; &lt;property name=&quot;readOnly&quot;&gt;true&lt;/property&gt; &lt;property name=&quot;benchmark&quot;&gt;1000&lt;/property&gt; &lt;property name=&quot;usingDecrypt&quot;&gt;0&lt;/property&gt; &lt;!-- 表级 DML 权限设置 --&gt; &lt;!-- &lt;privileges check=&quot;false&quot;&gt; &lt;schema name=&quot;TESTDB&quot; dml=&quot;0110&quot; &gt; &lt;table name=&quot;tb01&quot; dml=&quot;0000&quot;&gt;&lt;/table&gt; &lt;table name=&quot;tb02&quot; dml=&quot;1111&quot;&gt;&lt;/table&gt; &lt;/schema&gt; &lt;/privileges&gt; --&gt;&lt;/user&gt; user标签主要用于定义登录MyCat的用户和权限 : 1). &lt;user name=”root” defaultAccount=”true”&gt; : name 属性用于声明用户名 ; 2). &lt;property name=”password”&gt;123456&lt;/property&gt; : 指定该用户名访问MyCat的密码 ; 3). &lt;property name=”schemas”&gt;ITCAST&lt;/property&gt; : 能够访问的逻辑库, 多个的话, 使用 “,” 分割 4). &lt;property name=”readOnly”&gt;true&lt;/property&gt; : 是否只读 5). &lt;property name=”benchmark”&gt;11111&lt;/property&gt; : 指定前端的整体连接数量 , 0 或不设置表示不限制 6). &lt;property name=”usingDecrypt”&gt;0&lt;/property&gt; : 是否对密码加密默认 0 否 , 1 是 java -cp Mycat-server-1.6.7.3-release.jar io.mycat.util.DecryptUtil 0:root:123456 7). &lt;privileges check=”false”&gt; A. 对用户的 schema 及 下级的 table 进行精细化的 DML 权限控制; B. privileges 节点中的 check 属性是用 于标识是否开启 DML 权限检查， 默认 false 标识不检查，当然 privileges 节点不配置，等同 check=false, 由于 Mycat 一个用户的 schemas 属性可配置多个 schema ，所以 privileges 的下级节点 schema 节点同样 可配置多个，对多库多表进行细粒度的 DML 权限控制; C. 权限修饰符四位数字(0000 - 1111)，对应的操作是 IUSD ( 增，改，查，删 )。同时配置了库跟表的权限，就近原则。以表权限为准。 1.3 firewall标签firewall标签用来定义防火墙；firewall下whitehost标签用来定义 IP白名单 ，blacklist用来定义 SQL黑名单。 12345678910&lt;firewall&gt; &lt;!-- 白名单配置 --&gt; &lt;whitehost&gt; &lt;host user=&quot;root&quot; host=&quot;127.0.0.1&quot;&gt;&lt;/host&gt; &lt;/whitehost&gt; &lt;!-- 黑名单配置 --&gt; &lt;blacklist check=&quot;true&quot;&gt; &lt;property name=&quot;selelctAllow&quot;&gt;false&lt;/property&gt; &lt;/blacklist&gt;&lt;/firewall&gt; 黑名单拦截明细配置: 配置项 缺省值 描述 selelctAllow true 是否允许执行 SELECT 语句 selectAllColumnAllow true 是否允许执行 SELECT * FROM T 这样的语句。如果设置为 false，不允许执行 select * from t，但可以select * from (select id, name from t) a。这个选项是防御程序通过调用 select * 获得数据表的结构信息。 selectIntoAllow true SELECT 查询中是否允许 INTO 字句 deleteAllow true 是否允许执行 DELETE 语句 updateAllow true 是否允许执行 UPDATE 语句 insertAllow true 是否允许执行 INSERT 语句 replaceAllow true 是否允许执行 REPLACE 语句 mergeAllow true 是否允许执行 MERGE 语句，这个只在 Oracle 中有用 callAllow true 是否允许通过 jdbc 的 call 语法调用存储过程 setAllow true 是否允许使用 SET 语法 truncateAllow true truncate 语句是危险，缺省打开，若需要自行关闭 createTableAllow true 是否允许创建表 alterTableAllow true 是否允许执行 Alter Table 语句 dropTableAllow true 是否允许修改表 commentAllow false 是否允许语句中存在注释，Oracle 的用户不用担心，Wall 能够识别 hints和注释的区别 noneBaseStatementAllow false 是否允许非以上基本语句的其他语句，缺省关闭，通过这个选项就能够屏蔽 DDL。 multiStatementAllow false 是否允许一次执行多条语句，缺省关闭 useAllow true 是否允许执行 mysql 的 use 语句，缺省打开 describeAllow true 是否允许执行 mysql 的 describe 语句，缺省打开 showAllow true 是否允许执行 mysql 的 show 语句，缺省打开 commitAllow true 是否允许执行 commit 操作 rollbackAllow true 是否允许执行 roll back 操作 拦截配置－永真条件 selectWhereAlwayTrueCheck true 检查 SELECT 语句的 WHERE 子句是否是一个永真条件 selectHavingAlwayTrueCheck true 检查 SELECT 语句的 HAVING 子句是否是一个永真条件 deleteWhereAlwayTrueCheck true 检查 DELETE 语句的 WHERE 子句是否是一个永真条件 deleteWhereNoneCheck false 检查 DELETE 语句是否无 where 条件，这是有风险的，但不是 SQL 注入类型的风险 updateWhereAlayTrueCheck true 检查 UPDATE 语句的 WHERE 子句是否是一个永真条件 updateWhereNoneCheck false 检查 UPDATE 语句是否无 where 条件，这是有风险的，但不是SQL 注入类型的风险 conditionAndAlwayTrueAllow false 检查查询条件(WHERE/HAVING 子句)中是否包含 AND 永真条件 conditionAndAlwayFalseAllow false 检查查询条件(WHERE/HAVING 子句)中是否包含 AND 永假条件 conditionLikeTrueAllow true 检查查询条件(WHERE/HAVING 子句)中是否包含 LIKE 永真条件 其他拦截配置 selectIntoOutfileAllow false SELECT … INTO OUTFILE 是否允许，这个是 mysql 注入攻击的常见手段，缺省是禁止的 selectUnionCheck true 检测 SELECT UNION selectMinusCheck true 检测 SELECT MINUS selectExceptCheck true 检测 SELECT EXCEPT selectIntersectCheck true 检测 SELECT INTERSECT mustParameterized false 是否必须参数化，如果为 True，则不允许类似 WHERE ID = 1 这种不参数化的 SQL strictSyntaxCheck true 是否进行严格的语法检测，Druid SQL Parser 在某些场景不能覆盖所有的SQL 语法，出现解析 SQL 出错，可以临时把这个选项设置为 false，同时把 SQL 反馈给 Druid 的开发者。 conditionOpXorAllow false 查询条件中是否允许有 XOR 条件。XOR 不常用，很难判断永真或者永假，缺省不允许。 conditionOpBitwseAllow true 查询条件中是否允许有”&amp;”、”~”、”|”、”^”运算符。 conditionDoubleConstAllow false 查询条件中是否允许连续两个常量运算表达式 minusAllow true 是否允许 SELECT * FROM A MINUS SELECT * FROM B 这样的语句 intersectAllow true 是否允许 SELECT * FROM A INTERSECT SELECT * FROM B 这样的语句 constArithmeticAllow true 拦截常量运算的条件，比如说 WHERE FID = 3 - 1，其中”3 - 1”是常量运算表达式。 limitZeroAllow false 是否允许 limit 0 这样的语句 禁用对象检测配置 tableCheck true 检测是否使用了禁用的表 schemaCheck true 检测是否使用了禁用的 Schema functionCheck true 检测是否使用了禁用的函数 objectCheck true 检测是否使用了“禁用对对象” variantCheck true 检测是否使用了“禁用的变量” readOnlyTables 空 指定的表只读，不能够在 SELECT INTO、DELETE、UPDATE、INSERT、MERGE 中作为”被修改表”出现 2. schema.xmlschema.xml 作为MyCat中最重要的配置文件之一 , 涵盖了MyCat的逻辑库 、 表 、 分片规则、分片节点及数据源的配置。 2.1 schema标签123&lt;schema name=&quot;ITCAST&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot;&gt; &lt;table name=&quot;TB_TEST&quot; dataNode=&quot;dn1,dn2,dn3&quot; rule=&quot;auto-sharding-long&quot; /&gt;&lt;/schema&gt; schema 标签用于定义 MyCat实例中的逻辑库 , 一个MyCat实例中, 可以有多个逻辑库 , 可以通过 schema 标签来划分不同的逻辑库。MyCat中的逻辑库的概念 ， 等同于MySQL中的database概念 , 需要操作某个逻辑库下的表时, 也需要切换逻辑库: 1use ITCAST; 属性 name 指定逻辑库的库名，可以自己自定义人核字符串； checkSQLschema 取值为true/false 如果设置为true时 , 如果我们执行的语句为 “select * from ITCAST.TB_TEST;” , 则MyCat会自动把schema字符去掉, 把SQL语句修改为 “select * from TB_TEST;” 可以避免SQL发送到后端数据库执行时, 报table不存在的异常 。 不过当我们在编写SQL语句时, 指定了一个不存在schema, MyCat是不会帮我们自动去除的 ,这个时候数据库就会报错, 所以在编写SQL语句时,最好不要加逻辑库的库名, 直接查询表即可。 SQLMaxLimit 当该属性设置为某个数值时,每次执行的SQL语句如果没有加上limit语句, MyCat也会自动在limit语句后面加上对应的数值 。也就是说， 如果设置了该值为100，则执行 select * from TB_TEST 与 select * from TB_TEST limit 100 是相同的效果 。 所以在正常的使用中, 建立设置该值 , 这样就可以避免每次有过多的数据返回。 子标签tabletable便签定义了MyCat中逻辑库schema下的逻辑表，所有需要拆分的表都需要在table标签中定义 1&lt;table name=&quot;TB_TEST&quot; dataNode=&quot;dn1,dn2,dn3&quot; rule=&quot;auto-sharding-long&quot; /&gt; 属性 1). name 定义逻辑表的表名 , 在该逻辑库下必须唯一。 2). dataNode 定义的逻辑表所属的dataNode , 该属性需要与dataNode标签中的name属性的值对应。 如果一张表拆分的数据，存储在多个数据节点上，多个节点的名称使用”,”分隔 。 3). rule 该属性用于指定逻辑表的分片规则的名字, 规则的名字是在rule.xml文件中定义的, 必须与tableRule标签中name属性对应。 4). ruleRequired 该属性用于指定表是否绑定分片规则, 如果配置为true, 但是没有具体的rule, 程序会报错。 5). primaryKey 逻辑表对应真实表的主键 如: 分片规则是使用主键进行分片, 使用主键进行查询时, 就会发送查询语句到配置的所有的datanode上; 如果使用该属性配置真实表的主键, 那么MyCat会缓存主键与具体datanode的信息, 再次使用主键查询就不会进行广播式查询了, 而是直接将SQL发送给具体的datanode。 6). type 该属性定义了逻辑表的类型，目前逻辑表只有全局表和普通表。 全局表：type的值是 global , 代表 全局表 。 普通表：无 7). autoIncrement mysql对非自增长主键，使用last_insert_id() 是不会返回结果的，只会返回0。所以，只有定义了自增长主键的表，才可以用last_insert_id()返回主键值。mycat提供了自增长主键功能，但是对应的mysql节点上数据表，没有auto_increment,那么在mycat层调用last_insert_id()也是不会返回结果的。 如果使用这个功能， 则最好配合数据库模式的全局序列。使用 autoIncrement=”true” 指定该表使用自增长主键,这样MyCat才不会抛出 “分片键找不到” 的异常。 autoIncrement的默认值为 false。 8). needAddLimit 指定表是否需要自动在每个语句的后面加上limit限制, 默认为true。 2.2 dataNode标签1&lt;dataNode name=&quot;dn1&quot; dataHost=&quot;host1&quot; database=&quot;db1&quot; /&gt; dataNode标签中定义了MyCat中的数据节点, 也就是我们通常说的数据分片。一个dataNode标签就是一个独立的数据分片。 具体的属性 ： 属性 含义 描述 name 数据节点的名称 需要唯一 ; 在table标签中会引用这个名字, 标识表与分片的对应关系 dataHost 数据库实例主机名称 引用自 dataHost 标签中name属性 database 定义分片所属的数据库 2.3 dataHost标签12345&lt;dataHost name=&quot;host1&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=&quot;hostM1&quot; url=&quot;192.168.192.147:3306&quot; user=&quot;root&quot; password=&quot;itcast&quot;&gt;&lt;/writeHost&gt;&lt;/dataHost&gt; 该标签在MyCat逻辑库中作为底层标签存在, 直接定义了具体的数据库实例、读写分离、心跳语句。 2.3.1 属性 属性 含义 描述 name 数据节点名称 唯一标识， 供上层标签使用 maxCon 最大连接数 内部的writeHost、readHost都会使用这个属性 minCon 最小连接数 内部的writeHost、readHost初始化连接池的大小 balance 负载均衡类型 取值0,1,2,3 ; 后面章节会详细介绍; writeType 写操作分发方式 0 : 写操作都转发到第1台writeHost, writeHost1挂了, 会切换到writeHost2上; 1 : 所有的写操作都随机地发送到配置的writeHost上 ; dbType 后端数据库类型 mysql, mongodb , oracle dbDriver 数据库驱动 指定连接后端数据库的驱动,目前可选值有 native和JDBC。native执行的是二进制的MySQL协议，可以使用MySQL和MariaDB。其他类型数据库需要使用JDBC（需要在MyCat/lib目录下加入驱动jar） switchType 数据库切换策略 取值 -1,1,2,3 ; 后面章节会详细介绍; 2.3.2 子标签heartbeat配置MyCat与后端数据库的心跳，用于检测后端数据库的状态。heartbeat用于配置心跳检查语句。例如 ： MySQL中可以使用 select user(), Oracle中可以使用 select 1 from dual等。 2.3.3 子标签writeHost、readHost指定后端数据库的相关配置， 用于实例化后端连接池。 writeHost指定写实例， readHost指定读实例。 在一个dataHost中可以定义多个writeHost和readHost。但是，如果writeHost指定的后端数据库宕机， 那么这个writeHost绑定的所有readHost也将不可用。 属性： 属性名 含义 取值 host 实例主机标识 对于writeHost一般使用 *M1；对于readHost，一般使用 *S1； url 后端数据库连接地址 如果是native，一般为 ip:port ; 如果是JDBC, 一般为jdbc:mysql://ip:port/ user 数据库用户名 root password 数据库密码 itcast weight 权重 在readHost中作为读节点权重 usingDecrypt 密码加密 默认 0 否 , 1 是 3. rule.xmlrule.xml中定义所有拆分表的规则, 在使用过程中可以灵活的使用分片算法, 或者对同一个分片算法使用不同的参数, 它让分片过程可配置化。 3.1 tableRule标签123456&lt;tableRule name=&quot;auto-sharding-long&quot;&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;rang-long&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt; A. name : 指定分片算法的名称 B. rule : 定义分片算法的具体内容 C. columns : 指定对应的表中用于分片的列名 D. algorithm : 对应function中指定的算法名称 3.2 Function标签123&lt;function name=&quot;rang-long&quot; class=&quot;io.mycat.route.function.AutoPartitionByLong&quot;&gt; &lt;property name=&quot;mapFile&quot;&gt;autopartition-long.txt&lt;/property&gt;&lt;/function&gt; A. name : 指定算法名称, 该文件中唯一 B. class : 指定算法的具体类 C. property : 根据算法的要求执行 4. sequence 配置文件在分库分表的情况下 , 原有的自增主键已无法满足在集群中全局唯一的主键 ,因此, MyCat中提供了全局sequence来实现主键 , 并保证全局唯一。那么在MyCat的配置文件 sequence_conf.properties 中就配置的是序列的相关配置。 主要包含以下几种形式： 1). 本地文件方式 2). 数据库方式 3). 本地时间戳方式 4). 其他方式 5). 自增长主键","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://zsc-cloud.github.io/categories/MySQL/"},{"name":"MyCat","slug":"MySQL/MyCat","permalink":"https://zsc-cloud.github.io/categories/MySQL/MyCat/"}],"tags":[{"name":"MyCat","slug":"MyCat","permalink":"https://zsc-cloud.github.io/tags/MyCat/"},{"name":"分库分表","slug":"分库分表","permalink":"https://zsc-cloud.github.io/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"}]},{"title":"MyCat(四)---分片","slug":"Mycat(四)---分片","date":"2021-06-25T20:41:11.000Z","updated":"2022-03-26T03:42:17.332Z","comments":true,"path":"2021/06/25/Mycat(四)---分片/","link":"","permalink":"https://zsc-cloud.github.io/2021/06/25/Mycat(%E5%9B%9B)---%E5%88%86%E7%89%87/","excerpt":"","text":"垂直拆分概述 一种是按照不同的表（或者Schema）来切分到不同的数据库（主机）之上，这种切分可以称之为数据的垂直（纵向）切分。 案例场景 在业务系统中, 有以下表结构 ,但是由于用户与订单每天都会产生大量的数据, 单台服务器的数据存储及处理能力是有限的, 可以对数据库表进行拆分, 原有的数据库表: 准备工作1). 准备三台数据库实例 123192.168.192.157192.168.192.158192.168.192.159 2). 在三台数据库实例中建库建表 将准备好的三个SQL脚本, 分别导入到三台MySQL实例中 ; 登录MySQL数据库之后, 使用source命令导入 ; schema.xml的配置123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;?xml version=&quot;1.0&quot;?&gt;&lt;!DOCTYPE mycat:schema SYSTEM &quot;schema.dtd&quot;&gt;&lt;mycat:schema xmlns:mycat=&quot;http://io.mycat/&quot;&gt; &lt;schema name=&quot;ITCAST_DB&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot;&gt; &lt;table name=&quot;tb_areas_city&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;id&quot; /&gt; &lt;table name=&quot;tb_areas_provinces&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;id&quot; /&gt; &lt;table name=&quot;tb_areas_region&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;id&quot; /&gt; &lt;table name=&quot;tb_user&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;id&quot; /&gt; &lt;table name=&quot;tb_user_address&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;id&quot; /&gt; &lt;table name=&quot;tb_goods_base&quot; dataNode=&quot;dn2&quot; primaryKey=&quot;id&quot; /&gt; &lt;table name=&quot;tb_goods_desc&quot; dataNode=&quot;dn2&quot; primaryKey=&quot;goods_id&quot; /&gt; &lt;table name=&quot;tb_goods_item_cat&quot; dataNode=&quot;dn2&quot; primaryKey=&quot;id&quot; /&gt; &lt;table name=&quot;tb_order_item&quot; dataNode=&quot;dn3&quot; primaryKey=&quot;id&quot; /&gt; &lt;table name=&quot;tb_order_master&quot; dataNode=&quot;dn3&quot; primaryKey=&quot;order_id&quot; /&gt; &lt;table name=&quot;tb_order_pay_log&quot; dataNode=&quot;dn3&quot; primaryKey=&quot;out_trade_no&quot; /&gt; &lt;/schema&gt; &lt;dataNode name=&quot;dn1&quot; dataHost=&quot;host1&quot; database=&quot;user_db&quot; /&gt; &lt;dataNode name=&quot;dn2&quot; dataHost=&quot;host2&quot; database=&quot;goods_db&quot; /&gt; &lt;dataNode name=&quot;dn3&quot; dataHost=&quot;host3&quot; database=&quot;order_db&quot; /&gt; &lt;dataHost name=&quot;host1&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=&quot;hostM1&quot; url=&quot;192.168.192.157:3306&quot; user=&quot;root&quot; password=&quot;itcast&quot;&gt;&lt;/writeHost&gt; &lt;/dataHost&gt; &lt;dataHost name=&quot;host2&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=&quot;hostM2&quot; url=&quot;192.168.192.158:3306&quot; user=&quot;root&quot; password=&quot;itcast&quot;&gt;&lt;/writeHost&gt; &lt;/dataHost&gt; &lt;dataHost name=&quot;host3&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=&quot;hostM3&quot; url=&quot;192.168.192.159:3306&quot; user=&quot;root&quot; password=&quot;itcast&quot;&gt;&lt;/writeHost&gt; &lt;/dataHost&gt; &lt;/mycat:schema&gt; server.xml的配置123456789101112131415&lt;user name=&quot;root&quot; defaultAccount=&quot;true&quot;&gt; &lt;property name=&quot;password&quot;&gt;123456&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;ITCAST_DB&lt;/property&gt;&lt;/user&gt;&lt;user name=&quot;test&quot;&gt; &lt;property name=&quot;password&quot;&gt;123456&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;ITCAST_DB&lt;/property&gt;&lt;/user&gt;&lt;user name=&quot;user&quot;&gt; &lt;property name=&quot;password&quot;&gt;123456&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;ITCAST_DB&lt;/property&gt; &lt;property name=&quot;readOnly&quot;&gt;true&lt;/property&gt;&lt;/user&gt; 测试1). 查询数据 123select * from tb_goods_base;select * from tb_user;select * from tb_order_master; 2). 插入数据 1insert into tb_user_address(id,user_id,province_id,city_id,town_id,mobile,address,contact,is_default,notes,create_date,alias) values (null,&#x27;java00001&#x27;,NULL,NULL,NULL,&#x27;13900112222&#x27;,&#x27;钟楼&#x27;,&#x27;张三&#x27;,&#x27;0&#x27;,NULL,NULL,NULL) 1insert into tb_order_item(id,item_id,goods_id,order_id,title,price,num,total_fee,pic_path,seller_id) values (null,19,149187842867954,3,&#x27;3G 6&#x27;,&#x27;1.00&#x27;,5,&#x27;5.00&#x27;,NULL,&#x27;qiandu&#x27;) 3). 测试跨分片的查询 12SELECT order_id , payment ,receiver, province , city , area FROM tb_order_master o , tb_areas_provinces p , tb_areas_city c , tb_areas_region rWHERE o.receiver_province = p.provinceid AND o.receiver_city = c.cityid AND o.receiver_region = r.areaid ; 当运行上述的SQL语句时, MyCat会报错, 原因是因为当前SQL语句涉及到跨域的join操作 ; 全局表配置1). 将数据节点user_db中的关联的字典表 tb_areas_provinces , tb_areas_city , tb_areas_region中的数据备份 ; 123mysqldump -uroot -pitcast user_db tb_areas_provinces &gt; provinces;mysqldump -uroot -pitcast user_db tb_areas_city &gt; city;mysqldump -uroot -pitcast user_db tb_areas_region &gt; region; 2). 将备份的表结构及数据信息, 远程同步到其他两个数据节点的数据库中; 12345678scp city root@192.168.192.158:/rootscp city root@192.168.192.159:/rootscp provinces root@192.168.192.158:/rootscp provinces root@192.168.192.159:/rootscp region root@192.168.192.158:/rootscp region root@192.168.192.159:/root 3). 导入到对应的数据库中 123mysql -uroot -p goods_db &lt; citymysql -uroot -p goods_db &lt; provinces mysql -uroot -p goods_db &lt; region 4). MyCat逻辑表中的配置 123&lt;table name=&quot;tb_areas_city&quot; dataNode=&quot;dn1,dn2,dn3&quot; primaryKey=&quot;id&quot; type=&quot;global&quot;/&gt;&lt;table name=&quot;tb_areas_provinces&quot; dataNode=&quot;dn1,dn2,dn3&quot; primaryKey=&quot;id&quot; type=&quot;global&quot;/&gt;&lt;table name=&quot;tb_areas_region&quot; dataNode=&quot;dn1,dn2,dn3&quot; primaryKey=&quot;id&quot; type=&quot;global&quot;/&gt; 5). 重启MyCat 1bin/mycat restart 6). 测试 再次执行相同的连接查询 , 是可以正常查询出对应的数据的 ; 12SELECT order_id , payment ,receiver, province , city , area FROM tb_order_master o , tb_areas_provinces p , tb_areas_city c , tb_areas_region rWHERE o.receiver_province = p.provinceid AND o.receiver_city = c.cityid AND o.receiver_region = r.areaid ; 当我们对Mycat全局表进行增删改的操作时, 其他节点主机上的后端MySQL数据库中的数据时会同步变化的; 1update tb_areas_city set city = &#x27;石家庄&#x27; where id = 5; 水平拆分概述根据表中的数据的逻辑关系，将同一个表中的数据按照某种条件拆分到多台数据库（主机）上面，这种切分称之为数据的水平（横向）切分。 案例场景 在业务系统中, 有一张表(日志表), 业务系统每天都会产生大量的日志数据 , 单台服务器的数据存储及处理能力是有限的, 可以对数据库表进行拆分, 原有的数据库表拆分成以下表 : 准备工作1). 准备三台数据库实例 123192.168.192.157192.168.192.158192.168.192.159 2). 在三台数据库实例中创建数据库 1create database log_db DEFAULT CHARACTER SET utf8mb4; schema.xml的配置1234567891011121314151617181920212223242526272829&lt;?xml version=&quot;1.0&quot;?&gt;&lt;!DOCTYPE mycat:schema SYSTEM &quot;schema.dtd&quot;&gt;&lt;mycat:schema xmlns:mycat=&quot;http://io.mycat/&quot;&gt; &lt;schema name=&quot;LOG_DB&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot;&gt; &lt;table name=&quot;tb_log&quot; dataNode=&quot;dn1,dn2,dn3&quot; primaryKey=&quot;id&quot; rule=&quot;mod-long&quot; /&gt; &lt;/schema&gt; &lt;dataNode name=&quot;dn1&quot; dataHost=&quot;host1&quot; database=&quot;log_db&quot; /&gt; &lt;dataNode name=&quot;dn2&quot; dataHost=&quot;host2&quot; database=&quot;log_db&quot; /&gt; &lt;dataNode name=&quot;dn3&quot; dataHost=&quot;host3&quot; database=&quot;log_db&quot; /&gt; &lt;dataHost name=&quot;host1&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=&quot;hostM1&quot; url=&quot;192.168.192.157:3306&quot; user=&quot;root&quot; password=&quot;itcast&quot;&gt;&lt;/writeHost&gt; &lt;/dataHost&gt; &lt;dataHost name=&quot;host2&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=&quot;hostM2&quot; url=&quot;192.168.192.158:3306&quot; user=&quot;root&quot; password=&quot;itcast&quot;&gt;&lt;/writeHost&gt; &lt;/dataHost&gt; &lt;dataHost name=&quot;host3&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=&quot;hostM3&quot; url=&quot;192.168.192.159:3306&quot; user=&quot;root&quot; password=&quot;itcast&quot;&gt;&lt;/writeHost&gt; &lt;/dataHost&gt; &lt;/mycat:schema&gt; server.xml的配置123456789101112131415&lt;user name=&quot;root&quot; defaultAccount=&quot;true&quot;&gt; &lt;property name=&quot;password&quot;&gt;123456&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;LOG_DB&lt;/property&gt;&lt;/user&gt;&lt;user name=&quot;test&quot;&gt; &lt;property name=&quot;password&quot;&gt;123456&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;LOG_DB&lt;/property&gt;&lt;/user&gt;&lt;user name=&quot;user&quot;&gt; &lt;property name=&quot;password&quot;&gt;123456&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;LOG_DB&lt;/property&gt; &lt;property name=&quot;readOnly&quot;&gt;true&lt;/property&gt;&lt;/user&gt; 测试1). 在MyCat数据库中执行建表语句 123456789101112131415CREATE TABLE `tb_log` ( `id` bigint(20) NOT NULL COMMENT &#x27;ID&#x27;, `model_name` varchar(200) DEFAULT NULL COMMENT &#x27;模块名&#x27;, `model_value` varchar(200) DEFAULT NULL COMMENT &#x27;模块值&#x27;, `return_value` varchar(200) DEFAULT NULL COMMENT &#x27;返回值&#x27;, `return_class` varchar(200) DEFAULT NULL COMMENT &#x27;返回值类型&#x27;, `operate_user` varchar(20) DEFAULT NULL COMMENT &#x27;操作用户&#x27;, `operate_time` varchar(20) DEFAULT NULL COMMENT &#x27;操作时间&#x27;, `param_and_value` varchar(500) DEFAULT NULL COMMENT &#x27;请求参数名及参数值&#x27;, `operate_class` varchar(200) DEFAULT NULL COMMENT &#x27;操作类&#x27;, `operate_method` varchar(200) DEFAULT NULL COMMENT &#x27;操作方法&#x27;, `cost_time` bigint(20) DEFAULT NULL COMMENT &#x27;执行方法耗时, 单位 ms&#x27;, `source` int(1) DEFAULT NULL COMMENT &#x27;来源 : 1 PC , 2 Android , 3 IOS&#x27;, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 2). 插入数据 123456INSERT INTO `tb_log` (`id`, `model_name`, `model_value`, `return_value`, `return_class`, `operate_user`, `operate_time`, `param_and_value`, `operate_class`, `operate_method`, `cost_time`，`source`) VALUES(&#x27;1&#x27;,&#x27;user&#x27;,&#x27;insert&#x27;,&#x27;success&#x27;,&#x27;java.lang.String&#x27;,&#x27;10001&#x27;,&#x27;2020-02-26 18:12:28&#x27;,&#x27;&#123;\\&quot;age\\&quot;:\\&quot;20\\&quot;,\\&quot;name\\&quot;:\\&quot;Tom\\&quot;,\\&quot;gender\\&quot;:\\&quot;1\\&quot;&#125;&#x27;,&#x27;cn.itcast.controller.UserController&#x27;,&#x27;insert&#x27;,&#x27;10&#x27;,1);INSERT INTO `tb_log` (`id`, `model_name`, `model_value`, `return_value`, `return_class`, `operate_user`, `operate_time`, `param_and_value`, `operate_class`, `operate_method`, `cost_time`，`source`) VALUES(&#x27;2&#x27;,&#x27;user&#x27;,&#x27;insert&#x27;,&#x27;success&#x27;,&#x27;java.lang.String&#x27;,&#x27;10001&#x27;,&#x27;2020-02-26 18:12:27&#x27;,&#x27;&#123;\\&quot;age\\&quot;:\\&quot;20\\&quot;,\\&quot;name\\&quot;:\\&quot;Tom\\&quot;,\\&quot;gender\\&quot;:\\&quot;1\\&quot;&#125;&#x27;,&#x27;cn.itcast.controller.UserController&#x27;,&#x27;insert&#x27;,&#x27;23&#x27;,1);INSERT INTO `tb_log` (`id`, `model_name`, `model_value`, `return_value`, `return_class`, `operate_user`, `operate_time`, `param_and_value`, `operate_class`, `operate_method`, `cost_time`，`source`) VALUES(&#x27;3&#x27;,&#x27;user&#x27;,&#x27;update&#x27;,&#x27;success&#x27;,&#x27;java.lang.String&#x27;,&#x27;10001&#x27;,&#x27;2020-02-26 18:16:45&#x27;,&#x27;&#123;\\&quot;age\\&quot;:\\&quot;20\\&quot;,\\&quot;name\\&quot;:\\&quot;Tom\\&quot;,\\&quot;gender\\&quot;:\\&quot;1\\&quot;&#125;&#x27;,&#x27;cn.itcast.controller.UserController&#x27;,&#x27;update&#x27;,&#x27;34&#x27;,1);INSERT INTO `tb_log` (`id`, `model_name`, `model_value`, `return_value`, `return_class`, `operate_user`, `operate_time`, `param_and_value`, `operate_class`, `operate_method`, `cost_time`，`source`) VALUES(&#x27;4&#x27;,&#x27;user&#x27;,&#x27;update&#x27;,&#x27;success&#x27;,&#x27;java.lang.String&#x27;,&#x27;10001&#x27;,&#x27;2020-02-26 18:16:45&#x27;,&#x27;&#123;\\&quot;age\\&quot;:\\&quot;20\\&quot;,\\&quot;name\\&quot;:\\&quot;Tom\\&quot;,\\&quot;gender\\&quot;:\\&quot;1\\&quot;&#125;&#x27;,&#x27;cn.itcast.controller.UserController&#x27;,&#x27;update&#x27;,&#x27;13&#x27;,2);INSERT INTO `tb_log` (`id`, `model_name`, `model_value`, `return_value`, `return_class`, `operate_user`, `operate_time`, `param_and_value`, `operate_class`, `operate_method`, `cost_time`，`source`) VALUES(&#x27;5&#x27;,&#x27;user&#x27;,&#x27;insert&#x27;,&#x27;success&#x27;,&#x27;java.lang.String&#x27;,&#x27;10001&#x27;,&#x27;2020-02-26 18:30:31&#x27;,&#x27;&#123;\\&quot;age\\&quot;:\\&quot;200\\&quot;,\\&quot;name\\&quot;:\\&quot;TomCat\\&quot;,\\&quot;gender\\&quot;:\\&quot;0\\&quot;&#125;&#x27;,&#x27;cn.itcast.controller.UserController&#x27;,&#x27;insert&#x27;,&#x27;29&#x27;,3);INSERT INTO `tb_log` (`id`, `model_name`, `model_value`, `return_value`, `return_class`, `operate_user`, `operate_time`, `param_and_value`, `operate_class`, `operate_method`, `cost_time`，`source`) VALUES(&#x27;6&#x27;,&#x27;user&#x27;,&#x27;find&#x27;,&#x27;success&#x27;,&#x27;java.lang.String&#x27;,&#x27;10001&#x27;,&#x27;2020-02-26 18:30:31&#x27;,&#x27;&#123;\\&quot;age\\&quot;:\\&quot;200\\&quot;,\\&quot;name\\&quot;:\\&quot;TomCat\\&quot;,\\&quot;gender\\&quot;:\\&quot;0\\&quot;&#125;&#x27;,&#x27;cn.itcast.controller.UserController&#x27;,&#x27;find&#x27;,&#x27;29&#x27;,2); 分片规则MyCat的分片规则配置在conf目录下的rule.xml文件中定义 ; 环境准备 : 1). schema.xml中的内容做好备份 , 并配置逻辑库; 123456789101112131415161718192021222324252627&lt;schema name=&quot;PARTITION_DB&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot;&gt; &lt;table name=&quot;&quot; dataNode=&quot;dn1,dn2,dn3&quot; rule=&quot;&quot;/&gt;&lt;/schema&gt;&lt;dataNode name=&quot;dn1&quot; dataHost=&quot;host1&quot; database=&quot;partition_db&quot; /&gt;&lt;dataNode name=&quot;dn2&quot; dataHost=&quot;host2&quot; database=&quot;partition_db&quot; /&gt;&lt;dataNode name=&quot;dn3&quot; dataHost=&quot;host3&quot; database=&quot;partition_db&quot; /&gt;&lt;dataHost name=&quot;host1&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot;writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=&quot;hostM1&quot; url=&quot;192.168.192.157:3306&quot; user=&quot;root&quot; password=&quot;itcast&quot;&gt;&lt;/writeHost&gt;&lt;/dataHost&gt; &lt;dataHost name=&quot;host2&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot;writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=&quot;hostM2&quot; url=&quot;192.168.192.158:3306&quot; user=&quot;root&quot; password=&quot;itcast&quot;&gt;&lt;/writeHost&gt;&lt;/dataHost&gt; &lt;dataHost name=&quot;host3&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot;writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=&quot;hostM3&quot; url=&quot;192.168.192.159:3306&quot; user=&quot;root&quot; password=&quot;itcast&quot;&gt;&lt;/writeHost&gt;&lt;/dataHost&gt; 2). 在MySQL的三个节点的数据库中 , 创建数据库partition_db 1create database partition_db DEFAULT CHARACTER SET utf8mb4; 取模分片12345678910&lt;tableRule name=&quot;mod-long&quot;&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;mod-long&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt;&lt;function name=&quot;mod-long&quot; class=&quot;io.mycat.route.function.PartitionByMod&quot;&gt; &lt;property name=&quot;count&quot;&gt;3&lt;/property&gt;&lt;/function&gt; 配置说明 : 属性 描述 columns 标识将要分片的表字段 algorithm 指定分片函数与function的对应关系 class 指定该分片算法对应的类 count 数据节点的数量 范围分片根据指定的字段及其配置的范围与数据节点的对应情况， 来决定该数据属于哪一个分片 ， 配置如下： 1234567891011&lt;tableRule name=&quot;auto-sharding-long&quot;&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;rang-long&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt;&lt;function name=&quot;rang-long&quot; class=&quot;io.mycat.route.function.AutoPartitionByLong&quot;&gt; &lt;property name=&quot;mapFile&quot;&gt;autopartition-long.txt&lt;/property&gt; &lt;property name=&quot;defaultNode&quot;&gt;0&lt;/property&gt;&lt;/function&gt; autopartition-long.txt 配置如下： 12345# range start-end ,data node index# K=1000,M=10000.0-500M=0500M-1000M=11000M-1500M=2 含义为 ： 0 - 500 万之间的值 ， 存储在0号数据节点 ； 500万 - 1000万之间的数据存储在1号数据节点 ； 1000万 - 1500 万的数据节点存储在2号节点 ； 配置说明: 属性 描述 columns 标识将要分片的表字段 algorithm 指定分片函数与function的对应关系 class 指定该分片算法对应的类 mapFile 对应的外部配置文件 type 默认值为0 ; 0 表示Integer , 1 表示String defaultNode 默认节点 默认节点的所用:枚举分片时,如果碰到不识别的枚举值, 就让它路由到默认节点 ; 如果没有默认值,碰到不识别的则报错 。 **测试: ** 配置 1&lt;table name=&quot;tb_log&quot; dataNode=&quot;dn1,dn2,dn3&quot; rule=&quot;auto-sharding-long&quot;/&gt; 数据 1234567891011121314151). 创建表CREATE TABLE `tb_log` ( id bigint(20) NOT NULL COMMENT &#x27;ID&#x27;, operateuser varchar(200) DEFAULT NULL COMMENT &#x27;姓名&#x27;, operation int(2) DEFAULT NULL COMMENT &#x27;1: insert, 2: delete, 3: update , 4: select&#x27;, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;2). 插入数据insert into tb_log (id,operateuser ,operation) values(1,&#x27;Tom&#x27;,1);insert into tb_log (id,operateuser ,operation) values(2,&#x27;Cat&#x27;,2);insert into tb_log (id,operateuser ,operation) values(3,&#x27;Rose&#x27;,3);insert into tb_log (id,operateuser ,operation) values(4,&#x27;Coco&#x27;,2);insert into tb_log (id,operateuser ,operation) values(5,&#x27;Lily&#x27;,1); 枚举分片通过在配置文件中配置可能的枚举值, 指定数据分布到不同数据节点上, 本规则适用于按照省份或状态拆分数据等业务 , 配置如下: 123456789101112&lt;tableRule name=&quot;sharding-by-intfile&quot;&gt; &lt;rule&gt; &lt;columns&gt;status&lt;/columns&gt; &lt;algorithm&gt;hash-int&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt;&lt;function name=&quot;hash-int&quot; class=&quot;io.mycat.route.function.PartitionByFileMap&quot;&gt; &lt;property name=&quot;mapFile&quot;&gt;partition-hash-int.txt&lt;/property&gt; &lt;property name=&quot;type&quot;&gt;0&lt;/property&gt; &lt;property name=&quot;defaultNode&quot;&gt;0&lt;/property&gt;&lt;/function&gt; partition-hash-int.txt ，内容如下 : 1231=02=13=2 配置说明: 属性 描述 columns 标识将要分片的表字段 algorithm 指定分片函数与function的对应关系 class 指定该分片算法对应的类 mapFile 对应的外部配置文件 type 默认值为0 ; 0 表示Integer , 1 表示String defaultNode 默认节点 ; 小于0 标识不设置默认节点 , 大于等于0代表设置默认节点 ; 默认节点的所用:枚举分片时,如果碰到不识别的枚举值, 就让它路由到默认节点 ; 如果没有默认值,碰到不识别的则报错 。 测试: 配置 1&lt;table name=&quot;tb_user&quot; dataNode=&quot;dn1,dn2,dn3&quot; rule=&quot;sharding-by-enum-status&quot;/&gt; 数据 1234567891011121314151). 创建表CREATE TABLE `tb_user` ( id bigint(20) NOT NULL COMMENT &#x27;ID&#x27;, username varchar(200) DEFAULT NULL COMMENT &#x27;姓名&#x27;, status int(2) DEFAULT &#x27;1&#x27; COMMENT &#x27;1: 未启用, 2: 已启用, 3: 已关闭&#x27;, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;2). 插入数据insert into tb_user (id,username ,status) values(1,&#x27;Tom&#x27;,1);insert into tb_user (id,username ,status) values(2,&#x27;Cat&#x27;,2);insert into tb_user (id,username ,status) values(3,&#x27;Rose&#x27;,3);insert into tb_user (id,username ,status) values(4,&#x27;Coco&#x27;,2);insert into tb_user (id,username ,status) values(5,&#x27;Lily&#x27;,1); 范围求模算法该算法为先进行范围分片, 计算出分片组 , 再进行组内求模。 优点： 综合了范围分片和求模分片的优点。 分片组内使用求模可以保证组内的数据分布比较均匀， 分片组之间采用范围分片可以兼顾范围分片的特点。 缺点： 在数据范围时固定值（非递增值）时，存在不方便扩展的情况，例如将 dataNode Group size 从 2 扩展为 4 时，需要进行数据迁移才能完成 ； 如图所示： 配置如下： 1234567891011&lt;tableRule name=&quot;auto-sharding-rang-mod&quot;&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;rang-mod&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt;&lt;function name=&quot;rang-mod&quot; class=&quot;io.mycat.route.function.PartitionByRangeMod&quot;&gt; &lt;property name=&quot;mapFile&quot;&gt;autopartition-range-mod.txt&lt;/property&gt; &lt;property name=&quot;defaultNode&quot;&gt;0&lt;/property&gt;&lt;/function&gt; autopartition-range-mod.txt 配置格式 : 123#range start-end , data node group size0-500M=1500M1-2000M=2 在上述配置文件中, 等号前面的范围代表一个分片组 , 等号后面的数字代表该分片组所拥有的分片数量; 配置说明: 属性 描述 columns 标识将要分片的表字段名 algorithm 指定分片函数与function的对应关系 class 指定该分片算法对应的类 mapFile 对应的外部配置文件 defaultNode 默认节点 ; 未包含以上规则的数据存储在defaultNode节点中, 节点从0开始 测试: 配置 1&lt;table name=&quot;tb_stu&quot; dataNode=&quot;dn1,dn2,dn3&quot; rule=&quot;auto-sharding-rang-mod&quot;/&gt; 数据 123456789101112131415161718191). 创建表 CREATE TABLE `tb_stu` ( id bigint(20) NOT NULL COMMENT &#x27;ID&#x27;, username varchar(200) DEFAULT NULL COMMENT &#x27;姓名&#x27;, status int(2) DEFAULT &#x27;1&#x27; COMMENT &#x27;1: 未启用, 2: 已启用, 3: 已关闭&#x27;, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;2). 插入数据 insert into tb_stu (id,username ,status) values(1,&#x27;Tom&#x27;,1); insert into tb_stu (id,username ,status) values(2,&#x27;Cat&#x27;,2); insert into tb_stu (id,username ,status) values(3,&#x27;Rose&#x27;,3); insert into tb_stu (id,username ,status) values(4,&#x27;Coco&#x27;,2); insert into tb_stu (id,username ,status) values(5,&#x27;Lily&#x27;,1); insert into tb_stu (id,username ,status) values(5000001,&#x27;Roce&#x27;,1); insert into tb_stu (id,username ,status) values(5000002,&#x27;Jexi&#x27;,2); insert into tb_stu (id,username ,status) values(5000003,&#x27;Mini&#x27;,1); 固定分片hash算法该算法类似于十进制的求模运算，但是为二进制的操作，例如，取 id 的二进制低 10 位 与 1111111111 进行位 &amp; 运算。 最小值： 最大值： 优点： 这种策略比较灵活，可以均匀分配也可以非均匀分配，各节点的分配比例和容量大小由partitionCount和partitionLength两个参数决定 缺点：和取模分片类似。 配置如下 ： 1234567891011&lt;tableRule name=&quot;sharding-by-long-hash&quot;&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;func1&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt;&lt;function name=&quot;func1&quot; class=&quot;org.opencloudb.route.function.PartitionByLong&quot;&gt; &lt;property name=&quot;partitionCount&quot;&gt;2,1&lt;/property&gt; &lt;property name=&quot;partitionLength&quot;&gt;256,512&lt;/property&gt;&lt;/function&gt; 在示例中配置的分片策略，希望将数据水平分成3份，前两份各占 25%，第三份占 50%。 配置说明: 属性 描述 columns 标识将要分片的表字段名 algorithm 指定分片函数与function的对应关系 class 指定该分片算法对应的类 partitionCount 分片个数列表 partitionLength 分片范围列表 约束 : 1). 分片长度 : 默认最大2^10 , 为 1024 ; 2). count, length的数组长度必须是一致的 ; 3). 两组数据的对应情况: (partitionCount[0]partitionLength[0])=(partitionCount[1]partitionLength[1]) 以上分为三个分区:0-255,256-511,512-1023 测试: 配置 1&lt;table name=&quot;tb_brand&quot; dataNode=&quot;dn1,dn2,dn3&quot; rule=&quot;sharding-by-long-hash&quot;/&gt; 数据 1234567891011121314151). 创建表 CREATE TABLE `tb_brand` ( id int(11) NOT NULL COMMENT &#x27;ID&#x27;, name varchar(200) DEFAULT NULL COMMENT &#x27;名称&#x27;, firstChar char(1) COMMENT &#x27;首字母&#x27;, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;2). 插入数据 insert into tb_brand (id,name ,firstChar) values(1,&#x27;七匹狼&#x27;,&#x27;Q&#x27;); insert into tb_brand (id,name ,firstChar) values(529,&#x27;八匹狼&#x27;,&#x27;B&#x27;); insert into tb_brand (id,name ,firstChar) values(1203,&#x27;九匹狼&#x27;,&#x27;J&#x27;); insert into tb_brand (id,name ,firstChar) values(1205,&#x27;十匹狼&#x27;,&#x27;S&#x27;); insert into tb_brand (id,name ,firstChar) values(1719,&#x27;六匹狼&#x27;,&#x27;L&#x27;); 取模范围算法该算法先进行取模，然后根据取模值所属范围进行分片。 优点：可以自主决定取模后数据的节点分布 缺点：dataNode 划分节点是事先建好的，需要扩展时比较麻烦。 配置如下: 123456789101112&lt;tableRule name=&quot;sharding-by-pattern&quot;&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;sharding-by-pattern&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt;&lt;function name=&quot;sharding-by-pattern&quot; class=&quot;io.mycat.route.function.PartitionByPattern&quot;&gt; &lt;property name=&quot;mapFile&quot;&gt;partition-pattern.txt&lt;/property&gt; &lt;property name=&quot;defaultNode&quot;&gt;0&lt;/property&gt; &lt;property name=&quot;patternValue&quot;&gt;96&lt;/property&gt;&lt;/function&gt; partition-pattern.txt 配置如下: 1230-32=033-64=165-96=2 在mapFile配置文件中, 1-32即代表id%96后的分布情况。如果在1-32, 则在分片0上 ; 如果在33-64, 则在分片1上 ; 如果在65-96, 则在分片2上。 配置说明: 属性 描述 columns 标识将要分片的表字段 algorithm 指定分片函数与function的对应关系 class 指定该分片算法对应的类 mapFile 对应的外部配置文件 defaultNode 默认节点 ; 如果id不是数字, 无法求模, 将分配在defaultNode上 patternValue 求模基数 测试: 配置 1&lt;table name=&quot;tb_mod_range&quot; dataNode=&quot;dn1,dn2,dn3&quot; rule=&quot;sharding-by-pattern&quot;/&gt; 数据 12345678910111213141). 创建表 CREATE TABLE `tb_mod_range` ( id int(11) NOT NULL COMMENT &#x27;ID&#x27;, name varchar(200) DEFAULT NULL COMMENT &#x27;名称&#x27;, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;2). 插入数据 insert into tb_mod_range (id,name) values(1,&#x27;Test1&#x27;); insert into tb_mod_range (id,name) values(2,&#x27;Test2&#x27;); insert into tb_mod_range (id,name) values(3,&#x27;Test3&#x27;); insert into tb_mod_range (id,name) values(4,&#x27;Test4&#x27;); insert into tb_mod_range (id,name) values(5,&#x27;Test5&#x27;); 注意 : 取模范围算法只能针对于数字类型进行取模运算 ; 如果是字符串则无法进行取模分片 ; 字符串hash求模范围算法与取模范围算法类似, 该算法支持数值、符号、字母取模，首先截取长度为 prefixLength 的子串，在对子串中每一个字符的 ASCII 码求和，然后对求和值进行取模运算（sum%patternValue），就可以计算出子串的分片数。 优点：可以自主决定取模后数据的节点分布 缺点：dataNode 划分节点是事先建好的，需要扩展时比较麻烦。 配置如下： 123456789101112&lt;tableRule name=&quot;sharding-by-prefixpattern&quot;&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;sharding-by-prefixpattern&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt;&lt;function name=&quot;sharding-by-prefixpattern&quot; class=&quot;io.mycat.route.function.PartitionByPrefixPattern&quot;&gt; &lt;property name=&quot;mapFile&quot;&gt;partition-prefixpattern.txt&lt;/property&gt; &lt;property name=&quot;prefixLength&quot;&gt;5&lt;/property&gt; &lt;property name=&quot;patternValue&quot;&gt;96&lt;/property&gt;&lt;/function&gt; partition-prefixpattern.txt 配置如下: 123456789# range start-end ,data node index# ASCII# 48-57=0-9# 64、65-90=@、A-Z# 97-122=a-z###### first host configuration0-32=033-64=165-96=2 配置说明: 属性 描述 columns 标识将要分片的表字段 algorithm 指定分片函数与function的对应关系 class 指定该分片算法对应的类 mapFile 对应的外部配置文件 prefixLength 截取的位数; 将该字段获取前prefixLength位所有ASCII码的和, 进行求模sum%patternValue ,获取的值，在通配范围内的即分片数 ; patternValue 求模基数 如 : 12345678910111213字符串 : gf89f9a 截取字符串的前5位进行ASCII的累加运算 : g - 103 f - 102 8 - 56 9 - 57 f - 102 sum求和 : 103 + 102 + + 56 + 57 + 102 = 420 求模 : 420 % 96 = 36 附录 ASCII码表 : 测试: 配置 1&lt;table name=&quot;tb_u&quot; dataNode=&quot;dn1,dn2,dn3&quot; rule=&quot;sharding-by-prefixpattern&quot;/&gt; 数据 12345678910111213141). 创建表 CREATE TABLE `tb_u` ( username varchar(50) NOT NULL COMMENT &#x27;用户名&#x27;, age int(11) default 0 COMMENT &#x27;年龄&#x27;, PRIMARY KEY (`username`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;2). 插入数据 insert into tb_u (username,age) values(&#x27;Test100001&#x27;,18); insert into tb_u (username,age) values(&#x27;Test200001&#x27;,20); insert into tb_u (username,age) values(&#x27;Test300001&#x27;,19); insert into tb_u (username,age) values(&#x27;Test400001&#x27;,25); insert into tb_u (username,age) values(&#x27;Test500001&#x27;,22); 应用指定算法由运行阶段由应用自主决定路由到那个分片 , 直接根据字符子串（必须是数字）计算分片号 , 配置如下 : 12345678910111213&lt;tableRule name=&quot;sharding-by-substring&quot;&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;sharding-by-substring&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt;&lt;function name=&quot;sharding-by-substring&quot; class=&quot;io.mycat.route.function.PartitionDirectBySubString&quot;&gt; &lt;property name=&quot;startIndex&quot;&gt;0&lt;/property&gt; &lt;!-- zero-based --&gt; &lt;property name=&quot;size&quot;&gt;2&lt;/property&gt; &lt;property name=&quot;partitionCount&quot;&gt;3&lt;/property&gt; &lt;property name=&quot;defaultPartition&quot;&gt;0&lt;/property&gt;&lt;/function&gt; 配置说明: 属性 描述 columns 标识将要分片的表字段 algorithm 指定分片函数与function的对应关系 class 指定该分片算法对应的类 startIndex 字符子串起始索引 size 字符长度 partitionCount 分区(分片)数量 defaultPartition 默认分片(在分片数量定义时, 字符标示的分片编号不在分片数量内时,使用默认分片) 示例说明 : id=05-100000002 , 在此配置中代表根据id中从 startIndex=0，开始，截取siz=2位数字即05，05就是获取的分区，如果没传默认分配到defaultPartition 。 测试: 配置 1&lt;table name=&quot;tb_app&quot; dataNode=&quot;dn1,dn2,dn3&quot; rule=&quot;sharding-by-substring&quot;/&gt; 数据 1234567891011121314151). 创建表 CREATE TABLE `tb_app` ( id varchar(10) NOT NULL COMMENT &#x27;ID&#x27;, name varchar(200) DEFAULT NULL COMMENT &#x27;名称&#x27;, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;2). 插入数据 insert into tb_app (id,name) values(&#x27;00-00001&#x27;,&#x27;Testx00001&#x27;); insert into tb_app (id,name) values(&#x27;01-00001&#x27;,&#x27;Test100001&#x27;); insert into tb_app (id,name) values(&#x27;01-00002&#x27;,&#x27;Test200001&#x27;); insert into tb_app (id,name) values(&#x27;02-00001&#x27;,&#x27;Test300001&#x27;); insert into tb_app (id,name) values(&#x27;02-00002&#x27;,&#x27;TesT400001&#x27;); 字符串hash解析算法截取字符串中的指定位置的子字符串, 进行hash算法， 算出分片 ， 配置如下： 123456789101112&lt;tableRule name=&quot;sharding-by-stringhash&quot;&gt; &lt;rule&gt; &lt;columns&gt;user_id&lt;/columns&gt; &lt;algorithm&gt;sharding-by-stringhash&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt;&lt;function name=&quot;sharding-by-stringhash&quot; class=&quot;io.mycat.route.function.PartitionByString&quot;&gt; &lt;property name=&quot;partitionLength&quot;&gt;512&lt;/property&gt; &lt;!-- zero-based --&gt; &lt;property name=&quot;partitionCount&quot;&gt;2&lt;/property&gt; &lt;property name=&quot;hashSlice&quot;&gt;0:2&lt;/property&gt;&lt;/function&gt; 配置说明: 属性 描述 columns 标识将要分片的表字段 algorithm 指定分片函数与function的对应关系 class 指定该分片算法对应的类 partitionLength hash求模基数 ; length*count=1024 (出于性能考虑) partitionCount 分区数 hashSlice hash运算位 , 根据子字符串的hash运算 ; 0 代表 str.length() , -1 代表 str.length()-1 , 大于0只代表数字自身 ; 可以理解为substring（start，end），start为0则只表示0 测试: 配置 1&lt;table name=&quot;tb_strhash&quot; dataNode=&quot;dn1,dn2,dn3&quot; rule=&quot;sharding-by-stringhash&quot;/&gt; 数据 1234567891011121). 创建表create table tb_strhash( name varchar(20) primary key, content varchar(100))engine=InnoDB DEFAULT CHARSET=utf8mb4;2). 插入数据INSERT INTO tb_strhash (name,content) VALUES(&#x27;T1001&#x27;, UUID());INSERT INTO tb_strhash (name,content) VALUES(&#x27;ROSE&#x27;, UUID());INSERT INTO tb_strhash (name,content) VALUES(&#x27;JERRY&#x27;, UUID());INSERT INTO tb_strhash (name,content) VALUES(&#x27;CRISTINA&#x27;, UUID());INSERT INTO tb_strhash (name,content) VALUES(&#x27;TOMCAT&#x27;, UUID()); 原理: 一致性hash算法一致性Hash算法有效的解决了分布式数据的拓容问题 , 配置如下: 1234567891011121314&lt;tableRule name=&quot;sharding-by-murmur&quot;&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;murmur&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt;&lt;function name=&quot;murmur&quot; class=&quot;io.mycat.route.function.PartitionByMurmurHash&quot;&gt; &lt;property name=&quot;seed&quot;&gt;0&lt;/property&gt; &lt;property name=&quot;count&quot;&gt;3&lt;/property&gt;&lt;!-- --&gt; &lt;property name=&quot;virtualBucketTimes&quot;&gt;160&lt;/property&gt; &lt;!-- &lt;property name=&quot;weightMapFile&quot;&gt;weightMapFile&lt;/property&gt; --&gt; &lt;!-- &lt;property name=&quot;bucketMapPath&quot;&gt;/etc/mycat/bucketMapPath&lt;/property&gt; --&gt;&lt;/function&gt; 配置说明: 属性 描述 columns 标识将要分片的表字段 algorithm 指定分片函数与function的对应关系 class 指定该分片算法对应的类 seed 创建murmur_hash对象的种子，默认0 count 要分片的数据库节点数量，必须指定，否则没法分片 virtualBucketTimes 一个实际的数据库节点被映射为这么多虚拟节点，默认是160倍，也就是虚拟节点数是物理节点数的160倍;virtualBucketTimes*count就是虚拟结点数量 ; weightMapFile 节点的权重，没有指定权重的节点默认是1。以properties文件的格式填写，以从0开始到count-1的整数值也就是节点索引为key，以节点权重值为值。所有权重值必须是正整数，否则以1代替 bucketMapPath 用于测试时观察各物理节点与虚拟节点的分布情况，如果指定了这个属性，会把虚拟节点的murmur hash值与物理节点的映射按行输出到这个文件，没有默认值，如果不指定，就不会输出任何东西 测试： 配置 1&lt;table name=&quot;tb_order&quot; dataNode=&quot;dn1,dn2,dn3&quot; rule=&quot;sharding-by-murmur&quot;/&gt; 数据 1234567891011121314151617181920212223241). 创建表create table tb_order( id int(11) primary key, money int(11), content varchar(200))engine=InnoDB ;2). 插入数据INSERT INTO tb_order (id,money,content) VALUES(1, 100 , UUID());INSERT INTO tb_order (id,money,content) VALUES(212, 100 , UUID());INSERT INTO tb_order (id,money,content) VALUES(312, 100 , UUID());INSERT INTO tb_order (id,money,content) VALUES(412, 100 , UUID());INSERT INTO tb_order (id,money,content) VALUES(534, 100 , UUID());INSERT INTO tb_order (id,money,content) VALUES(621, 100 , UUID());INSERT INTO tb_order (id,money,content) VALUES(754563, 100 , UUID());INSERT INTO tb_order (id,money,content) VALUES(8123, 100 , UUID());INSERT INTO tb_order (id,money,content) VALUES(91213, 100 , UUID());INSERT INTO tb_order (id,money,content) VALUES(23232, 100 , UUID());INSERT INTO tb_order (id,money,content) VALUES(112321, 100 , UUID());INSERT INTO tb_order (id,money,content) VALUES(21221, 100 , UUID());INSERT INTO tb_order (id,money,content) VALUES(112132, 100 , UUID());INSERT INTO tb_order (id,money,content) VALUES(12132, 100 , UUID());INSERT INTO tb_order (id,money,content) VALUES(124321, 100 , UUID());INSERT INTO tb_order (id,money,content) VALUES(212132, 100 , UUID()); 日期分片算法按照日期来分片 12345678910111213&lt;tableRule name=&quot;sharding-by-date&quot;&gt; &lt;rule&gt; &lt;columns&gt;create_time&lt;/columns&gt; &lt;algorithm&gt;sharding-by-date&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt;&lt;function name=&quot;sharding-by-date&quot; class=&quot;io.mycat.route.function.PartitionByDate&quot;&gt; &lt;property name=&quot;dateFormat&quot;&gt;yyyy-MM-dd&lt;/property&gt; &lt;property name=&quot;sBeginDate&quot;&gt;2020-01-01&lt;/property&gt; &lt;property name=&quot;sEndDate&quot;&gt;2020-12-31&lt;/property&gt; &lt;property name=&quot;sPartionDay&quot;&gt;10&lt;/property&gt;&lt;/function&gt; 配置说明: 属性 描述 columns 标识将要分片的表字段 algorithm 指定分片函数与function的对应关系 class 指定该分片算法对应的类 dateFormat 日期格式 sBeginDate 开始日期 sEndDate 结束日期，如果配置了结束日期，则代码数据到达了这个日期的分片后，会重复从开始分片插入 sPartionDay 分区天数，默认值 10 ，从开始日期算起，每个10天一个分区 注意：配置规则的表的 dataNode 的分片，必须和分片规则数量一致，例如 2020-01-01 到 2020-12-31 ，每10天一个分片，一共需要37个分片。 单月小时算法单月内按照小时拆分, 最小粒度是小时 , 一天最多可以有24个分片, 最小1个分片, 下个月从头开始循环, 每个月末需要手动清理数据。 配置如下 ： 12345678910&lt;tableRule name=&quot;sharding-by-hour&quot;&gt; &lt;rule&gt; &lt;columns&gt;create_time&lt;/columns&gt; &lt;algorithm&gt;sharding-by-hour&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt;&lt;function name=&quot;sharding-by-hour&quot; class=&quot;io.mycat.route.function.LatestMonthPartion&quot;&gt; &lt;property name=&quot;splitOneDay&quot;&gt;24&lt;/property&gt;&lt;/function&gt; 配置说明: 属性 描述 columns 标识将要分片的表字段 ； 字符串类型（yyyymmddHH）， 需要符合JAVA标准 algorithm 指定分片函数与function的对应关系 splitOneDay 一天切分的分片数 自然月分片算法使用场景为按照月份列分区, 每个自然月为一个分片, 配置如下: 123456789101112&lt;tableRule name=&quot;sharding-by-month&quot;&gt; &lt;rule&gt; &lt;columns&gt;create_time&lt;/columns&gt; &lt;algorithm&gt;sharding-by-month&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt;&lt;function name=&quot;sharding-by-month&quot; class=&quot;io.mycat.route.function.PartitionByMonth&quot;&gt; &lt;property name=&quot;dateFormat&quot;&gt;yyyy-MM-dd&lt;/property&gt; &lt;property name=&quot;sBeginDate&quot;&gt;2020-01-01&lt;/property&gt; &lt;property name=&quot;sEndDate&quot;&gt;2020-12-31&lt;/property&gt;&lt;/function&gt; 配置说明: 属性 描述 columns 标识将要分片的表字段 algorithm 指定分片函数与function的对应关系 class 指定该分片算法对应的类 dateFormat 日期格式 sBeginDate 开始日期 sEndDate 结束日期，如果配置了结束日期，则代码数据到达了这个日期的分片后，会重复从开始分片插入 日期范围hash算法其思想和范围取模分片一样，先根据日期进行范围分片求出分片组，再根据时间hash使得短期内数据分布的更均匀 ; 优点 : 可以避免扩容时的数据迁移，又可以一定程度上避免范围分片的热点问题 注意 : 要求日期格式尽量精确些，不然达不到局部均匀的目的 12345678910111213&lt;tableRule name=&quot;range-date-hash&quot;&gt; &lt;rule&gt; &lt;columns&gt;create_time&lt;/columns&gt; &lt;algorithm&gt;range-date-hash&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt;&lt;function name=&quot;range-date-hash&quot; class=&quot;io.mycat.route.function.PartitionByRangeDateHash&quot;&gt; &lt;property name=&quot;dateFormat&quot;&gt;yyyy-MM-dd HH:mm:ss&lt;/property&gt; &lt;property name=&quot;sBeginDate&quot;&gt;2020-01-01 00:00:00&lt;/property&gt; &lt;property name=&quot;groupPartionSize&quot;&gt;6&lt;/property&gt; &lt;property name=&quot;sPartionDay&quot;&gt;10&lt;/property&gt;&lt;/function&gt; 配置说明: 属性 描述 columns 标识将要分片的表字段 algorithm 指定分片函数与function的对应关系 class 指定该分片算法对应的类 dateFormat 日期格式 , 符合Java标准 sBeginDate 开始日期 , 与 dateFormat指定的格式一致 groupPartionSize 每组的分片数量 sPartionDay 代表多少天为一组","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://zsc-cloud.github.io/categories/MySQL/"},{"name":"MyCat","slug":"MySQL/MyCat","permalink":"https://zsc-cloud.github.io/categories/MySQL/MyCat/"}],"tags":[{"name":"MyCat","slug":"MyCat","permalink":"https://zsc-cloud.github.io/tags/MyCat/"},{"name":"分库分表","slug":"分库分表","permalink":"https://zsc-cloud.github.io/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"}]},{"title":"TCP三次握手","slug":"TCP三次握手","date":"2021-06-25T01:12:39.000Z","updated":"2022-03-26T03:42:17.265Z","comments":true,"path":"2021/06/24/TCP三次握手/","link":"","permalink":"https://zsc-cloud.github.io/2021/06/24/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B/","excerpt":"","text":"握手的过程1、第一次握手：客户端给服务器发送一个 SYN 报文。 2、第二次握手：服务器收到 SYN 报文之后，会应答一个 SYN+ACK 报文。 3、第三次握手：客户端收到 SYN+ACK 报文之后，会回应一个 ACK 报文。 4、服务器收到 ACK 报文之后，三次握手建立完成。 为什么需要三次握手而不是两次第一次握手：客户端发送网络包，服务端收到了。这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。 第二次握手：服务端发包，客户端收到了。这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。不过此时服务器并不能确认客户端的接收能力是否正常。 第三次握手：客户端发包，服务端收到了。这样服务端就能得出结论：客户端的接收、发送能力正常，服务器自己的发送、接收能力也正常。 因此，需要三次握手才能确认双方的接收与发送能力是否正常。 三次握手的具体描述1、第一次握手：客户端给服务端发一个 SYN 报文，并指明客户端的初始化序列号 **SN(c)**。此时客户端处于 SYN_Send 状态。 2、第二次握手：服务器收到客户端的 SYN 报文之后，会以自己的 SYN 报文作为应答，并且也是指定了自己的初始化序列号 ISN(s)，同时会把客户端的 ISN + 1 作为 ACK 的值，表示自己已经收到了客户端的 SYN，此时服务器处于 SYN_REVD 的状态。 3、第三次握手：客户端收到 SYN 报文之后，会发送一个 ACK 报文，当然，也是一样把服务器的 ISN + 1 作为 ACK 的值，表示已经收到了服务端的 SYN 报文，此时客户端处于 establised 状态。 4、服务器收到 ACK 报文之后，也处于 establised 状态，此时，双方以建立起了链接。 三次握手的作用1、确认双方的接受能力、发送能力是否正常。 2、指定自己的初始化序列号，为后面的可靠传送做准备。 （ISN）是固定的吗三次握手的一个重要功能是客户端和服务端交换ISN(Initial Sequence Number), 以便让对方知道接下来接收数据的时候如何按序列号组装数据。 如果ISN是固定的，攻击者很容易猜出后续的确定号，因此 ISN 是动态生成的 半连接队列服务器第一次收到客户端的 SYN 之后，就会处于 SYN_RCVD 状态，此时双方还没有完全建立其连接，服务器会把此种状态下请求连接放在一个队列里，我们把这种队列称之为半连接队列。当然还有一个全连接队列，就是已经完成三次握手，建立起连接的就会放在全连接队列中。如果队列满了就有可能会出现丢包现象。 这里在补充一点关于SYN-ACK 重传次数的问题： 服务器发送完SYN－ACK包，如果未收到客户确认包，服务器进行首次重传，等待一段时间仍未收到客户确认包，进行第二次重传，如果重传次数超 过系统规定的最大重传次数，系统将该连接信息从半连接队列中删除。注意，每次重传等待的时间不一定相同，一般会是指数增长，例如间隔时间为 1s, 2s, 4s, 8s, …. 三次握手过程中可以携带数据吗很多人可能会认为三次握手都不能携带数据，其实第三次握手的时候，是可以携带数据的。也就是说，第一次、第二次握手不可以携带数据，而第三次握手是可以携带数据的。 为什么这样呢？大家可以想一个问题，假如第一次握手可以携带数据的话，如果有人要恶意攻击服务器，那他每次都在第一次握手中的 SYN 报文中放入大量的数据，因为攻击者根本就不理服务器的接收、发送能力是否正常，然后疯狂着重复发 SYN 报文的话，这会让服务器花费很多时间、内存空间来接收这些报文。也就是说，第一次握手可以放数据的话，其中一个简单的原因就是会让服务器更加容易受到攻击了。 而对于第三次的话，此时客户端已经处于 established 状态，也就是说，对于客户端来说，他已经建立起连接了，并且也已经知道服务器的接收、发送能力是正常的了，所以能携带数据页没啥毛病。","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://zsc-cloud.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://zsc-cloud.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"TCP四次挥手","slug":"TCP四次挥手","date":"2021-06-25T01:12:39.000Z","updated":"2022-03-26T03:42:17.403Z","comments":true,"path":"2021/06/24/TCP四次挥手/","link":"","permalink":"https://zsc-cloud.github.io/2021/06/24/TCP%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/","excerpt":"","text":"四次挥手过程刚开始双方都处于 establised 状态，假如是客户端先发起关闭请求，则： 1、第一次挥手：客户端发送一个 FIN 报文，报文中会指定一个序列号。此时客户端处于FIN_WAIT1状态。 2、第二次握手：服务端收到 FIN 之后，会发送 ACK 报文，且把客户端的序列号值 + 1 作为 ACK 报文的序列号值，表明已经收到客户端的报文了，此时服务端处于 CLOSE_WAIT状态。 3、第三次挥手：如果服务端也想断开连接了，和客户端的第一次挥手一样，发给 FIN 报文，且指定一个序列号。此时服务端处于 LAST_ACK 的状态。 4、第四次挥手：客户端收到 FIN 之后，一样发送一个 ACK 报文作为应答，且把服务端的序列号值 + 1 作为自己 ACK 报文的序列号值，此时客户端处于 TIME_WAIT 状态。需要过一阵子以确保服务端收到自己的 ACK 报文之后才会进入 CLOSED 状态 5、服务端收到 ACK 报文之后，就处于关闭连接了，处于 CLOSED 状态。 这里特别需要主要的就是TIME_WAIT这个状态了，这个是面试的高频考点，就是要理解，为什么客户端发送 ACK 之后不直接关闭，而是要等一阵子才关闭。这其中的原因就是，要确保服务器是否已经收到了我们的 ACK 报文，如果没有收到的话，服务器会重新发 FIN 报文给客户端，客户端再次收到 ACK 报文之后，就知道之前的 ACK 报文丢失了，然后再次发送 ACK 报文。 至于 TIME_WAIT 持续的时间至少是一个报文的来回时间。一般会设置一个计时，如果过了这个计时没有再次收到 FIN 报文，则代表对方成功就是 ACK 报文，此时处于 CLOSED 状态。 LISTEN – 侦听来自远方TCP端口的连接请求； SYN-SENT -在发送连接请求后等待匹配的连接请求； SYN-RECEIVED – 在收到和发送一个连接请求后等待对连接请求的确认； ESTABLISHED- 代表一个打开的连接，数据可以传送给用户； FIN-WAIT-1 – 等待远程TCP的连接中断请求，或先前的连接中断请求的确认； FIN-WAIT-2 – 从远程TCP等待连接中断请求； CLOSE-WAIT – 等待从本地用户发来的连接中断请求； CLOSING -等待远程TCP对连接中断的确认； LAST-ACK – 等待原来发向远程TCP的连接中断请求的确认； TIME-WAIT -等待足够的时间以确保远程TCP接收到连接中断请求的确认； CLOSED – 没有任何连接状态；","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://zsc-cloud.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://zsc-cloud.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"网络五层模型","slug":"计算机网络五层模型","date":"2021-06-25T01:12:39.000Z","updated":"2022-03-26T03:42:17.245Z","comments":true,"path":"2021/06/24/计算机网络五层模型/","link":"","permalink":"https://zsc-cloud.github.io/2021/06/24/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%BA%94%E5%B1%82%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"前言 天各一方的两台计算机是如何通信的呢？在成千上万的计算机中，为什么一台计算机能够准确的寻找到另外一台计算机，并且把数据发送给它呢？ 可能很多人都听说过网络通信的 5 层模型，但是可能并不是很清楚为什么需要五层模型，五层模型负责的任务也有可能经常混淆。下面是网络通信的五层模型 1. 物理层一台计算机与另一台计算机要进行通信，第一件要做的事是什么？当然是把这台计算机与另外的其他计算机连起来。这样，我们才能把数据传输过去。例如可以通过光纤，电缆，双绞线等介质把他们连接起来。然后才能进行通信。 也就是说，物理层负责把两台计算机连起来，然后在计算机之间通过高低电频来传送0,1这样的电信号。 2. 数据链路层前面说了，物理层它只是单纯的负责把计算机连接起来。并且在计算机之间传输0，1这样的电信号。如果是这些0，1组合的传送毫无规则的话，计算机是解读不了的，一大堆0,1谁知道是什么东西。 因此，我们需要制定一套规则来进行0,1的传送。例如多少个电信号为一组，每一组信号应该如何标识才能让计算机读懂等等。 于是，有了以太网协议。 1. 以太网协议以太网协议规定，一组电信号构成一个数据包，我们把这个数据包称之为帧。每一个帧由标头（Head）和数据（Data）两部分组成。 帧的大小一般为 64 – 1518 个字节。假如需要传送的数据很大的话，就分成多个桢来进行传送。 对于表头和数据这两个部分，他们存放的都是一些什么数据呢？我猜你眯着眼睛都能想到他们应该放什么数据。 毫无疑问，我们至少得知道这个桢是谁发送，发送给谁的等这些信息吧？所以标头部分主要是一些说明数据，例如发送者，接收者等信息。而数据部分则是这个数据包具体的，想给接守者的内容。 大家想一个问题，一个桢的长度是 64~1518 个字节，也就是说桢的长度不是固定的，那你觉得标头部分的字节长度是固定的吗？它当然是固定的啊，假如不是固定的，每个桢都是单独发的，那计算机怎么知道标头是几个字节，数据是几个字节呢。所以标头部分的字节是固定的，并且固定为18个字节。 把一台计算的的数据通过物理层和链路层发送给另一台计算机，究竟是谁发给谁的，计算机与计算机之间如何区分，，你总得给他们一个唯一的标识吧？ 于是，MAC 地址出现了。 2. MAC 地址连入网络的每一个计算机都会有网卡接口，每一个网卡都会有一个唯一的地址，这个地址就叫做 MAC 地址。计算机之间的数据传送，就是通过 MAC 地址来唯一寻找、传送的。 MAC地址 由 6 个字节（48位）所构成，在网卡生产时就被唯一标识了。 3. 广播与ARP协议广播 如图，假如计算机 A 知道了计算机 B 的 MAC 地址，然后计算机 A 想要给计算机 B 传送数据，虽然计算机 A 知道了计算机 B 的 MAC 地址，可是它要怎么给它传送数据呢？计算机 A 不仅连着计算机 B，而且计算机 A 也还连着其他的计算机。 虽然计算机 A 知道计算机 B 的 MAC 地址，可是计算机 A 却不知道知道计算机 B 是分布在哪边路线上，为了解决这个问题，于是，有了广播的出现。 在同一个子网中，计算机 A 要向计算机 B 发送一个数据包，这个数据包会包含接收者的 MAC 地址。当发送时，计算机 A 是通过广播的方式发送的，这时同一个子网中的计算机 C, D 也会收到这个数据包的，然后收到这个数据包的计算机，会把数据包的 MAC 地址取出来，与自身的 MAC 地址对比，如果两者相同，则接受这个数据包，否则就丢弃这个数据包。这种发送方式我们称之为广播,就像我们平时在广场上通过广播的形式呼叫某个人一样，如果这个名字是你，你就理会一下，如果不是你，你就当作听不见。 ARP 协议那么问题来了，计算机 A 是如何知道计算机 B 的 MAC 地址的呢？这个时候就得由 ARP 协议这个家伙来解决了，不过 ARP 协议会涉及到IP地址，我们下面才会扯到IP地址。因此我们先放着，就当作是有这么一个 ARP 协议，通过它我们可以知道子网中其他计算机的 MAC 地址。 3. 网络层上面我们有说到子网这个关键词，实际上我们所处的网络，是由无数个子网络构成的。广播的时候，也只有同一个子网里面的计算机能够收到。 假如没有子网这种划分的话，计算机 A 通过广播的方式发一个数据包给计算机 B , 其他所有计算机也都能收到这个数据包，然后进行对比再舍弃。世界上有那么多它计算机，每一台计算机都能收到其他所有计算机的数据包，那就不得了了。那还不得奔溃。 因此产生了子网这么一个东西。 那么问题来了，我们如何区分哪些 MAC 地址是属于同一个子网的呢？假如是同一个子网，那我们就用广播的形式把数据传送给对方，如果不是同一个子网的，我们就会把数据发给网关，让网关进行转发。 为了解决这个问题，于是，有了 IP 协议。 1. IP协议IP协议，它所定义的地址，我们称之为IP地址。IP协议有两种版本，一种是 IPv4,另一种是 IPv6。不过我们目前大多数用的还是 IPv4，我们现在也只讨论 IPv4 这个版本的协议。 这个 IP 地址由 32 位的二进制数组成，我们一般把它分成4段的十进制表示，地址范围为0.0.0.0~255.255.255.255。 每一台想要联网的计算机都会有一个IP地址。这个IP地址被分为两部分，前面一部分代表网络部分，后面一部分代表主机部分。并且网络部分和主机部分所占用的二进制位数是不固定的。 假如两台计算机的网络部分是一模一样的，我们就说这两台计算机是处于同一个子网中。例如 192.168.43.1 和 192.168.43.2, 假如这两个 IP 地址的网络部分为 24 位，主机部分为 8 位。那么他们的网络部分都为 192.168.43，所以他们处于同一个子网中。 可是问题来了，你怎么知道网络部分是占几位，主机部分又是占几位呢？也就是说，单单从两台计算机的IP地址，我们是无法判断他们的是否处于同一个子网中的。 这就引申出了另一个关键词————子网掩码。子网掩码和IP地址一样也是 32 位二进制数，不过它的网络部分规定全部为 1，主机部分规定全部为 0.也就是说，假如上面那两个IP地址的网络部分为 24 位，主机部分为 8 位的话，那他们的子网掩码都为 11111111.11111111.11111111.00000000，即255.255.255.0。 那有了子网掩码，如何来判端IP地址是否处于同一个子网中呢。显然，知道了子网掩码，相当于我们知道了网络部分是几位，主机部分是几位。我们只需要把 IP 地址与它的子网掩码做与(and)运算，然后把各自的结果进行比较就行了，如果比较的结果相同，则代表是同一个子网，否则不是同一个子网。 例如，192.168.43.1和192.168.43.2的子码掩码都为255.255.255.0，把IP与子码掩码相与，可以得到他们都为192.168.43.0，进而他们处于同一个子网中。 2. ARP协议有了上面IP协议的知识，我们回来讲一下ARP协议。 有了两台计算机的IP地址与子网掩码，我们就可以判断出它们是否处于同一个子网之中了。 假如他们处于同一个子网之中，计算机A要给计算机B发送数据时。我们可以通过ARP协议来得到计算机B的MAC地址。 ARP协议也是通过广播的形式给同一个子网中的每台电脑发送一个数据包(当然，这个数据包会包含接收方的IP地址)。对方收到这个数据包之后，会取出IP地址与自身的对比，如果相同，则把自己的MAC地址回复给对方，否则就丢弃这个数据包。这样，计算机A就能知道计算机B的MAC地址了。 可能有人会问，知道了MAC地址之后，发送数据是通过广播的形式发送，询问对方的MAC地址也是通过广播的形式来发送，那其他计算机怎么知道你是要传送数据还是要询问MAC地址呢？其实在询问MAC地址的数据包中，在对方的MAC地址这一栏中，填的是一个特殊的MAC地址，其他计算机看到这个特殊的MAC地址之后，就能知道广播想干嘛了。 假如两台计算机的IP不是处于同一个子网之中，这个时候，我们就会把数据包发送给网关，然后让网关让我们进行转发传送 DNS服务器这里再说一个问题，我们是如何知道对方计算机的IP地址的呢？这个问题可能有人会觉得很白痴，心想，当然是计算机的操作者来进行输入了。这没错，当我们想要访问某个网站的时候，我们可以输入IP来进行访问，但是我相信绝大多数人是输入一个网址域名的，例如访问百度是输入 www.baidu.com 这个域名。其实当我们输入这个域名时，会有一个叫做DNS服务器的家伙来帮我们解析这个域名，然后返回这个域名对应的IP给我们的。 因此，网络层的功能就是让我们在茫茫人海中，能够找到另一台计算机在哪里，是否属于同一个子网等。 4. 传输层通过物理层、数据链路层以及网络层的互相帮助，我们已经把数据成功从计算机A传送到计算机B了，可是，计算机B里面有各种各样的应用程序，计算机该如何知道这些数据是给谁的呢？ 这个时候，**端口(Port)**这个家伙就上场了，也就是说，我们在从计算机A传数据给计算表B的时候，还得指定一个端口，以供特定的应用程序来接受处理。 也就是说，传输层的功能就是建立端口到端口的通信。相比网络层的功能是建立主机到主机的通信。 也就是说，只有有了IP和端口，我们才能进行准确着通信。这个时候可能有人会说，我输入IP地址的时候并没有指定一个端口啊。其实呢，对于有些传输协议，已经有设定了一些默认端口了。例如http的传输默认端口是80，这些端口信息也会包含在数据包里的。 传输层最常见的两大协议是 TCP 协议和 UDP 协议，其中 TCP 协议与 UDP 最大的不同就是 TCP 提供可靠的传输，而 UDP 提供的是不可靠传输。 5. 应用层终于说到应用层了，应用层这一层最接近我们用户了。 虽然我们收到了传输层传来的数据，可是这些传过来的数据五花八门，有html格式的，有mp4格式的，各种各样。你确定你能看的懂？ 因此我们需要指定这些数据的格式规则，收到后才好解读渲染。例如我们最常见的 Http 数据包中，就会指定该数据包是 什么格式的文件了。","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://zsc-cloud.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://zsc-cloud.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"MyCat(五)---性能监控","slug":"MyCat(五)---性能监控","date":"2021-06-23T20:41:11.000Z","updated":"2022-03-26T03:42:17.442Z","comments":true,"path":"2021/06/23/MyCat(五)---性能监控/","link":"","permalink":"https://zsc-cloud.github.io/2021/06/23/MyCat(%E4%BA%94)---%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/","excerpt":"","text":"MyCat 性能监控MyCat-web简介Mycat-web 是 Mycat 可视化运维的管理和监控平台，弥补了 Mycat 在监控上的空白。帮 Mycat 分担统计任务和配置管理任务。Mycat-web 引入了 ZooKeeper 作为配置中心，可以管理多个节点。Mycat-web 主要管理和监控 Mycat 的流量、连接、活动线程和内存等，具备 IP 白名单、邮件告警等模块，还可以统计 SQL 并分析慢 SQL 和高频 SQL 等。为优化 SQL 提供依据。 MyCat-web下载下载地址 : http://dl.mycat.io/ Mycat-web安装配置安装1). 安装Zookeeper 1234567891011121314151617A. 上传安装包 alt + p -----&gt; put D:\\tmp\\zookeeper-3.4.11.tar.gz B. 解压 tar -zxvf zookeeper-3.4.11.tar.gz -C /usr/local/C. 创建数据存放目录 mkdir dataD. 修改配置文件名称并配置 mv zoo_sample.cfg zoo.cfgE. 配置数据存放目录 dataDir=/usr/local/zookeeper-3.4.11/data F. 启动Zookeeper bin/zkServer.sh start 2). 安装Mycat-web 12345678910111213141516171819A. 上传安装包 alt + p --------&gt; put D:\\tmp\\Mycat-web-1.0-SNAPSHOT-20170102153329-linux.tar.gz B. 解压 tar -zxvf Mycat-web-1.0-SNAPSHOT-20170102153329-linux.tar.gz -C /usr/local/C. 目录介绍 drwxr-xr-x. 2 root root 4096 Oct 19 2015 etc ----&gt; jetty配置文件 drwxr-xr-x. 3 root root 4096 Oct 19 2015 lib ----&gt; 依赖jar包 drwxr-xr-x. 7 root root 4096 Jan 1 2017 mycat-web ----&gt; mycat-web项目 -rwxr-xr-x. 1 root root 116 Oct 19 2015 readme.txt -rwxr-xr-x. 1 root root 17125 Oct 19 2015 start.jar ----&gt; 启动jar -rwxr-xr-x. 1 root root 381 Oct 19 2015 start.sh ----&gt; linux启动脚本D. 启动 sh start.sh E. 访问 http://192.168.192.147:8082/mycat 如果Zookeeper与Mycat-web不在同一台服务器上 , 需要设置Zookeeper的地址 ; 在/usr/local/mycat-web/mycat-web/WEB-INF/classes/mycat.properties文件中配置 : 配置 Mycat-web之MyCat性能监控在 Mycat-web 上可以进行 Mycat 性能监控，例如：内存分享、流量分析、连接分析、活动线程分析等等。 如下图: A. MyCat内存分析: MyCat的内存分析 , 反映了当前的内存使用情况与历史时间段的峰值、平均值。 B. MyCat流量分析: MyCat流量分析统计了历史时间段的流量峰值、当前值、平均值，是MyCat数据传输的重要指标， In代表输入， Out代表输出。 C. MyCat连接分析 MyCat连接分析, 反映了MyCat的连接数 D. MyCat TPS分析 MyCat TPS 是并发性能的重要参数指标, 指系统在每秒内能够处理的请求数量。 MyCat TPS的值越高 , 代表MyCat单位时间内能够处理的请求就越多, 并发能力也就越高。 E. MyCat活动线程分析反映了MyCat线程的活动情况。 F. MyCat缓存队列分析, 反映了当前在缓存队列中的任务数量。 Mycat-web之MySQL性能监控指标1). MySQL配置 2). MySQL监控指标 可以通过MySQL服务监控, 检测每一个MySQL节点的运行状态, 包含缓存命中率 、增删改查比例、流量统计、慢查询比例、线程、临时表等相关性能数据。 Mycat-web之SQL监控1). SQL 统计 2). SQL表分析 3). SQL监控 4). 高频SQL 5). 慢SQL统计 6). SQL解析","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://zsc-cloud.github.io/categories/MySQL/"},{"name":"MyCat","slug":"MySQL/MyCat","permalink":"https://zsc-cloud.github.io/categories/MySQL/MyCat/"}],"tags":[{"name":"MyCat","slug":"MyCat","permalink":"https://zsc-cloud.github.io/tags/MyCat/"},{"name":"分库分表","slug":"分库分表","permalink":"https://zsc-cloud.github.io/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"}]},{"title":"MyCat(六)---读写分离","slug":"MyCat(六)---读写分离","date":"2021-06-22T20:41:11.000Z","updated":"2022-03-26T03:42:17.373Z","comments":true,"path":"2021/06/22/MyCat(六)---读写分离/","link":"","permalink":"https://zsc-cloud.github.io/2021/06/22/MyCat(%E5%85%AD)---%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB/","excerpt":"","text":"MySQL主从复制原理复制是指将主数据库的DDL 和 DML 操作通过二进制日志传到从库服务器中，然后在从库上对这些日志重新执行（也叫重做），从而使得从库和主库的数据保持同步。 MySQL支持一台主库同时向多台从库进行复制， 从库同时也可以作为其他从服务器的主库，实现链状复制。 MySQL主从复制的原理如下 : 从上层来看，复制分成三步： Master 主库在事务提交时，会把数据变更作为时间 Events 记录在二进制日志文件 Binlog 中。 主库推送二进制日志文件 Binlog 中的日志事件到从库的中继日志 Relay Log 。 slave重做中继日志中的事件，将改变反映它自己的数据。 MySQL 复制的优点： 主库出现问题，可以快速切换到从库提供服务。 可以在从库上执行查询操作，从主库中更新，实现读写分离，降低主库的访问压力。 可以在从库中执行备份，以避免备份期间影响主库的服务。 MySQL一主一从搭建准备的两台机器: MySQL IP 端口号 Master 192.168.192.157 3306 Slave 192.168.192.158 3306 master1） 在master 的配置文件（/usr/my.cnf）中，配置如下内容： 1234567891011121314151617#mysql 服务ID,保证整个集群环境中唯一server-id=1#mysql binlog 日志的存储路径和文件名log-bin=/var/lib/mysql/mysqlbin#设置logbin格式binlog_format=STATEMENT#是否只读,1 代表只读, 0 代表读写read-only=0#忽略的数据, 指不需要同步的数据库#binlog-ignore-db=mysql#指定同步的数据库binlog-do-db=db01 2） 执行完毕之后，需要重启Mysql： 1service mysql restart ; 3） 创建同步数据的账户，并且进行授权操作： 123grant replication slave on *.* to &#x27;itcast&#x27;@&#x27;192.168.192.158&#x27; identified by &#x27;itcast&#x27;; flush privileges; 4） 查看master状态： 1show master status; 字段含义: 123File : 从哪个日志文件开始推送日志文件 Position ： 从哪个位置开始推送日志Binlog_Ignore_DB : 指定不需要同步的数据库 slave1） 在 slave 端配置文件/usr/my.cnf中，配置如下内容： 12345678#mysql服务端ID,唯一server-id=2#指定binlog日志log-bin=/var/lib/mysql/mysqlbin#启用中继日志relay-log=mysql-relay 2） 执行完毕之后，需要重启Mysql： 1service mysql restart; 3） 执行如下指令 ： 1change master to master_host= &#x27;192.168.192.157&#x27;, master_user=&#x27;itcast&#x27;, master_password=&#x27;itcast&#x27;, master_log_file=&#x27;mysqlbin.000001&#x27;, master_log_pos=413; 指定当前从库对应的主库的IP地址，用户名，密码，从哪个日志文件开始的那个位置开始同步推送日志。 4） 开启同步操作 123start slave;show slave status; 5） 停止同步操作 1stop slave; 验证主从同步1） 在主库中创建数据库，创建表，并插入数据 ： 1234567891011121314create database db01;user db01;create table user( id int(11) not null auto_increment, name varchar(50) not null, sex varchar(1), primary key (id))engine=innodb default charset=utf8;insert into user(id,name,sex) values(null,&#x27;Tom&#x27;,&#x27;1&#x27;);insert into user(id,name,sex) values(null,&#x27;Trigger&#x27;,&#x27;0&#x27;);insert into user(id,name,sex) values(null,&#x27;Dawn&#x27;,&#x27;1&#x27;); 2） 在从库中查询数据，进行验证 ： 在从库中，可以查看到刚才创建的数据库： 在该数据库中，查询user表中的数据： MyCat一主一从读写分离读写分离原理 读写分离,简单地说是把对数据库的读和写操作分开,以对应不同的数据库服务器。主数据库提供写操作，从数据库提供读操作，这样能有效地减轻单台数据库的压力。 通过MyCat即可轻易实现上述功能，不仅可以支持MySQL，也可以支持Oracle和SQL Server。 MyCat控制后台数据库的读写分离和负载均衡由schema.xml文件datahost标签的balance属性控制。 读写分离配置配置如下： 1). 检查MySQL的主从复制是否运行正常 . 2). 修改MyCat 的conf/schema.xml 配置如下: 1234567891011121314151617&lt;?xml version=&quot;1.0&quot;?&gt;&lt;!DOCTYPE mycat:schema SYSTEM &quot;schema.dtd&quot;&gt;&lt;mycat:schema xmlns:mycat=&quot;http://io.mycat/&quot;&gt; &lt;schema name=&quot;ITCAST&quot; checkSQLschema=&quot;true&quot; sqlMaxLimit=&quot;100&quot;&gt; &lt;table name=&quot;user&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;id&quot;/&gt; &lt;/schema&gt; &lt;dataNode name=&quot;dn1&quot; dataHost=&quot;localhost1&quot; database=&quot;db01&quot; /&gt; &lt;dataHost name=&quot;localhost1&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;1&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=&quot;hostM1&quot; url=&quot;192.168.192.157:3306&quot; user=&quot;root&quot; password=&quot;itcast&quot;&gt; &lt;readHost host=&quot;hostS1&quot; url=&quot;192.168.192.158:3306&quot; user=&quot;root&quot; password=&quot;itcast&quot; /&gt; &lt;/writeHost&gt; &lt;/dataHost&gt; &lt;/mycat:schema&gt; 3). 修改conf/server.xml 123456789101112131415&lt;user name=&quot;root&quot; defaultAccount=&quot;true&quot;&gt; &lt;property name=&quot;password&quot;&gt;123456&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;ITCAST&lt;/property&gt;&lt;/user&gt;&lt;user name=&quot;test&quot;&gt; &lt;property name=&quot;password&quot;&gt;123456&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;ITCAST&lt;/property&gt;&lt;/user&gt;&lt;user name=&quot;user&quot;&gt; &lt;property name=&quot;password&quot;&gt;123456&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;ITCAST&lt;/property&gt; &lt;property name=&quot;readOnly&quot;&gt;true&lt;/property&gt;&lt;/user&gt; 4). 配置完毕之后, 重启MyCat服务; 属性含义说明: 1234567891011121314checkSQLschema 当该值设置为true时, 如果我们执行语句&quot;select * from test01.user ;&quot; 语句时, MyCat则会把schema字符去掉 , 可以避免后端数据库执行时报错 ; balance 负载均衡类型, 目前取值有4种: balance=&quot;0&quot; : 不开启读写分离机制 , 所有读操作都发送到当前可用的writeHost上. balance=&quot;1&quot; : 全部的readHost 与 stand by writeHost (备用的writeHost) 都参与select 语句的负载均衡,简而言之,就是采用双主双从模式(M1 --&gt; S1 , M2 --&gt; S2, 正常情况下，M2,S1,S2 都参与 select 语句的负载均衡。); balance=&quot;2&quot; : 所有的读写操作都随机在writeHost , readHost上分发 balance=&quot;3&quot; : 所有的读请求随机分发到writeHost对应的readHost上执行, writeHost不负担读压力 ;balance=3 只在MyCat1.4 之后生效 . 验证读写分离修改balance的值, 查询MyCat中的逻辑表中的数据变化; MySQL双主双从搭建架构一个主机 Master1 用于处理所有写请求，它的从机 Slave1 和另一台主机 Master2 还有它的从机 Slave2 负责所有读请求。当 Master1 主机宕机后，Master2 主机负责写请求，Master1 、Master2 互为备机。架构图如下: 双主双从配置准备的机器如下: 编号 角色 IP地址 端口号 1 Master1 192.168.192.157 3306 2 Slave1 192.168.192.158 3306 3 Master2 192.168.192.159 3306 4 Slave2 192.168.192.160 3306 1). 双主机配置 Master1配置: 1234567891011121314151617181920#主服务器唯一IDserver-id=1#启用二进制日志log-bin=mysql-bin# 设置不要复制的数据库(可设置多个)# binlog-ignore-db=mysql# binlog-ignore-db=information_schema#设置需要复制的数据库binlog-do-db=db02binlog-do-db=db03binlog-do-db=db04#设置logbin格式binlog_format=STATEMENT# 在作为从数据库的时候，有写入操作也要更新二进制日志文件log-slave-updates Master2配置: 1234567891011121314151617181920#主服务器唯一IDserver-id=3#启用二进制日志log-bin=mysql-bin# 设置不要复制的数据库(可设置多个)#binlog-ignore-db=mysql#binlog-ignore-db=information_schema#设置需要复制的数据库binlog-do-db=db02binlog-do-db=db03binlog-do-db=db04#设置logbin格式binlog_format=STATEMENT# 在作为从数据库的时候，有写入操作也要更新二进制日志文件log-slave-updates 2). 双从机配置 Slave1配置: 12345#从服务器唯一IDserver-id=2#启用中继日志relay-log=mysql-relay Salve2配置: 12345#从服务器唯一IDserver-id=4#启用中继日志relay-log=mysql-relay 3). 双主机、双从机重启 mysql 服务 4). 主机从机都关闭防火墙 5). 在两台主机上建立帐户并授权 slave 1234#在主机MySQL里执行授权命令GRANT REPLICATION SLAVE ON *.* TO &#x27;itcast&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;itcast&#x27;;flush privileges; 查询Master1的状态 : 查询Master2的状态 : 6). 在从机上配置需要复制的主机 Slave1 复制 Master1，Slave2 复制 Master2 slave1 指令: 1234CHANGE MASTER TO MASTER_HOST=&#x27;192.168.192.157&#x27;,MASTER_USER=&#x27;itcast&#x27;,MASTER_PASSWORD=&#x27;itcast&#x27;,MASTER_LOG_FILE=&#x27;mysql-bin.000001&#x27;,MASTER_LOG_POS=409; slave2 指令: 1234CHANGE MASTER TO MASTER_HOST=&#x27;192.168.192.159&#x27;,MASTER_USER=&#x27;itcast&#x27;,MASTER_PASSWORD=&#x27;itcast&#x27;,MASTER_LOG_FILE=&#x27;mysql-bin.000001&#x27;,MASTER_LOG_POS=409; 7). 启动两台从服务器复制功能 , 查看主从复制的运行状态 123start slave;show slave status\\G; 8). 两个主机互相复制 Master2 复制 Master1，Master1 复制 Master2 Master1 执行指令: 1234CHANGE MASTER TO MASTER_HOST=&#x27;192.168.192.159&#x27;,MASTER_USER=&#x27;itcast&#x27;,MASTER_PASSWORD=&#x27;itcast&#x27;,MASTER_LOG_FILE=&#x27;mysql-bin.000001&#x27;,MASTER_LOG_POS=409; Master2 执行指令: 1234CHANGE MASTER TO MASTER_HOST=&#x27;192.168.192.157&#x27;,MASTER_USER=&#x27;itcast&#x27;,MASTER_PASSWORD=&#x27;itcast&#x27;,MASTER_LOG_FILE=&#x27;mysql-bin.000001&#x27;,MASTER_LOG_POS=409; 9). 启动两台主服务器复制功能 , 查看主从复制的运行状态 123start slave;show slave status\\G; 10). 验证 12345678910111213141516171819create database db03;use db03;create table user( id int(11) not null auto_increment, name varchar(50) not null, sex varchar(1), primary key (id))engine=innodb default charset=utf8;insert into user(id,name,sex) values(null,&#x27;Tom&#x27;,&#x27;1&#x27;);insert into user(id,name,sex) values(null,&#x27;Trigger&#x27;,&#x27;0&#x27;);insert into user(id,name,sex) values(null,&#x27;Dawn&#x27;,&#x27;1&#x27;);insert into user(id,name,sex) values(null,&#x27;Jack Ma&#x27;,&#x27;1&#x27;);insert into user(id,name,sex) values(null,&#x27;Coco&#x27;,&#x27;0&#x27;);insert into user(id,name,sex) values(null,&#x27;Jerry&#x27;,&#x27;1&#x27;); 在Master1上创建数据库: 在Master1上创建表 : 11). 停止从服务复制功能 1stop slave; 12). 重新配置主从关系 12stop slave;reset master; MyCat双主双从读写分离配置修改&lt;dataHost&gt;的 balance属性，通过此属性配置读写分离的类型 ; 1234567891011121314151617181920212223&lt;?xml version=&quot;1.0&quot;?&gt;&lt;!DOCTYPE mycat:schema SYSTEM &quot;schema.dtd&quot;&gt;&lt;mycat:schema xmlns:mycat=&quot;http://io.mycat/&quot;&gt; &lt;schema name=&quot;ITCAST&quot; checkSQLschema=&quot;true&quot; sqlMaxLimit=&quot;100&quot;&gt; &lt;table name=&quot;user&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;id&quot;/&gt; &lt;/schema&gt; &lt;dataNode name=&quot;dn1&quot; dataHost=&quot;localhost1&quot; database=&quot;db03&quot; /&gt; &lt;dataHost name=&quot;localhost1&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;1&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=&quot;hostM1&quot; url=&quot;192.168.192.147:3306&quot; user=&quot;root&quot; password=&quot;itcast&quot;&gt; &lt;readHost host=&quot;hostS1&quot; url=&quot;192.168.192.149:3306&quot; user=&quot;root&quot; password=&quot;itcast&quot; /&gt; &lt;/writeHost&gt; &lt;writeHost host=&quot;hostM2&quot; url=&quot;192.168.192.150:3306&quot; user=&quot;root&quot; password=&quot;itcast&quot;&gt; &lt;readHost host=&quot;hostS2&quot; url=&quot;192.168.192.151:3306&quot; user=&quot;root&quot; password=&quot;itcast&quot; /&gt; &lt;/writeHost&gt; &lt;/dataHost&gt; &lt;/mycat:schema&gt; 1). balance 1 : 代表 全部的 readHost 与 stand by writeHost 参与 select 语句的负载均衡，简单的说，当双主双从模式(M1-&gt;S1，M2-&gt;S2，并且 M1 与 M2 互为主备)，正常情况下，M2,S1,S2 都参与 select 语句的负载均衡 ; 2). writeType 0 : 写操作都转发到第1台writeHost, writeHost1挂了, 会切换到writeHost2上; 1 : 所有的写操作都随机地发送到配置的writeHost上 ; 3). switchType -1 : 不自动切换 1 : 默认值, 自动切换 2 : 表示基于MySQL的主从同步状态决定是否切换, 心跳语句 : show slave status 读写分离验证查询数据 : select * from user; 插入数据 : insert into user(id,name,sex) values(null,’Dawn’,’1’); 可用性验证关闭Master1 , 然后再执行写入的SQL语句 , 通过日志查询当前写入操作, 操作的是那台服务器 ;","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://zsc-cloud.github.io/categories/MySQL/"},{"name":"MyCat","slug":"MySQL/MyCat","permalink":"https://zsc-cloud.github.io/categories/MySQL/MyCat/"}],"tags":[{"name":"MyCat","slug":"MyCat","permalink":"https://zsc-cloud.github.io/tags/MyCat/"},{"name":"分库分表","slug":"分库分表","permalink":"https://zsc-cloud.github.io/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"}]},{"title":"MyCat(七)---高可用集群搭建","slug":"Mycat(七)---高可用集群搭建","date":"2021-06-21T20:41:11.000Z","updated":"2022-03-26T03:42:17.429Z","comments":true,"path":"2021/06/21/Mycat(七)---高可用集群搭建/","link":"","permalink":"https://zsc-cloud.github.io/2021/06/21/Mycat(%E4%B8%83)---%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/","excerpt":"","text":"MyCat高可用集群搭建MyCat实现读写分离架构在上面的章节, 我们已经讲解过了通过MyCat来实现MySQL的读写分离, 从而完成MySQL集群的负载均衡 , 如下面的结构图: 但是以上架构存在问题 , 由于MyCat中间件是单节点的服务, 前端客户端所有的压力过来都直接请求这一台MyCat , 存在单点故障。所以这个时候， 我们就需要考虑MyCat的集群 ； MyCat集群架构通过MyCat来实现后端MySQL的负载均衡 ， 通过HAProxy再实现MyCat集群的负载均衡 ; HAProxy 负责将请求分发到 MyCat 上，起到负载均衡的作用，同时 HAProxy 也能检测到 MyCat 是否存活，HAProxy 只会将请求转发到存活的 MyCat 上。如果一台 MyCat 服务器宕机，HAPorxy 转发请求时不会转发到宕机的 MyCat 上，所以 MyCat 依然可用。 HAProxy介绍: HAProxy 是一个开源的、高性能的基于TCP(第四层)和HTTP(第七层)应用的负载均衡软件。 使用HAProxy可以快速、可靠地实现基于TCP与HTTP应用的负载均衡解决方案。 具有以下优点： ①. 可靠性和稳定性好, 可以与硬件级的F5负载均衡服务器媲美 ; ②. 处理能力强, 最高可以通过维护4w-5w个并发连接, 单位时间处理的最大请求数达到2w个 ; ③. 支持多种负载均衡算法 ; ④. 有功能强大的监控界面, 通过此页面可以实时了解系统的运行情况 ; 但是， 上述的架构也是存在问题的， 因为所以的客户端请求都是先到达HAProxy, 由HAProxy再将请求再向下分发, 如果HAProxy宕机的话, 就会造成整个MyCat集群不能正常运行, 依然存在单点故障。 MyCat的高可用集群 图解说明：1). HAProxy 实现了 MyCat 多节点的集群高可用和负载均衡，而 HAProxy 自身的高可用则可以通过Keepalived 来实现。因此，HAProxy 主机上要同时安装 HAProxy 和 Keepalived，Keepalived 负责为该服务器抢占 vip（虚拟 ip），抢占到 vip 后，对该主机的访问可以通过原来的 ip访问，也可以直接通过 vip访问。 2). Keepalived 抢占 vip 有优先级，在 keepalived.conf 配置中的 priority 属性决定。但是一般哪台主机上的Keepalived服务先启动就会抢占到vip，即使是slave，只要先启动也能抢到（要注意避免Keepalived的资源抢占问题）。 3). HAProxy 负责将对 vip 的请求分发到 MyCat 集群节点上，起到负载均衡的作用。同时 HAProxy 也能检测到 MyCat 是否存活，HAProxy 只会将请求转发到存活的 MyCat 上。 4). 如果 Keepalived+HAProxy 高可用集群中的一台服务器宕机，集群中另外一台服务器上的 Keepalived会立刻抢占 vip 并接管服务，此时抢占了 vip 的 HAProxy 节点可以继续提供服务。 5). 如果一台 MyCat 服务器宕机，HAPorxy 转发请求时不会转发到宕机的 MyCat 上，所以 MyCat 依然可用。 综上：MyCat 的高可用及负载均衡由 HAProxy 来实现，而 HAProxy 的高可用，由 Keepalived 来实现。 keepalived介绍: Keepalived是一种基于VRRP协议来实现的高可用方案,可以利用其来避免单点故障。 通常有两台甚至多台服务器运行Keepalived，一台为主服务器(Master), 其他为备份服务器, 但是对外表现为一个虚拟IP(VIP), 主服务器会发送特定的消息给备份服务器, 当备份服务器接收不到这个消息时, 即认为主服务器宕机, 备份服务器就会接管虚拟IP, 继续提供服务, 从而保证了整个集群的高可用。VRRP(虚拟路由冗余协议-Virtual Router Redundancy Protocol)协议是用于实现路由器冗余的协议，VRRP 协议将两台或多台路由器设备虚拟成一个设备，对外提供虚拟路由器 IP(一个或多个)，而在路由器组内部，如果实际拥有这个对外 IP 的路由器如果工作正常的话就是 MASTER，或者是通过算法选举产生。MASTER 实现针对虚拟路由器 IP 的各种网络功能，如 ARP 请求，ICMP，以及数据的转发等；其他设备不拥有该虚拟 IP，状态是 BACKUP，除了接收 MASTER 的VRRP 状态通告信息外，不执行对外的网络功能。当主机失效时，BACKUP 将接管原先 MASTER 的网络功能。VRRP 协议使用多播数据来传输 VRRP 数据，VRRP 数据使用特殊的虚拟源 MAC 地址发送数据而不是自身网卡的 MAC 地址，VRRP 运行时只有 MASTER 路由器定时发送 VRRP 通告信息，表示 MASTER 工作正常以及虚拟路由器 IP(组)，BACKUP 只接收 VRRP 数据，不发送数据，如果一定时间内没有接收到 MASTER 的通告信息，各 BACKUP 将宣告自己成为 MASTER，发送通告信息，重新进行 MASTER 选举状态。 高可用集群搭建部署环境规划 名称 IP 端口 用户名/密码 MySQL Master 192.168.192.157 3306 root/itcast MySQL Slave 192.168.192.158 3306 root/itcast MyCat节点1 192.168.192.157 8066 root/123456 MyCat节点2 192.168.192.158 8066 root/123456 HAProxy节点1/keepalived主 192.168.192.159 HAProxy节点2/keepalived备 192.168.192.160 MySQL主从复制搭建master1） 在master 的配置文件（/usr/my.cnf）中，配置如下内容： 123456789101112#mysql 服务ID,保证整个集群环境中唯一server-id=1#mysql binlog 日志的存储路径和文件名log-bin=/var/lib/mysql/mysqlbin#设置logbin格式binlog_format=STATEMENT#是否只读,1 代表只读, 0 代表读写read-only=0#指定同步的数据库binlog-do-db=db01binlog-do-db=db02binlog-do-db=db03 2） 执行完毕之后，需要重启Mysql： 1service mysql restart ; 3） 创建同步数据的账户，并且进行授权操作： 123grant replication slave on *.* to &#x27;itcast&#x27;@&#x27;%&#x27; identified by &#x27;itcast&#x27;; flush privileges; 4） 查看master状态： 1show master status; 字段含义: 123File : 从哪个日志文件开始推送日志文件 Position ： 从哪个位置开始推送日志Binlog_Do_DB : 指定需要同步的数据库 slave1） 在 slave 端配置文件中，配置如下内容： 123456#mysql服务端ID,唯一server-id=2#指定binlog日志log-bin=/var/lib/mysql/mysqlbin#启用中继日志relay-log=mysql-relay 2） 执行完毕之后，需要重启Mysql： 1service mysql restart; 3） 执行如下指令 ： 1change master to master_host= &#x27;192.168.192.157&#x27;, master_user=&#x27;itcast&#x27;, master_password=&#x27;itcast&#x27;, master_log_file=&#x27;mysqlbin.000002&#x27;, master_log_pos=120; 指定当前从库对应的主库的IP地址，用户名，密码，从哪个日志文件开始的那个位置开始同步推送日志。 4） 开启同步操作 12start slave;show slave status; 5） 停止同步操作 1stop slave; 测试验证1234567891011121314create database db01;user db01;create table user( id int(11) not null auto_increment, name varchar(50) not null, sex varchar(1), primary key (id))engine=innodb default charset=utf8;insert into user(id,name,sex) values(null,&#x27;Tom&#x27;,&#x27;1&#x27;);insert into user(id,name,sex) values(null,&#x27;Trigger&#x27;,&#x27;0&#x27;);insert into user(id,name,sex) values(null,&#x27;Dawn&#x27;,&#x27;1&#x27;); MyCat安装配置schema.xml123456789101112131415&lt;?xml version=&quot;1.0&quot;?&gt;&lt;!DOCTYPE mycat:schema SYSTEM &quot;schema.dtd&quot;&gt;&lt;mycat:schema xmlns:mycat=&quot;http://io.mycat/&quot;&gt; &lt;schema name=&quot;ITCAST&quot; checkSQLschema=&quot;true&quot; sqlMaxLimit=&quot;100&quot;&gt; &lt;table name=&quot;user&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;id&quot;/&gt; &lt;/schema&gt; &lt;dataNode name=&quot;dn1&quot; dataHost=&quot;localhost1&quot; database=&quot;db01&quot; /&gt; &lt;dataHost name=&quot;localhost1&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;1&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=&quot;hostM1&quot; url=&quot;192.168.192.157:3306&quot; user=&quot;root&quot; password=&quot;itcast&quot;&gt; &lt;readHost host=&quot;hostS1&quot; url=&quot;192.168.192.158:3306&quot; user=&quot;root&quot; password=&quot;itcast&quot; /&gt; &lt;/writeHost&gt; &lt;/dataHost&gt; &lt;/mycat:schema&gt; server.xml123456789&lt;user name=&quot;root&quot; defaultAccount=&quot;true&quot;&gt; &lt;property name=&quot;password&quot;&gt;123456&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;ITCAST&lt;/property&gt;&lt;/user&gt;&lt;user name=&quot;test&quot;&gt; &lt;property name=&quot;password&quot;&gt;123456&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;ITCAST&lt;/property&gt;&lt;/user&gt; 两台MyCat服务, 做相同的配置 ; HAProxy安装配置安装1). 准备好HAProxy安装包，传到/root目录下 1haproxy-1.5.16.tar.gz 2). 解压到/usr/local/src目录下 1tar -zxvf haproxy-1.5.16.tar.gz -C /usr/local/src 3). 进入解压后的目录，查看内核版本，进行编译 1234567cd /usr/local/src/haproxy-1.5.16uname -rmake TARGET=linux2632 PREFIX=/usr/local/haproxy ARCH=x86_64# TARGET=linux310，内核版本，使用uname -r查看内核，如：2.6.32-431.el6.x86_64，此时该参数就为linux2632；# ARCH=x86_64，系统位数；# PREFIX=/usr/local/haprpxy #/usr/local/haprpxy，为haprpxy安装路径。 4). 编译完成后，进行安装 1make install PREFIX=/usr/local/haproxy 5). 安装完成后，创建目录 1mkdir -p /usr/data/haproxy/ 6). 创建HAProxy配置文件 vim /usr/local/haproxy/haproxy.conf 12345678910111213141516171819202122232425262728293031323334353637global log 127.0.0.1 local0 maxconn 4096 chroot /usr/local/haproxy pidfile /usr/data/haproxy/haproxy.pid uid 99 gid 99 daemon node mysql-haproxy-01 description mysql-haproxy-01defaults log global mode tcp option abortonclose option redispatch retries 3 maxconn 2000 timeout connect 50000ms timeout client 50000ms timeout server 50000mslisten proxy_status bind 0.0.0.0:48066 mode tcp balance roundrobin server mycat_1 192.168.192.157:8066 check server mycat_2 192.168.192.158:8066 checkfrontend admin_stats bind 0.0.0.0:8888 mode http stats enable option httplog maxconn 10 stats refresh 30s stats uri /admin stats auth admin:123123 stats hide-version stats admin if TRUE 内容解析如下 : 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677#global 配置中的参数为进程级别的参数，通常与其运行的操作系统有关global #定义全局的syslog服务器, 最多可定义2个; local0 是日志设备, 对应于/etc/rsyslog.conf中的配置 , 默认收集info级别日志 log 127.0.0.1 local0 #log 127.0.0.1 local1 notice #log loghost local0 info #设定每个haproxy进程所接受的最大并发连接数 ; maxconn 4096 #修改HAproxy工作目录至指定的目录并在放弃权限之前执行chroot操作, 可以提升haproxy的安全级别 chroot /usr/local/haproxy #进程ID保存文件 pidfile /usr/data/haproxy/haproxy.pid #指定用户ID uid 99 #指定组ID gid 99 #设置HAproxy以守护进程方式运行 daemon #debug #quiet node mysql-haproxy-01 ## 定义当前节点的名称，用于 HA 场景中多 haproxy 进程共享同一个 IP 地址时 description mysql-haproxy-01 ## 当前实例的描述信息 #defaults：用于为所有其他配置段提供默认参数，这默认配置参数可由下一个&quot;defaults&quot;所重新设定defaults #继承global中的log定义 log global #所使用的处理模式(tcp:四层 , http:七层, health:状态检查,只返回OK) ### tcp: 实例运行于纯 tcp 模式，在客户端和服务器端之间将建立一个全双工的连接，且不会对 7 层报文做任何类型的检查，此为默认模式 ### http:实例运行于 http 模式，客户端请求在转发至后端服务器之前将被深度分析，所有不与 RFC 模式兼容的请求都会被拒绝 ### health：实例运行于 health 模式，其对入站请求仅响应“OK”信息并关闭连接，且不会记录任何日志信息 ，此模式将用于相应外部组件的监控状态检测请求 mode tcp #当服务器负载很高的时候，自动结束掉当前队列处理时间比较长的连接 option abortonclose #当使用了cookie时，haproxy将会将请求的后端服务器的serverID插入到cookie中，以保证会话的session持久性，而此时，后端服务器宕机，但是客户端的cookie不会刷新，设置此参数，将会将客户请求强制定向到另外一个后端server上，以保证服务的正常。 option redispatch retries 3 # 前端的最大并发连接数（默认为 2000） maxconn 2000 # 连接超时(默认是毫秒,单位可以设置 us,ms,s,m,h,d) timeout connect 5000 # 客户端超时时间 timeout client 50000 # 服务器超时时间 timeout server 50000#listen: 用于定义通过关联“前端”和“后端”一个完整的代理，通常只对 TCP 流量有用listen proxy_status bind 0.0.0.0:48066 # 绑定端口 mode tcp balance roundrobin # 定义负载均衡算法，可用于&quot;defaults&quot;、&quot;listen&quot;和&quot;backend&quot;中,默认为轮询 #格式: server &lt;name&gt; &lt;address&gt; [:[port]] [param*] # weight : 权重，默认为 1，最大值为 256，0 表示不参与负载均衡 # backup : 设定为备用服务器，仅在负载均衡场景中的其他 server 均不可以启用此 server # check : 启动对此 server 执行监控状态检查，其可以借助于额外的其他参数完成更精细的设定 # inter : 设定监控状态检查的时间间隔，单位为毫秒，默认为 2000，也可以使用 fastinter 和 downinter 来根据服务器端专题优化此事件延迟 # rise : 设置 server 从离线状态转换至正常状态需要检查的次数（不设置的情况下，默认值为 2） # fall : 设置 server 从正常状态转换至离线状态需要检查的次数（不设置的情况下，默认值为 3） # cookie : 为指定 server 设定 cookie 值，此处指定的值将会在请求入站时被检查，第一次为此值挑选的 server 将会被后续的请求所选中，其目的在于实现持久连接的功能 # maxconn: 指定此服务器接受的最大并发连接数，如果发往此服务器的连接数目高于此处指定的值，其将被放置于请求队列，以等待其他连接被释放 server mycat_1 192.168.192.157:8066 check inter 10s server mycat_2 192.168.192.158:8066 check inter 10s# 用来匹配接收客户所请求的域名，uri等，并针对不同的匹配，做不同的请求处理# HAProxy 的状态信息统计页面frontend admin_stats bind 0.0.0.0:8888 mode http stats enable option httplog maxconn 10 stats refresh 30s stats uri /admin stats auth admin:123123 stats hide-version stats admin if TRUE HAProxy的负载均衡策略: 策略 含义 roundrobin 表示简单的轮循，即客户端每访问一次，请求轮循跳转到后端不同的节点机器上 static-rr 基于权重轮循，根据权重轮循调度到后端不同节点 leastconn 加权最少连接，表示最少连接者优先处理 source 表示根据请求源IP，这个跟Nginx的IP_hash机制类似，使用其作为解决session问题的一种方法 uri 表示根据请求的URL，调度到后端不同的服务器 url_param 表示根据请求的URL参数来进行调度 hdr（name） 表示根据HTTP请求头来锁定每一次HTTP请求 rdp-cookie（name） 表示根据cookie（name）来锁定并哈希每一次TCP请求 启动访问1). 启动HAProxy 1/usr/local/haproxy/sbin/haproxy -f /usr/local/haproxy/haproxy.conf 2). 查看HAProxy进程 1ps -ef|grep haproxy 3). 访问 http://192.168.192.162:8888/admin 界面: Keepalived安装配置 安装配置1). 上传安装包到Linux 1alt + p --------&gt; put D:/tmp/keepalived-1.4.5.tar.gz 2). 解压安装包到目录 /usr/local/src 1tar -zxvf keepalived-1.4.5.tar.gz -C /usr/local/src 3). 安装依赖插件 1yum install -y gcc openssl-devel popt-devel 4). 进入解压后的目录，进行配置，进行编译 123cd /usr/local/src/keepalived-1.4.5./configure --prefix=/usr/local/keepalived 5). 进行编译，完成后进行安装 1make &amp;&amp; make install 6). 运行前配置 12345cp /usr/local/src/keepalived-1.4.5/keepalived/etc/init.d/keepalived /etc/init.d/mkdir /etc/keepalivedcp /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived/cp /usr/local/src/keepalived-1.4.5/keepalived/etc/sysconfig/keepalived /etc/sysconfig/cp /usr/local/keepalived/sbin/keepalived /usr/sbin/ 7). 修改配置文件 /etc/keepalived/keepalived.conf Master: 1234567891011121314151617181920212223242526272829303132333435363738394041global_defs &#123; notification_email &#123; javadct@163.com &#125; notification_email_from keepalived@showjoy.com smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id haproxy01 vrrp_skip_check_adv_addr vrrp_garp_interval 0 vrrp_gna_interval 0&#125;vrrp_script chk_haproxy &#123; script &quot;/etc/keepalived/haproxy_check.sh&quot; interval 2 weight 2&#125;vrrp_instance VI_1 &#123; #主机配MASTER，备机配BACKUP state MASTER #所在机器网卡 interface eth1 virtual_router_id 51 #数值越大优先级越高 priority 120 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; ## 将 track_script 块加入 instance 配置块 track_script &#123; chk_haproxy ## 检查 HAProxy 服务是否存活 &#125; virtual_ipaddress &#123; #虚拟IP 192.168.192.200 &#125;&#125; BackUP: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546global_defs &#123; notification_email &#123; javadct@163.com &#125; notification_email_from keepalived@showjoy.com smtp_server 127.0.0.1 smtp_connect_timeout 30 #标识本节点 router_id haproxy02 vrrp_skip_check_adv_addr vrrp_garp_interval 0 vrrp_gna_interval 0&#125;# keepalived 会定时执行脚本并对脚本执行的结果进行分析，动态调整 vrrp_instance 的优先级vrrp_script chk_haproxy &#123; # 检测 haproxy 状态的脚本路径 script &quot;/etc/keepalived/haproxy_check.sh&quot; #检测时间间隔 interval 2 #如果条件成立，权重+2 weight 2&#125;vrrp_instance VI_1 &#123; #主机配MASTER，备机配BACKUP state BACKUP #所在机器网卡 interface eth1 virtual_router_id 51 #数值越大优先级越高 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; ## 将 track_script 块加入 instance 配置块 track_script &#123; chk_haproxy ## 检查 HAProxy 服务是否存活 &#125; virtual_ipaddress &#123; #虚拟IP 192.168.192.200 &#125;&#125; 8). 编写检测haproxy的shell脚本 haproxy_check.sh 123456789101112131415161718192021#!/bin/bashA=`ps -C haproxy --no-header | wc -l`if [ $A -eq 0 ];then /usr/local/haproxy/sbin/haproxy -f /usr/local/haproxy/haproxy.conf echo &quot;haproxy restart ...&quot; &amp;&gt; /dev/null sleep 1 if [ `ps -C haproxy --no-header | wc -l` -eq 0 ];then /etc/init.d/keepalived stop echo &quot;stop keepalived&quot; &amp;&gt; /dev/null fifi 启动测试1). 启动Keepalived 1service keepalived start 2). 登录验证 1mysql -uroot -p123456 -h 192.168.192.200 -P 48066","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://zsc-cloud.github.io/categories/MySQL/"},{"name":"MyCat","slug":"MySQL/MyCat","permalink":"https://zsc-cloud.github.io/categories/MySQL/MyCat/"}],"tags":[{"name":"MyCat","slug":"MyCat","permalink":"https://zsc-cloud.github.io/tags/MyCat/"},{"name":"分库分表","slug":"分库分表","permalink":"https://zsc-cloud.github.io/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"}]},{"title":"MyCat(八)---架构解析","slug":"MyCat(八)---架构解析","date":"2021-06-20T20:41:11.000Z","updated":"2022-03-26T03:42:17.358Z","comments":true,"path":"2021/06/20/MyCat(八)---架构解析/","link":"","permalink":"https://zsc-cloud.github.io/2021/06/20/MyCat(%E5%85%AB)---%E6%9E%B6%E6%9E%84%E8%A7%A3%E6%9E%90/","excerpt":"","text":"MyCat总体架构介绍源码下载及导入 导入Idea 总体架构MyCat在逻辑上由几个模块组成: 通信协议、路由解析、结果集处理、数据库连接、监控等模块。如图所示： 1). 通信协议模块： 通信协议模块承担底层的收发数据、线程回调处理工作， MyCat通信协议默认采用Reactor模式，在协议层采用MySQL协议； 2). 路由解析模块: 负责对传入的SQL语句进行语法解析, 解析语句的条件、类型、关键字等，并进行优化； 3). SQL执行模块: 负责从连接池中获取连接, 再根据路由解析的结果, 把SQL语句分发到相应的节点执行; 4). 数据库连接模块: 负责创建、管理、维护后端的连接池。为减少每次建立数据库连接的开销，数据库使用连接池机制对连接声明周期进行管理； 5). 结果集处理模块: 负责对跨分片的查询结果进行汇聚、排序、截取等； 6). 监控管理模块: 负责MyCat的连接、内存等资源进行监控和管理。监控主要通过管理指令及监控服务展现一些监控数据； 管理则主要通过轮询事件来检测和释放不适用的资源； 总体执行流程 MyCat网络I/O架构及实现BIO、NIO与AIO1). BIO BIO(同步阻塞I/O) 通常由一个单独的Acceptor线程负责监听客户端的连接, 接收到客户端的连接请求后, 会为每个客户端创建一个新的线程进行处理, 处理完成之后, 再给客户端返回结果, 销毁线程 。 每个客户端请求接入时， 都需要开启一个线程进行处理， 一个线程只能处理一个客户端连接。 当客户端变多时，会创建大量的处理线程， 每个线程都需要分配栈空间和CPU， 并且频繁的线程上下文切换也会造成性能的浪费。所以该模式， 无法满足高性能、高并发接入的需求。 2). NIO NIO(同步非阻塞I/O)基于Reactor模式作为底层通信模型，Reactor模式可以将事件驱动的应用进行事件分派, 将客户端发送过来的服务请求分派给合适的处理类(handler)。当Socket有流可读或可写入Socket时, 操作系统会通知相应的应用程序进行处理, 应用程序再将流读取到缓冲区或写入操作系统。 这时已经不是一个连接对应一个处理线程了， 而是一个有效的请求对应一个线程， 当没有数据时， 就没有工作线程来处理。 NIO 的最大优点体现在线程轮询访问Selector, 当read或write到达时则处理, 未到达时则继续轮询。 3). AIO AIO，全程 Asynchronous IO(异步非阻塞的IO), 是一种非阻塞异步的通信模式。在NIO的基础上引入了新的异步通道的概念，并提供了异步文件通道和异步套接字通道的实现。AIO中客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理。 AIO与NIO的主要区别在于回调与轮询, 客户端不需要关注服务处理事件是否完成, 也不需要轮询, 只需要关注自己的回调函数。 通信架构在MyCat中实现了NIO与AIO两种I/O模式, 可以通过配置文件server.xml进行指定 : 1&lt;property name=&quot;usingAIO&quot;&gt;1&lt;/property&gt; usingAIO为1代表使用AIO模型 , 为0表示使用NIO模型; MyCat的AIO架构 1). MyCatStartUp是整个MyCat服务启动的入口; 2). 在获取到MyCat的home目录后, 把主要的任务交给MyCatServer , 并调用其startup方法; 3). 初始化系统配置, 获取配置文件中的usingAIO的配置, 如果配置为1, 说明使用AIO模型 , 进入到AIO的分支, 并创建两个连接, 一个是管理后台连接(9066), 一个server的连接(8066); 4). 进入AIO分支 , 主要有AIOAcceptor接收客户端请求, 绑定端口, 创建服务端的异步Socket ;在accept方法中完成两件事: ①. FrontedConnection的创建, 这是前段连接的关键; ②. register注册事件, MySQL协议握手包就在此时发送; MyCat的NIO架构 如果设置的usingAIO为0 ,那么将走NIOAcceptor通道 , 流程如下: 1). 如果走NIO分支 , 将首先创建NIOAcceptor对象, 并调用其start方法; 2). NIOAcceptor 负责处理Accept事件, 服务端接收客户端的连接事件, 就是MyCat作为服务端去处理前端业务程序发过来的连接请求, 建立链接后, 调用NIOAcceptor的 NIOReactor.postRegister方法进行注册（并没有注解注册， 而是放入缓冲队列， 避免加锁的竞争）。 NIOAcceptor的accept方法 ： NIOReactor的postRegister方法： Mycat实现MySQL协议MySQL协议简介概述MySQL协议处于应用层之下、TCP/IP之上, 在MySQL客户端和服务端之间使用。包含了链接器、MySQL代理、主从复制服务器之间通信，并支持SSL加密、传输数据的压缩、连接和身份验证及数据交互等。其中，握手认证阶段和命令执行阶段是MySQL协议中的两个重要阶段。 握手认证阶段 A. 握手认证阶段是客户端连接服务器的必经之路, 客户端与服务端完成TCP的三次握手以后, 服务端会向客户端发送一个初始化握手包, 握手包中包含了协议版本、MySQLServer版本、线程ID、服务器的权能标识和字符集等信息。 B. 客户端在接收到服务端的初始化握手包之后， 会发送身份验证包给服务端（AuthPacket）, 该包中包含用户名、密码等信息。 C. 服务端接收到客户端的登录验证包之后，需要进行逻辑校验，校验该登录信息是否正确。如果信息都符合，则返回一个OKPacket，表示登录成功,否则返回ERR_Packet，表示拒绝。 Wireshark抓包如下: 报文分析如下： 1). 初始化握手包 通过抓包工具Wireshark抓取到的握手包信息如下, 握手包格式: 说明: Packet Length : 包的长度; Packet Number : 包的序号; Server Greeting : 消息体, 包含了协议版本、MySQLServer版本、线程ID和字符集等信息。 2). 登录认证包 客户端在接收到服务端发来的初始握手包之后， 向服务端发出认证请求， 该请求包含以下信息（由Wireshark抓获） ： 3). OK包或ERROR包 服务端接收到客户端的登录认证包之后，如果通过认证，则返回一个OKPacket，如果未通过认证，则返回一个ERROR包。 OK报文如下： ERROR报文如下 : 命令执行阶段在握手认证阶段通过并完成以后, 客户端可以向服务端发送各种命令来请求数据, 此阶段的流程是: 命令请求-&gt;返回结果集。 Wireshark 捕获的数据包如下： 1). 命令包 2). 结果集包 MySQL协议在MyCat中实现握手认证实现在MyCat中同时实现了NIO和AIO, 通过配置可以选择NIO和AIO。MyCat Server在启动阶段已经选择好采用NIO还是AIO，因此建立I/O通道后,MyCat服务端一直等待客户端端的连接,当有连接到来的时候,MyCat首先发送握手包。 1). 握手包源码实现 MyCat中的源码中io.mycat.net.FrontendConnection类的实现如下: 握手包信息组装完毕后, 通过FrontedConnection写回客户端。 2). 认证包源码实现 客户端接收到握手包后, 紧接着向服务端发起一个认证包, MyCat封装为类 AuthPacket: 客户端发送的认证包转由 FrontendAuthenticator 的Handler来处理, 主要操作就是 拆包, 检查用户名、密码合法性， 检查连接数是够超出限制。源码实现如下： 认证失败， 调用failure方法， 认证成功调用success方法。 failure方法源码： success方法源码： 命令执行实现命令执行阶段就是SQL命令和SQL语句执行阶段， 在该阶段MyCat主要需要做的事情， 就是对客户端发来的数据包进行拆包， 并判断命令的类型， 并解析SQL语句， 执行响应的SQL语句， 最后把执行结果封装在结果集包中， 返回给客户端。 从客户端发来的命令交给 FrontendCommandHandler 中的handle方法处理: 处理具体的请求, 返回客户端结果集数据包: MyCat线程架构与实现MyCat线程池实现在MyCat中大量用到了线程池， 通过线程池来避免频繁的创建和销毁线程而造成的系统性能的浪费。在MyCat中使用的线程池是JDK中提供的线程池 ThreadPoolExecutor 的子类 NameableExecutor ， 构造方法如下： 父类构造为： 构造参数含义: corePoolSize : 核心池大小 maximumPoolSize : 最大线程数 keepAliveTime: 线程没有任务执行时, 最多能够存活多久 timeUnit: 时间单位 workQueue: 阻塞任务队列 threadFactory: 线程工厂, 用来创建线程 MyCat线程架构 在MyCat中主要有两大线程池: timerExecutor 和 businessExecutor。 1). timerExecutor 线程池主要完成系统时间定时更新、处理器定时检查、数据节点定时连接空闲超时检查、数据节点定时心跳检测等任务。 2). businessExecutor是MyCat最重要的线程资源池, 该资源池的线程使用的范围非常广, 涵盖以下方面: A. 后端用原生协议连接数据 B. JDBC执行SQL语句 C. SQL拦截 D. 数据合并服务 E. 批量SQL作业 F. 查询结果的异步分发 G. 基于guava实现异步回调 MyCat内存管理及缓存框架与实现这里所提到的内存管理指的是MyCat缓冲区管理, 众所周知设置缓冲区的唯一目的是提高系统的性能, 缓冲区通常是部分常用的数据存放在缓冲池中以便系统直接访问, 避免使用磁盘IO访问磁盘数据, 从而提高性能。 内存管理1). 缓冲池组成 缓冲池的最小单位为chunk, 默认的chunk大小为4096字节(DEFAULT_BUFFER_CHUNK_SIZE), BufferPool的总大小为4096 x processors x 1000(其中processors为处理器数量)。对I/O进程而言, 他们共享一个缓冲池。缓冲池有两种类型： 本地缓存线程（以$_开头的线程）缓冲区和其他缓冲区， 分配buffer时, 优先获取ThreadLocalPool中的buffer, 没有命中时会获取BufferPool中的buffer。 2). 分配MyCat缓冲池 分配缓冲池时, 可以指定大小, 也可以用默认值。 A. allocate(): 先检测是否为本地线程， 当执行线程为本地缓存线程时， localBufferPool取出一个可用的buffer。如果不是， 则从ConcurrentLinkedQueue队列中取出一个buffer进行分配, 如果队列没有可用的buffer, 则创建一个直接缓冲区。 B. allocate(size): 如果用户指定的size不大于chunkSize, 则调用allocate()进行分配; 反之则调用createTempBuffer(size)创建临时非直接缓冲区。 3). MyCat缓冲池的回收 回收时先判断buffer是否有效, 有如下情况时缓冲池不回收。 A. 不是直接缓冲区 B. buffer是空的 C. buffer的容量大于chunkSize MyCat缓存架构1). 缓存框架选择 MyCat支持ehcache、mapdb、leveldb缓存, 可通过配置文件cacheserver.properties来进行配置; 2). 缓存内容 MyCat有路由缓存、表主键到datanode缓存、ER关系缓存。 A. 路由缓存: 即SQLRouteCache, 根据SQL语句查找路由信息的缓存, 该缓存只是针对select语句, 如果执行了之前已经执行过的某个SQL语句(缓存命中), 那么路由信息就不需要重复计算了, 直接从缓存中获取。 B. 表主键到datanode缓存: 当分片字段与主键字段不一致时, 直接通过主键值查询时无法定位具体分片的(只能全分片下发), 所以设置该缓存之后, 就可以利用主键值查找到分片名, 缓存的key是ID值, value是节点名。 C. ER关系缓存: 在ER分片时使用, 而且在insert查询中才会使用缓存, 当字表插入数据时, 根据父子关联字段确定子表分片, 下次可以直接从缓存中获取所在的分片。 查看缓存指令： show @@cache； MyCat连接池架构与实现这里我们所讨论的连接池是MyCat的后端连接池， 也就是MyCat后端与各个数据库节点之间的连接架构。 1). 连接池创建 MyCat按照每个dataHost创建一个连接池, 根据schema.xml文件的配置取得最小的连接数minCon, 并初始化minCon个连接。在初始化连接时， 还需要判定用户选择的是JDBC还是原生的MySQL协议， 以便于创建对应的连接。 2). 连接池分配 分配连接就是从连接池队列中取出一个连接， 在取出一个连接时， MyCat需要根据负载均衡（balance属性）的类型选择不同的数据源， 因为连接和数据源绑在一起，所以需要知道MyCat读写的是那些数据源， 才能分配响应的连接。 3). 架构 MyCat主从切换架构与实现MyCat主从切换概述MyCat实现MySQL读写分离的目的在于降低单节点数据库的访问压力, 原理就是让主数据库执行增删改操作, 从数据库执行查询操作, 利用MySQL数据库的复制机制将Master的数据同步到slave上。 当master宕机后，slave承载的业务如何切换到master继续提供服务，以及slave宕机后如何将master切换到slave上。手动切换数据源很简单， 但不是运维工作的首选，本节重点就是讲解如何实现自动切换。 MyCat的读写分离依赖于MySQL的主从同步, 也就是说MyCat没有实现数据的主从同步功能, 但是实现了自动切换功能。 1). 自动切换 自动切换是MyCat主从复制的默认配置 , 当主机或从机宕机后, MyCat自动切换到可用的服务器上。 假设写服务器为M， 读服务器为S， 则： 正常时， 写M读S； 当M宕机后， 读写S ； 恢复M后， 写S， 读M ； 当S宕机后， 读写M ； 恢复S后， 写M， 读S ； 2). 基于MySQL主从同步状态的切换 这种切换方式与自动切换不同， MyCat检测到主从数据同步延迟时， 会自动切换到拥有最新数据的MySQL服务器上， 防止读到很久以前的数据。 原理就是通过检查MySQL的主从同步状态（show slave status）中的Seconds_Behind_Master、Slave_IO_Running、Slave_SQL_Running三个字段,来确定当前主从同步的状态以及主从之间的数据延迟。 Seconds_Behind_Master为0表示没有延迟，数值越大，则说明延迟越高。 MyCat主从切换实现基于延迟的切换， 则判断结果集中的Slave_IO_Running、Slave_SQL_Running两个个字段是否都为yes，以及Seconds_Behind_Master 是否小于配置文件中配置的 slaveThreshold的值, 如果有其中任何一个条件不满足, 则切换。 主要流程如下: MyCat核心技术MyCat分布式事务实现MyCat在1.6版本以后已经支持XA分布式事务类型了。具体的使用流程如下： 1). 在应用层需要设置事务不能自动提交 1set autocommit=0; 2). 在SQL中设置XA为开启状态 1set xa = on; 3). 执行SQL 1insert into user(id,name,sex) values(1,&#x27;Tom&#x27;,&#x27;1&#x27;),(2,&#x27;Rose&#x27;,&#x27;2&#x27;),(3,&#x27;Leo&#x27;,&#x27;1&#x27;),(4,&#x27;Lee&#x27;,&#x27;1&#x27;); 4). 对事务进行提交或回滚 1commit/rollback 完整流程如下: MyCat SQL路由实现MyCat的路由是和SQL解析组件息息相关的, SQL路由模块是MyCat数据库中间件最重要的模块之一, 使用MyCat主要是为了分库分表, 而分库分表的核心就是路由。 路由的作用 如图所示， MyCat接收到应用系统发来的查询语句， 要将其发送到后端连接的MySQL数据库去执行， 但是后端有三个数据库服务器，具体要查询那一台数据库服务器呢， 这就是路由需要实现的功能。 SQL的路由既要保证数据的完整 ， 也不能造成资源的浪费， 还要保证路由的效率。 解析器Mycat1.3版本之前模式使用的是Fdbparser的foundationdb的开源SQL解析器，在2015年被apple收购后，从开源变为闭源了。 目前版本的MyCat采用的是Druid的SQL解析器， 性能比采用Fdbparser整体性能提高20%以上。 MyCat跨库Join全局表每个企业级的系统中, 都会存在一些系统的基础信息表, 类似于字典表、省份、城市、区域、语言表等， 这些表与业务表之间存在关系， 但不是业务主从关系，而是一种属性关系。 当我们对业务表进行分片处理时， 可以将这些基础信息表设置为全局表， 也就是在每个节点中都存在该表。 全局表的特性如下： A. 全局表的insert、update、delete操作会实时地在所有节点同步执行, 保持各个节点数据的一致性 B. 全局表的查询操作会从任意节点执行,因为所有节点的数据都一致 C. 全局表可以和任意表进行join操作 ER表关系型数据库是基于实体关系模型(Entity Relationship Model)的, MyCat中的ER表便来源于此。 MyCat提出了基于ER关系的数据分片策略 , 子表的记录与其所关联的父表的记录存放在同一个数据分片中, 通过表分组(Table Group)保证数据关联查询不会跨库操作。 catletcatlet是MyCat为了解决跨分片Join提出的一种创新思路, 也叫做人工智能(HBT)。MyCat参考了数据库中存储过程的实现方式，提出类似的跨库解决方案，用户可以根据系统提供的API接口实现跨分片Join。 采用这种方案开发时,必须要实现Catlet接口的两个方法 : route 方法: 路由的方法, 传递系统配置和schema配置等 ; processSQL方法: EngineCtx执行SQL并给客户端返回结果集 ; 当我们自定义Catlet完成之后, 需要将Catlet的实现类进行编译,并将其字节码文件 XXXCatlet.class存放在mycat_home/catlet目录下, 系统会加载相关Class, 而且每隔1分钟扫描一次文件是否更新, 若更新则自动重新加载,因此无需重启服务。 ShareJoin ShareJoin 是Catlet的实现， 是一个简单的跨分片Join， 目前支持两个表的Join，原理就是解析SQL语句， 拆分成单表的语句执行， 单后把各个节点的数据进行汇集。 要想使用Catlet完成join， 还需要借助于MyCat中的注解， 在执行SQL语句时，使用catlet注解: 1/*!mycat:catlet=demo.catlets.ShareJoin */ select a.id as aid , a.id , b.id as bid , b.name as name from customer a, company b where a.company_id=b.id and a.id = 1; MyCat数据汇聚与排序通过MyCat实现数据汇聚和排序,不仅可以减少各分片与客户端之间的数据传输IO, 也可以帮助开发者总复杂的数据处理中解放出来,从而专注于开发业务代码。 在MySQL中存在两种排序方式： 一种利用有序索引获取有序数据， 另一种通过相应的排序算法将获取到的数据在内存中进行排序。 而MyCat中数据排序采用堆排序法对多个分片返回有序数据，并在合并、排序后再返回给客户端。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://zsc-cloud.github.io/categories/MySQL/"},{"name":"MyCat","slug":"MySQL/MyCat","permalink":"https://zsc-cloud.github.io/categories/MySQL/MyCat/"}],"tags":[{"name":"MyCat","slug":"MyCat","permalink":"https://zsc-cloud.github.io/tags/MyCat/"},{"name":"分库分表","slug":"分库分表","permalink":"https://zsc-cloud.github.io/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"}]},{"title":"MyCat(九)---案例","slug":"MyCat(九)---案例","date":"2021-06-19T20:41:11.000Z","updated":"2022-03-26T03:42:17.288Z","comments":true,"path":"2021/06/19/MyCat(九)---案例/","link":"","permalink":"https://zsc-cloud.github.io/2021/06/19/MyCat(%E4%B9%9D)---%E6%A1%88%E4%BE%8B/","excerpt":"","text":"案例概述案例介绍本案例将模拟电商项目中的商品管理、订单管理、基础信息管理、日志管理模块，对整个系统中的数据表进行分片操作，将根据不同的业务需求，采用不同的分片方式 。 系统架构 本案例涉及到的模块： 1). 商品微服务 2). 订单微服务 3). 日志微服务 技术选型 SpringBoot SpringCloud SpringMVC Mybatis SpringDataRedis MySQL Redis Lombok 案例需求1). 商品管理 A. 添加商品 B. 查询商品 2). 订单管理 A. 下订单 B. 查询订单 3). 日志管理 A. 日志记录 B. 日志查询 案例环境搭建数据库1). 省份表 tb_provinces Field Type Comment provinceid varchar(20) 省份ID province varchar(50) 省份名称 2). 市表 tb_cities Field Type Comment cityid varchar(20) 城市ID city varchar(50) 城市名称 provinceid varchar(20) 省份ID 3). 区县表 tb_areas Field Type Comment areaid varchar(20) 区域ID area varchar(50) 区域名称 cityid varchar(20) 城市ID 4). 商品分类表 tb_category Field Type Comment id int(20) 分类ID name varchar(50) 分类名称 goods_num int(11) 商品数量 is_show char(1) 是否显示 is_menu char(1) 是否导航 seq int(11) 排序 parent_id int(20) 上级ID 5). 品牌表 tb_brand Field Type Comment id int(11) 品牌id name varchar(100) 品牌名称 image varchar(1000) 品牌图片地址 letter char(1) 品牌的首字母 seq int(11) 排序 6). 商品SPU表 tb_spu Field Type Comment id varchar(20) 主键 sn varchar(60) 货号 name varchar(100) SPU名 caption varchar(100) 副标题 brand_id int(11) 品牌ID category1_id int(20) 一级分类 category2_id int(10) 二级分类 category3_id int(10) 三级分类 template_id int(20) 模板ID freight_id int(11) 运费模板id image varchar(200) 图片 images varchar(2000) 图片列表 sale_service varchar(50) 售后服务 introduction text 介绍 spec_items varchar(3000) 规格列表 para_items varchar(3000) 参数列表 sale_num int(11) 销量 comment_num int(11) 评论数 is_marketable char(1) 是否上架 is_enable_spec char(1) 是否启用规格 is_delete char(1) 是否删除 status char(1) 审核状态 7). 商品SKU表 tb_sku Field Type Comment id varchar(20) 商品id sn varchar(100) 商品条码 name varchar(200) SKU名称 price int(20) 价格（分） num int(10) 库存数量 alert_num int(11) 库存预警数量 image varchar(200) 商品图片 images varchar(2000) 商品图片列表 weight int(11) 重量（克） create_time datetime 创建时间 update_time datetime 更新时间 spu_id varchar(20) SPUID category_id int(10) 类目ID category_name varchar(200) 类目名称 brand_name varchar(100) 品牌名称 spec varchar(200) 规格 sale_num int(11) 销量 comment_num int(11) 评论数 status char(1) 商品状态 1-正常，2-下架，3-删除 version int(255) 8). 订单表 tb_order Field Type Comment id varchar(200) 订单id total_num int(11) 数量合计 total_money int(11) 金额合计 pre_money int(11) 优惠金额 post_fee int(11) 邮费 pay_money int(11) 实付金额 pay_type varchar(1) 支付类型，1、在线支付、0 货到付款 create_time datetime 订单创建时间 update_time datetime 订单更新时间 pay_time datetime 付款时间 consign_time datetime 发货时间 end_time datetime 交易完成时间 close_time datetime 交易关闭时间 shipping_name varchar(20) 物流名称 shipping_code varchar(20) 物流单号 username varchar(50) 用户名称 buyer_message varchar(1000) 买家留言 buyer_rate char(1) 是否评价 receiver_contact varchar(50) 收货人 receiver_mobile varchar(12) 收货人手机 receiver_province varchar(200) 收货人省份 receiver_city varchar(200) 收货人市 receiver_area varchar(200) 收货人区/县 receiver_address varchar(200) 收货人具体街道地址 source_type char(1) 订单来源：1:web，2：app，3：微信公众号，4：微信小程序 5 H5手机页面 transaction_id varchar(30) 交易流水号 order_status char(1) 订单状态 pay_status char(1) 支付状态 0:未支付 1:已支付 consign_status char(1) 发货状态 0:未发货 1:已发货 2:已送达 is_delete char(1) 是否删除 9). 订单明细表 tb_order_item Field Type Comment id varchar(200) ID category_id1 int(11) 1级分类 category_id2 int(11) 2级分类 category_id3 int(11) 3级分类 spu_id varchar(200) SPU_ID sku_id varchar(200) SKU_ID order_id varchar(200) 订单ID name varchar(200) 商品名称 price int(20) 单价 num int(10) 数量 money int(20) 总金额 pay_money int(11) 实付金额 image varchar(200) 图片地址 weight int(11) 重量 post_fee int(11) 运费 is_return char(1) 是否退货 10). 订单日志表 tb_order_log Field Type Comment id varchar(20) ID operater varchar(50) 操作员 operate_time datetime 操作时间 order_id bigint(20) 订单ID order_status char(1) 订单状态 pay_status char(1) 付款状态 consign_status char(1) 发货状态 remarks varchar(100) 备注 11). 操作日志表 tb_operatelog Field Type Comment id bigint(20) ID model_name varchar(200) 模块名 model_value varchar(200) 模块值 return_value varchar(200) 返回值 return_class varchar(200) 返回值类型 operate_user varchar(20) 操作用户 operate_time varchar(20) 操作时间 param_and_value varchar(500) 请求参数名及参数值 operate_class varchar(200) 操作类 operate_method varchar(200) 操作方法 cost_time bigint(20) 执行方法耗时, 单位 ms 12). 字典表 tb_dictionary Field Type Comment id int(11) 主键ID , 自增 codeid int(11) 码表ID codetype varchar(2) 码值类型 codename varchar(50) 名称 codevalue varchar(50) 码值 description varchar(100) 描述 createtime datetime 创建时间 updatetime datetime 修改时间 createuser int(11) 创建人 updateuser int(11) 修改人 工程预览 1234567891011spring-boot-starter-parent |- v_parent --------------------&gt; 父工程, 统一管理依赖版本 |- v_common ----------------&gt; 通用工程, 存放通用的工具类及组件 |- v_model -----------------&gt; 实体类 |- v_eureka ----------------&gt; 注册中心 |- v_feign_api -------------&gt; feign远程调用的客户端接口 |- v_gateway ---------------&gt; 网关工程 |- v_manage_web ------------&gt; 模拟前端工程 |- v_service_goods ---------&gt; 商品微服务 |- v_service_log -----------&gt; 日志微服务 |- v_service_order ---------&gt; 订单微服务 工程层级关系 父工程搭建工程名: v_parent pom.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&lt;!-- springBoot项目需要集成自父工程 --&gt;&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.4.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;skipTests&gt;true&lt;/skipTests&gt;&lt;/properties&gt;&lt;!--依赖包--&gt;&lt;dependencies&gt; &lt;!--测试包--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Greenwich.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--MySQL数据库驱动--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;/dependency&gt; &lt;!--mybatis分页插件--&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.51&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.6&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 基础工程搭建1). v_model 该基础工程中存放的是与数据库对应的实体类 ; A. pom.xml 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; B. 导入实体类 2). v_common 该基础工程中存放的是通用的组件及工具类 , 比如 分页实体类, 结果实体类, 状态码 等 直接导入资料中提供的基础组件和工具类 ; 3). v_feign_api 该工程中, 主要存放的是Feign远程调用的客户端接口; pom.xml 1234567891011121314151617181920212223242526&lt;dependencies&gt; &lt;!--web起步依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Feign起步依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.itcast&lt;/groupId&gt; &lt;artifactId&gt;v_common&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.itcast&lt;/groupId&gt; &lt;artifactId&gt;v_model&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; Eureka Server搭建1). pom.xml 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2). 引导类 1234567@SpringBootApplication@EnableEurekaServerpublic class EurekaApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaApplication.class,args); &#125;&#125; 3). application.yml 12345678910111213spring: application: name: eurekaserver: port: 8161eureka: client: register-with-eureka: false #是否将自己注册到eureka中 fetch-registry: false #是否从eureka中获取信息 service-url: defaultZone: http://127.0.0.1:$&#123;server.port&#125;/eureka/ server: enable-self-preservation: true GateWay 网关搭建1). pom.xml 123456789101112&lt;!--网关依赖--&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2). 引导类 1234567@SpringBootApplication@EnableEurekaClientpublic class GateWayApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(GateWayApplication.class,args); &#125;&#125; 3). application.yml 123456789101112131415161718192021222324252627server: port: 8001eureka: client: service-url: defaultZone: http://127.0.0.1:8161/eureka instance: prefer-ip-address: truespring: application: name: gateway cloud: gateway: routes: - id: v_goods_route uri: lb://goods predicates: - Path=/goods/** filters: - StripPrefix=1 - id: v_order_route uri: lb://order predicates: - Path=/order/** filters: - StripPrefix=1 4). Cors配置类 1234567891011121314151617181920212223242526import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.cors.CorsConfiguration;import org.springframework.web.cors.reactive.CorsWebFilter;import org.springframework.web.cors.reactive.UrlBasedCorsConfigurationSource;import org.springframework.web.util.pattern.PathPatternParser;@Configurationpublic class CorsConfig &#123; @Bean public CorsWebFilter corsFilter()&#123; UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(new PathPatternParser()); source.registerCorsConfiguration(&quot;/**&quot;, buildConfig()); return new CorsWebFilter(source); &#125; private CorsConfiguration buildConfig()&#123; CorsConfiguration corsConfiguration = new CorsConfiguration(); //在生产环境上最好指定域名，以免产生跨域安全问题 corsConfiguration.addAllowedOrigin(&quot;*&quot;); corsConfiguration.addAllowedHeader(&quot;*&quot;); corsConfiguration.addAllowedMethod(&quot;*&quot;); return corsConfiguration; &#125;&#125; 功能开发商品管理模块需求 : 1). 根据ID查询商品SPU信息; 2). 根据条件查询商品SPU列表; 3). 根据ID查询商品SKU信息; 概念: 1). SPU = Standard Product Unit （标准产品单位） 概念 : SPU 是商品信息聚合的最小单位，是一组可复用、易检索的标准化信息的集合，该集合描述了一个产品的特性。通俗点讲，属性值、特性相同的货品就可以称为一个 SPU 例如：华为P30 就是一个 SPU 2). SKU=stock keeping unit( 库存量单位) SKU 即库存进出计量的单位， 可以是以件、盒、托盘等为单位。SKU 是物理上不可分割的最小存货单元。在使用时要根据不同业态，不同管理模式来处理。在服装、鞋类商品中使用最多最普遍。 例如：红色 64G 全网通 的华为P30 就是一个 SKU 创建工程pom.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;dependencies&gt; &lt;!-- Eureka客户端依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--MySQL数据库驱动--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mybatis分页插件--&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web起步依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- redis 使用--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- fastJson依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Feign依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.itcast&lt;/groupId&gt; &lt;artifactId&gt;v_common&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.itcast&lt;/groupId&gt; &lt;artifactId&gt;v_model&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.itcast&lt;/groupId&gt; &lt;artifactId&gt;v_feign_api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; application.yml 1234567891011121314151617181920server: port: 9001spring: application: name: goods datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/v_shop?useUnicode=true&amp;characterEncoding=UTF-8&amp;serverTimezone=UTC username: root password: 2143 main: allow-bean-definition-overriding: true #当遇到同样名字的时候，是否允许覆盖注册eureka: client: fetch-registry: true register-with-eureka: true service-url: defaultZone: http://127.0.0.1:8161/eureka instance: prefer-ip-address: true 引导类 123456789@SpringBootApplication@EnableEurekaClient@EnableFeignClients(basePackages = &quot;cn.itcast.feign&quot;)@MapperScan(&quot;cn.itcast.goods.mapper&quot;)public class GoodsApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(GoodsApplication.class,args); &#125;&#125; Mapper1). mapper接口定义 1234567public interface SpuMapper &#123; public TbSpu findById(String spuId); public List&lt;TbSpu&gt; search(Map&lt;String,Object&gt; searchMap);&#125; 12345public interface SkuMapper &#123; //根据ID查询SKU public TbSku findById(String skuId);&#125; 2). mapper映射配置文件 SpuMapper.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;mapper namespace=&quot;cn.itcast.goods.mapper.SpuMapper&quot; &gt; &lt;resultMap id=&quot;spuResultMap&quot; type=&quot;cn.itcast.model.TbSpu&quot;&gt; &lt;id column=&quot;id&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;id&quot; /&gt; &lt;result column=&quot;sn&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;sn&quot; /&gt; &lt;result column=&quot;name&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;name&quot; /&gt; &lt;result column=&quot;caption&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;caption&quot; /&gt; &lt;result column=&quot;brand_id&quot; jdbcType=&quot;INTEGER&quot; property=&quot;brandId&quot; /&gt; &lt;result column=&quot;category1_id&quot; jdbcType=&quot;INTEGER&quot; property=&quot;category1Id&quot; /&gt; &lt;result column=&quot;category2_id&quot; jdbcType=&quot;INTEGER&quot; property=&quot;category2Id&quot; /&gt; &lt;result column=&quot;category3_id&quot; jdbcType=&quot;INTEGER&quot; property=&quot;category3Id&quot; /&gt; &lt;result column=&quot;template_id&quot; jdbcType=&quot;INTEGER&quot; property=&quot;templateId&quot; /&gt; &lt;result column=&quot;freight_id&quot; jdbcType=&quot;INTEGER&quot; property=&quot;freightId&quot; /&gt; &lt;result column=&quot;image&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;image&quot; /&gt; &lt;result column=&quot;images&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;images&quot; /&gt; &lt;result column=&quot;sale_service&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;saleService&quot; /&gt; &lt;result column=&quot;spec_items&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;specItems&quot; /&gt; &lt;result column=&quot;para_items&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;paraItems&quot; /&gt; &lt;result column=&quot;sale_num&quot; jdbcType=&quot;INTEGER&quot; property=&quot;saleNum&quot; /&gt; &lt;result column=&quot;comment_num&quot; jdbcType=&quot;INTEGER&quot; property=&quot;commentNum&quot; /&gt; &lt;result column=&quot;is_marketable&quot; jdbcType=&quot;CHAR&quot; property=&quot;isMarketable&quot; /&gt; &lt;result column=&quot;is_enable_spec&quot; jdbcType=&quot;CHAR&quot; property=&quot;isEnableSpec&quot; /&gt; &lt;result column=&quot;is_delete&quot; jdbcType=&quot;CHAR&quot; property=&quot;isDelete&quot; /&gt; &lt;result column=&quot;status&quot; jdbcType=&quot;CHAR&quot; property=&quot;status&quot; /&gt; &lt;/resultMap&gt; &lt;select id=&quot;findById&quot; parameterType=&quot;java.lang.String&quot; resultMap=&quot;spuResultMap&quot;&gt; select * from tb_spu where id = #&#123;spuId&#125; &lt;/select&gt; &lt;select id=&quot;search&quot; resultMap=&quot;spuResultMap&quot;&gt; select * from tb_spu &lt;where&gt; &lt;if test=&quot;name != null and name != &#x27;&#x27;&quot;&gt; and name like &#x27;%$&#123;name&#125;%&#x27; &lt;/if&gt; &lt;if test=&quot;caption != null and caption != &#x27;&#x27;&quot; &gt; and caption like &#x27;%$&#123;caption&#125;%&#x27; &lt;/if&gt; &lt;if test=&quot;brandId != null&quot;&gt; and brand_id = #&#123;brandId&#125; &lt;/if&gt; &lt;if test=&quot;status != null and status != &#x27;&#x27;&quot;&gt; and status = #&#123;status&#125; &lt;/if&gt; &lt;/where&gt; &lt;/select&gt;&lt;/mapper&gt; SkuMapper.xml 1234567891011121314151617181920212223242526272829&lt;mapper namespace=&quot;cn.itcast.goods.mapper.SkuMapper&quot; &gt; &lt;resultMap id=&quot;skuResultMap&quot; type=&quot;cn.itcast.model.TbSku&quot;&gt; &lt;id column=&quot;id&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;id&quot; /&gt; &lt;result column=&quot;sn&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;sn&quot; /&gt; &lt;result column=&quot;name&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;name&quot; /&gt; &lt;result column=&quot;price&quot; jdbcType=&quot;INTEGER&quot; property=&quot;price&quot; /&gt; &lt;result column=&quot;num&quot; jdbcType=&quot;INTEGER&quot; property=&quot;num&quot; /&gt; &lt;result column=&quot;alert_num&quot; jdbcType=&quot;INTEGER&quot; property=&quot;alertNum&quot; /&gt; &lt;result column=&quot;image&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;image&quot; /&gt; &lt;result column=&quot;images&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;images&quot; /&gt; &lt;result column=&quot;weight&quot; jdbcType=&quot;INTEGER&quot; property=&quot;weight&quot; /&gt; &lt;result column=&quot;create_time&quot; jdbcType=&quot;TIMESTAMP&quot; property=&quot;createTime&quot; /&gt; &lt;result column=&quot;update_time&quot; jdbcType=&quot;TIMESTAMP&quot; property=&quot;updateTime&quot; /&gt; &lt;result column=&quot;spu_id&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;spuId&quot; /&gt; &lt;result column=&quot;category_id&quot; jdbcType=&quot;INTEGER&quot; property=&quot;categoryId&quot; /&gt; &lt;result column=&quot;category_name&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;categoryName&quot; /&gt; &lt;result column=&quot;brand_name&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;brandName&quot; /&gt; &lt;result column=&quot;spec&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;spec&quot; /&gt; &lt;result column=&quot;sale_num&quot; jdbcType=&quot;INTEGER&quot; property=&quot;saleNum&quot; /&gt; &lt;result column=&quot;comment_num&quot; jdbcType=&quot;INTEGER&quot; property=&quot;commentNum&quot; /&gt; &lt;result column=&quot;status&quot; jdbcType=&quot;CHAR&quot; property=&quot;status&quot; /&gt; &lt;result column=&quot;version&quot; jdbcType=&quot;INTEGER&quot; property=&quot;version&quot; /&gt; &lt;/resultMap&gt; &lt;select id=&quot;findById&quot; parameterType=&quot;java.lang.String&quot; resultMap=&quot;skuResultMap&quot;&gt; select * from tb_sku where id = #&#123;skuId&#125; &lt;/select&gt;&lt;/mapper&gt; Service1). 接口定义 12345678public interface SkuService &#123; /** * 根据ID查询SKU * @param skuId * @return */ public TbSku findById(String skuId);&#125; 12345678910111213141516public interface SpuService &#123; /** * 根据ID查询 * @param id * @return */ TbSpu findById(String id); /*** * 多条件分页查询 * @param searchMap * @param page * @param size * @return */ Page&lt;TbSpu&gt; findPage(Map&lt;String, Object&gt; searchMap, int page, int size);&#125; 2).接口实现 12345678910111213@Servicepublic class SkuServiceImpl implements SkuService &#123; @Autowired private SkuMapper skuMapper; @Autowired private RedisTemplate redisTemplate; @Override public TbSku findById(String skuId) &#123; return skuMapper.findById(skuId); &#125; &#125; 123456789101112131415161718192021222324252627282930@Servicepublic class SpuServiceImpl implements SpuService &#123; @Autowired private SpuMapper spuMapper; /** * 根据ID查询 * @param id * @return */ @Override public TbSpu findById(String id)&#123; return spuMapper.findById(id); &#125; /** * 条件+分页查询 * @param searchMap 查询条件 * @param page 页码 * @param size 页大小 * @return 分页结果 */ @Override public Page&lt;TbSpu&gt; findPage(Map&lt;String,Object&gt; searchMap, int page, int size)&#123; PageHelper.startPage(page,size); return (Page&lt;TbSpu&gt;) spuMapper.search(searchMap); &#125;&#125; Controller1234567891011121314151617@RestController@CrossOrigin(origins = &quot;*&quot;)@RequestMapping(&quot;/sku&quot;)public class SkuController &#123; @Autowired private SkuService skuService; /*** * 根据ID查询数据 * @param id * @return */ @GetMapping(&quot;/&#123;id&#125;&quot;) public Result&lt;TbSku&gt; findById(@PathVariable(&quot;id&quot;) String id)&#123; TbSku sku = skuService.findById(id); return new Result(true,StatusCode.OK,&quot;查询成功&quot;,sku); &#125;&#125; 123456789101112131415161718192021222324252627282930313233@RestController@CrossOrigin(origins = &quot;*&quot;)@RequestMapping(&quot;/spu&quot;)public class SpuController &#123; @Autowired private SpuService spuService; /*** * 根据ID查询数据 * @param id * @return */ @GetMapping(&quot;/&#123;id&#125;&quot;) public Result&lt;TbSpu&gt; findById(@PathVariable(&quot;id&quot;) String id)&#123; TbSpu spu = spuService.findById(id); return new Result(true,StatusCode.OK,&quot;查询成功&quot;,spu); &#125; /*** * 分页搜索实现 * @param searchMap * @param page * @param size * @return */ @PostMapping(value = &quot;/search/&#123;page&#125;/&#123;size&#125;&quot; ) public Result&lt;TbSpu&gt; findPage(@RequestBody Map searchMap, @PathVariable Integer page, @PathVariable Integer size)&#123; com.github.pagehelper.Page&lt;TbSpu&gt; pageList = spuService.findPage(searchMap, page, size); PageResult pageResult=new PageResult&lt;TbSpu&gt;(pageList.getTotal(),pageList.getResult()); return new Result&lt;TbSpu&gt;(true,StatusCode.OK,&quot;查询成功&quot;,pageResult); &#125;&#125; 订单模块需求: 1). 下单业务分析 2). 根据条件分页查询订单 表结构: tb_order , tb_order_item , tb_order_log 创建工程1).pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869 &lt;dependencies &lt;dependency&gt; &lt;groupId&gt;cn.itcast&lt;/groupId&gt; &lt;artifactId&gt;v_common&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.itcast&lt;/groupId&gt; &lt;artifactId&gt;v_model&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.itcast&lt;/groupId&gt; &lt;artifactId&gt;v_feign_api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Eureka客户端依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- springboot - Mybatis 起步依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--MySQL数据库驱动--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mybatis分页插件--&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web起步依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- redis 使用--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- fastJson依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Feign依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2). application.yml 1234567891011121314151617181920212223242526server: port: 9002spring: application: name: order datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/v_shop?useUnicode=true&amp;characterEncoding=UTF-8&amp;serverTimezone=UTC username: root password: 2143 main: allow-bean-definition-overriding: true #当遇到同样名字的时候，是否允许覆盖注册eureka: client: fetch-registry: true register-with-eureka: true service-url: defaultZone: http://127.0.0.1:8161/eureka instance: prefer-ip-address: truefeign: client: config: default: #配置全局的feign的调用超时时间 如果 有指定的服务配置 默认的配置不会生效 connectTimeout: 60000 # 指定的是 消费者 连接服务提供者的连接超时时间 是否能连接 单位是毫秒 readTimeout: 20000 # 指定的是调用服务提供者的 服务 的超时时间（） 单位是毫秒 3). 引导类 12345678@SpringBootApplication@EnableEurekaClient@MapperScan(basePackages = &quot;cn.itcast.order.mapper&quot;)public class OrderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(OrderApplication.class,args); &#125;&#125; 下单业务分析 查询订单 Mapper1). mapper接口 123public interface OrderMapper &#123; public List&lt;TbOrder&gt; search(Map&lt;String,Object&gt; searchMap);&#125; 2). mapper映射配置文件 OrderMapper.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;mapper namespace=&quot;cn.itcast.order.mapper.OrderMapper&quot; &gt; &lt;resultMap id=&quot;orderResultMap&quot; type=&quot;cn.itcast.model.TbOrder&quot;&gt; &lt;id column=&quot;id&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;id&quot; /&gt; &lt;result column=&quot;total_num&quot; jdbcType=&quot;INTEGER&quot; property=&quot;totalNum&quot; /&gt; &lt;result column=&quot;total_money&quot; jdbcType=&quot;INTEGER&quot; property=&quot;totalMoney&quot; /&gt; &lt;result column=&quot;pre_money&quot; jdbcType=&quot;INTEGER&quot; property=&quot;preMoney&quot; /&gt; &lt;result column=&quot;post_fee&quot; jdbcType=&quot;INTEGER&quot; property=&quot;postFee&quot; /&gt; &lt;result column=&quot;pay_money&quot; jdbcType=&quot;INTEGER&quot; property=&quot;payMoney&quot; /&gt; &lt;result column=&quot;pay_type&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;payType&quot; /&gt; &lt;result column=&quot;create_time&quot; jdbcType=&quot;TIMESTAMP&quot; property=&quot;createTime&quot; /&gt; &lt;result column=&quot;update_time&quot; jdbcType=&quot;TIMESTAMP&quot; property=&quot;updateTime&quot; /&gt; &lt;result column=&quot;pay_time&quot; jdbcType=&quot;TIMESTAMP&quot; property=&quot;payTime&quot; /&gt; &lt;result column=&quot;consign_time&quot; jdbcType=&quot;TIMESTAMP&quot; property=&quot;consignTime&quot; /&gt; &lt;result column=&quot;end_time&quot; jdbcType=&quot;TIMESTAMP&quot; property=&quot;endTime&quot; /&gt; &lt;result column=&quot;close_time&quot; jdbcType=&quot;TIMESTAMP&quot; property=&quot;closeTime&quot; /&gt; &lt;result column=&quot;shipping_name&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;shippingName&quot; /&gt; &lt;result column=&quot;shipping_code&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;shippingCode&quot; /&gt; &lt;result column=&quot;username&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;username&quot; /&gt; &lt;result column=&quot;buyer_message&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;buyerMessage&quot; /&gt; &lt;result column=&quot;buyer_rate&quot; jdbcType=&quot;CHAR&quot; property=&quot;buyerRate&quot; /&gt; &lt;result column=&quot;receiver_contact&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;receiverContact&quot; /&gt; &lt;result column=&quot;receiver_mobile&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;receiverMobile&quot; /&gt; &lt;result column=&quot;receiver_province&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;receiverProvince&quot; /&gt; &lt;result column=&quot;receiver_city&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;receiverCity&quot; /&gt; &lt;result column=&quot;receiver_area&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;receiverArea&quot; /&gt; &lt;result column=&quot;receiver_address&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;receiverAddress&quot; /&gt; &lt;result column=&quot;source_type&quot; jdbcType=&quot;CHAR&quot; property=&quot;sourceType&quot; /&gt; &lt;result column=&quot;transaction_id&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;transactionId&quot; /&gt; &lt;result column=&quot;order_status&quot; jdbcType=&quot;CHAR&quot; property=&quot;orderStatus&quot; /&gt; &lt;result column=&quot;pay_status&quot; jdbcType=&quot;CHAR&quot; property=&quot;payStatus&quot; /&gt; &lt;result column=&quot;consign_status&quot; jdbcType=&quot;CHAR&quot; property=&quot;consignStatus&quot; /&gt; &lt;result column=&quot;is_delete&quot; jdbcType=&quot;CHAR&quot; property=&quot;isDelete&quot; /&gt; &lt;/resultMap&gt; &lt;select id=&quot;search&quot; resultType=&quot;cn.itcast.model.TbOrder&quot;&gt; SELECT o.id , o.`create_time` createTime, o.username , o.`total_money` totalMoney, o.`total_num` totalNum, o.`pay_type` payType, o.`pay_status` payStatus, p.`province` receiverProvince FROM tb_order o , tb_provinces p WHERE o.receiver_province = p.provinceid &lt;if test=&quot;orderId != null and orderId != &#x27;&#x27;&quot;&gt; and o.id = #&#123;orderId&#125; &lt;/if&gt; &lt;if test=&quot;payType != null and payType != &#x27;&#x27;&quot;&gt; and o.pay_type = #&#123;payType&#125; &lt;/if&gt; &lt;if test=&quot;username != null and username != &#x27;&#x27;&quot;&gt; and o.username = #&#123;username&#125; &lt;/if&gt; &lt;if test=&quot;payStatus != null and payStatus != &#x27;&#x27;&quot;&gt; and o.order_status = #&#123;payStatus&#125; &lt;/if&gt; &lt;/select&gt;&lt;/mapper&gt; Serviceservice接口 123456789101112131415161718public interface OrderService &#123; /*** * 新增 * @param order */ void add(TbOrder order); /*** * 多条件分页查询 * @param searchMap * @param page * @param size * @return */ Page&lt;TbOrder&gt; findPage(Map&lt;String, Object&gt; searchMap, int page, int size);&#125; service实现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Servicepublic class OrderServiceImpl implements OrderService &#123; @Autowired private OrderMapper orderMapper; @Autowired private OrderItemMapper orderItemMapper; @Autowired private IdWorker idWorker; /** * 增加 * @param order */ @Override public void add(TbOrder order)&#123; //1.获取购物车的相关数据(redis) //2.统计计算:总金额,总数量 //3.填充订单数据并保存到tb_order //4.填充订单项数据并保存到tb_order_item //5.记录订单日志 //6.扣减库存并增加销量 //7.删除购物车数据(redis) &#125; /** * 条件+分页查询 * @param searchMap 查询条件 * @param page 页码 * @param size 页大小 * @return 分页结果 */ @Override public Page&lt;TbOrder&gt; findPage(Map&lt;String,Object&gt; searchMap, int page, int size)&#123; PageHelper.startPage(page,size); return (Page&lt;TbOrder&gt;)orderMapper.search(searchMap); &#125;&#125; Controller123456789101112131415161718192021222324252627282930313233@RestController@CrossOrigin(value = &#123;&quot;*&quot;&#125;)@RequestMapping(&quot;/order&quot;)public class OrderController &#123; @Autowired private OrderService orderService; @PostMapping @OperateLog public Result add(@RequestBody TbOrder order)&#123; //获取登录人名称 orderService.add(order); return new Result(true,StatusCode.OK,&quot;提交成功&quot;); &#125; /*** * 分页搜索实现 * @param searchMap * @param page * @param size * @return */ @PostMapping(value = &quot;/search/&#123;page&#125;/&#123;size&#125;&quot; ) @OperateLog public Result findPage(@RequestBody Map searchMap, @PathVariable Integer page, @PathVariable Integer size)&#123; Page&lt;TbOrder&gt; pageList = orderService.findPage(searchMap, page, size); PageResult pageResult=new PageResult(pageList.getTotal(),pageList.getResult()); return new Result(true,StatusCode.OK,&quot;查询成功&quot;,pageResult); &#125;&#125; 日志模块表结构: tb_operatelog 需求: 1). 记录日志 2). 查询日志 创建工程1). pom.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;cn.itcast&lt;/groupId&gt; &lt;artifactId&gt;v_common&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.itcast&lt;/groupId&gt; &lt;artifactId&gt;v_model&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.itcast&lt;/groupId&gt; &lt;artifactId&gt;v_feign_api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Eureka客户端依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--MySQL数据库驱动--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mybatis分页插件--&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web起步依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- fastJson依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Feign依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2). application.yml 1234567891011121314151617181920server: port: 9003spring: application: name: log datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/v_shop?useUnicode=true&amp;characterEncoding=UTF-8&amp;serverTimezone=UTC username: root password: 2143 main: allow-bean-definition-overriding: true #当遇到同样名字的时候，是否允许覆盖注册eureka: client: fetch-registry: true register-with-eureka: true service-url: defaultZone: http://127.0.0.1:8161/eureka instance: prefer-ip-address: true 3). 引导类 12345678910111213@SpringBootApplication@EnableEurekaClient@MapperScan(basePackages = &quot;cn.itcast.log.mapper&quot;)public class LogApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(LogApplication.class,args); &#125; @Bean public IdWorker idworker()&#123; return new IdWorker(0,0); &#125;&#125; 分布式ID生成 snowflake是 Twitter 开源的分布式ID生成算法，结果是一个long型的ID。其核心思想是：使用41bit作为毫秒数，10bit作为机器的ID（5个bit是数据中心，5个bit的机器ID），12bit作为毫秒内的流水号（意味着每个节点在每毫秒可以产生 4096 个 ID），最后还有一个符号位，永远是0 ; 使用方式: 123456IdWorker idWorker=new IdWorker(1,1);//0-31 , 0-31for(int i=0;i&lt;10000;i++)&#123; long id = idWorker.nextId(); System.out.println(id);&#125; Mappermapper接口 1234567public interface OperateLogMapper &#123; public void insert(TbOperatelog operationLog); public List&lt;TbOperatelog&gt; search(Map searchMap);&#125; OperateLogMapper.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;mapper namespace=&quot;cn.itcast.log.mapper.OperateLogMapper&quot; &gt; &lt;resultMap id=&quot;operateLogResultMap&quot; type=&quot;cn.itcast.model.TbOperatelog&quot;&gt; &lt;id column=&quot;id&quot; jdbcType=&quot;BIGINT&quot; property=&quot;id&quot; /&gt; &lt;result column=&quot;model_name&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;modelName&quot; /&gt; &lt;result column=&quot;model_value&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;modelValue&quot; /&gt; &lt;result column=&quot;return_value&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;returnValue&quot; /&gt; &lt;result column=&quot;return_class&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;returnClass&quot; /&gt; &lt;result column=&quot;operate_user&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;operateUser&quot; /&gt; &lt;result column=&quot;operate_time&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;operateTime&quot; /&gt; &lt;result column=&quot;param_and_value&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;paramAndValue&quot; /&gt; &lt;result column=&quot;operate_class&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;operateClass&quot; /&gt; &lt;result column=&quot;operate_method&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;operateMethod&quot; /&gt; &lt;result column=&quot;cost_time&quot; jdbcType=&quot;BIGINT&quot; property=&quot;costTime&quot; /&gt; &lt;/resultMap&gt; &lt;insert id=&quot;insert&quot; parameterType=&quot;cn.itcast.model.TbOperatelog&quot;&gt; insert into tb_operatelog (id, model_name, model_value, return_value, return_class, operate_user, operate_time, param_and_value, operate_class, operate_method, cost_time) values (#&#123;id&#125;, #&#123;modelName&#125;, #&#123;modelValue&#125;, #&#123;returnValue&#125;, #&#123;returnClass&#125;, #&#123;operateUser&#125;, #&#123;operateTime&#125;, #&#123;paramAndValue&#125;, #&#123;operateClass&#125;, #&#123;operateMethod&#125;, #&#123;costTime&#125;) &lt;/insert&gt; &lt;select id=&quot;search&quot; resultMap=&quot;operateLogResultMap&quot;&gt; select * from tb_operatelog &lt;where&gt; &lt;if test=&quot;operateUser != null and operateUser != &#x27;&#x27;&quot;&gt; and operate_user = #&#123;operateUser&#125; &lt;/if&gt; &lt;if test=&quot;operateMethod != null and operateMethod != &#x27;&#x27;&quot;&gt; and operate_method = #&#123;operateMethod&#125; &lt;/if&gt; &lt;if test=&quot;returnClass != null and returnClass != &#x27;&#x27;&quot;&gt; and return_class = #&#123;returnClass&#125; &lt;/if&gt; &lt;if test=&quot;costTime != null and costTime != &#x27;&#x27; &quot;&gt; and cost_time = #&#123;costTime&#125; &lt;/if&gt; &lt;/where&gt; &lt;/select&gt;&lt;/mapper&gt; Service接口 12345public interface OperateLogService &#123; public void insert(TbOperatelog operationLog); public Page&lt;TbOperatelog&gt; findPage(Map searchMap, Integer pageNum , Integer pageSize);&#125; 实现 123456789101112131415161718192021222324@Service@Transactionalpublic class OperateLogServiceImpl implements OperateLogService &#123; @Autowired private OperateLogMapper operateLogMapper; public void insert(TbOperatelog operationLog)&#123; long id = idworker.nextId(); operationLog.setId(id); operateLogMapper.insert(operationLog); &#125; public Page&lt;TbOperatelog&gt; findPage(Map searchMap, Integer pageNum , Integer pageSize)&#123; System.out.println(searchMap); PageHelper.startPage(pageNum,pageSize); List&lt;TbOperatelog&gt; list = operateLogMapper.search(searchMap); return (Page&lt;TbOperatelog&gt;) list; &#125;&#125; Controller123456789101112131415161718192021222324@RestController@RequestMapping(&quot;/operateLog&quot;)public class OperateLogController &#123; @Autowired private OperateLogService operateLogService; @RequestMapping(&quot;/search/&#123;page&#125;/&#123;size&#125;&quot;) public Result findList(@RequestBody Map dataMap, @PathVariable Integer page, @PathVariable Integer size)&#123; Page&lt;TbOperatelog&gt; pageList = operateLogService.findPage(dataMap, page, size); PageResult pageResult=new PageResult(pageList.getTotal(),pageList.getResult()); return new Result(true, StatusCode.OK,&quot;查询成功&quot;,pageResult); &#125; @RequestMapping(&quot;/add&quot;) public Result add(@RequestBody TbOperatelog operatelog)&#123; operateLogService.insert(operatelog); return new Result(true,StatusCode.OK,&quot;添加成功&quot;); &#125;&#125; AOP记录日志在需要记录操作日志的微服务中, 引入AOP记录日志的类 : 1). 自定义注解 123456@Inherited@Documented@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface OperateLog &#123;&#125; 2). AOP通知类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657@Component@Aspectpublic class OperateAdvice &#123; @Autowired private OperateLogFeign operateLogFeign; @Around(&quot;execution(* cn.itcast.goods.controller.*.*(..)) &amp;&amp; @annotation(operateLog)&quot;) public Object insertLogAround(ProceedingJoinPoint pjp , OperateLog operateLog) throws Throwable&#123; System.out.println(&quot; *********************************** 记录日志 [start] ****************************** &quot;); TbOperatelog op = new TbOperatelog(); DateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); op.setOperateTime(sdf.format(new Date())); op.setOperateUser(&quot;10000&quot;); op.setOperateClass(pjp.getTarget().getClass().getName()); op.setOperateMethod(pjp.getSignature().getName()); String paramAndValue = &quot;&quot;; Object[] args = pjp.getArgs(); if(args != null)&#123; for (Object arg : args) &#123; if(arg instanceof String || arg instanceof Integer || arg instanceof Long)&#123; paramAndValue += arg +&quot;,&quot;; &#125;else&#123; paramAndValue += JSON.toJSONString(arg)+&quot;,&quot;; &#125; &#125; op.setParamAndValue(paramAndValue); &#125; long start_time = System.currentTimeMillis(); //放行 Object object = pjp.proceed(); long end_time = System.currentTimeMillis(); op.setCostTime(end_time - start_time); if(object != null)&#123; op.setReturnClass(object.getClass().getName()); op.setReturnValue(object.toString()); &#125;else&#123; op.setReturnClass(&quot;java.lang.Object&quot;); op.setParamAndValue(&quot;void&quot;); &#125; operateLogFeign.add(op); System.out.println(&quot; *********************************** 记录日志 [end] ****************************** &quot;); return object; &#125;&#125; MyCat分片当前数据库的情况 : 由于当前项目是一个电商项目，项目上线后，随着项目的运营，业务系统的数据库中的数据与日俱增，特别是订单、日志等数据，如果数据量过大，这个时候就需要考虑通过MyCat分库分表。 分片分析1). 垂直拆分 数据量过大，需要考虑扩容，可以通过MyCat来实现数据库表的垂直拆分，将同一块业务的数据库表拆分到同一个数据库服务中。拆分方式如下： 2). 全局表 按照上述的方式进行表结构的拆分，可以解决扩容的问题，但是存在另一个问题：由于省、市、区县、数据字典表，在订单及商品等模块中都需要用到，还会涉及到多表连接查询，那么这个时候涉及到跨库的join操作，可以使用全局表来解决。结构图如下： 3). 水平拆分 即使我们在上述的方案中使用垂直拆分，将系统中的表结构拆分到了三个数据库服务器中，但是对于当前这个比较繁忙的业务系统来说，每天都会产生大量的用户操作日志，长年累月，这张表的数据在单台服务器中已经存储不下了，这个时候，我们就可以使用MyCat的水平拆分来解决这个问题。 服务器配置 名称 IP 端口 用户名/密码 MyCat-Server 192.168.192.157 8066 root/123456 MySQL-1 192.168.192.158 3306 root/itcast MySQL-2 192.168.192.159 3306 root/itcast MySQL-3 192.168.192.160 3306 root/itcast MySQL-4 192.168.192.161 3306 root/itcast schema.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;?xml version=&quot;1.0&quot;?&gt;&lt;!DOCTYPE mycat:schema SYSTEM &quot;schema.dtd&quot;&gt;&lt;mycat:schema xmlns:mycat=&quot;http://io.mycat/&quot;&gt; &lt;schema name=&quot;V_SHOP&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot;&gt; &lt;table name=&quot;tb_areas&quot; dataNode=&quot;dn1,dn2,dn3,dn4&quot; primaryKey=&quot;areaid&quot; type=&quot;global&quot;/&gt; &lt;table name=&quot;tb_provinces&quot; dataNode=&quot;dn1,dn2,dn3,dn4&quot; primaryKey=&quot;provinceid&quot; type=&quot;global&quot;/&gt; &lt;table name=&quot;tb_cities&quot; dataNode=&quot;dn1,dn2,dn3,dn4&quot; primaryKey=&quot;cityid&quot; type=&quot;global&quot;/&gt; &lt;table name=&quot;tb_dictionary&quot; dataNode=&quot;dn1,dn2,dn3,dn4&quot; primaryKey=&quot;id&quot; type=&quot;global&quot;/&gt; &lt;table name=&quot;tb_brand&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;id&quot; /&gt; &lt;table name=&quot;tb_category&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;id&quot; /&gt; &lt;table name=&quot;tb_sku&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;id&quot; /&gt; &lt;table name=&quot;tb_spu&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;id&quot; /&gt; &lt;table name=&quot;tb_order&quot; dataNode=&quot;dn2&quot; primaryKey=&quot;id&quot; /&gt; &lt;table name=&quot;tb_order_item&quot; dataNode=&quot;dn2&quot; primaryKey=&quot;id&quot; /&gt; &lt;table name=&quot;tb_order_log&quot; dataNode=&quot;dn2&quot; primaryKey=&quot;id&quot; /&gt; &lt;table name=&quot;tb_operatelog&quot; dataNode=&quot;dn3,dn4&quot; primaryKey=&quot;id&quot; rule=&quot;log-sharding-by-murmur&quot;/&gt; &lt;/schema&gt; &lt;dataNode name=&quot;dn1&quot; dataHost=&quot;host1&quot; database=&quot;v_goods&quot; /&gt; &lt;dataNode name=&quot;dn2&quot; dataHost=&quot;host2&quot; database=&quot;v_order&quot; /&gt; &lt;dataNode name=&quot;dn3&quot; dataHost=&quot;host3&quot; database=&quot;v_log&quot; /&gt; &lt;dataNode name=&quot;dn4&quot; dataHost=&quot;host4&quot; database=&quot;v_log&quot; /&gt; &lt;dataHost name=&quot;host1&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=&quot;hostM1&quot; url=&quot;192.168.192.158:3306&quot; user=&quot;root&quot; password=&quot;itcast&quot;&gt; &lt;/writeHost&gt; &lt;/dataHost&gt; &lt;dataHost name=&quot;host2&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=&quot;hostM2&quot; url=&quot;192.168.192.159:3306&quot; user=&quot;root&quot; password=&quot;itcast&quot;&gt;&lt;/writeHost&gt; &lt;/dataHost&gt; &lt;dataHost name=&quot;host3&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=&quot;hostM3&quot; url=&quot;192.168.192.160:3306&quot; user=&quot;root&quot; password=&quot;itcast&quot;&gt;&lt;/writeHost&gt; &lt;/dataHost&gt; &lt;dataHost name=&quot;host4&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=&quot;hostM4&quot; url=&quot;192.168.192.161:3306&quot; user=&quot;root&quot; password=&quot;itcast&quot;&gt;&lt;/writeHost&gt; &lt;/dataHost&gt; &lt;/mycat:schema&gt; 分片配置1). 配置Mycat的schema.xml 2). 配置rule.xml 123456789101112&lt;tableRule name=&quot;log-sharding-by-murmur&quot;&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;log-murmur&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt;&lt;function name=&quot;log-murmur&quot; class=&quot;io.mycat.route.function.PartitionByMurmurHash&quot;&gt; &lt;property name=&quot;seed&quot;&gt;0&lt;/property&gt; &lt;property name=&quot;count&quot;&gt;2&lt;/property&gt; &lt;property name=&quot;virtualBucketTimes&quot;&gt;160&lt;/property&gt;&lt;/function&gt; 3). 配置server.xml 12345678910111213141516&lt;user name=&quot;root&quot; defaultAccount=&quot;true&quot;&gt; &lt;property name=&quot;password&quot;&gt;GO0bnFVWrAuFgr1JMuMZkvfDNyTpoiGU7n/Wlsa151CirHQnANVk3NzE3FErx8v6pAcO0ctX3xFecmSr+976QA==&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;V_SHOP&lt;/property&gt; &lt;property name=&quot;readOnly&quot;&gt;false&lt;/property&gt; &lt;property name=&quot;benchmark&quot;&gt;1000&lt;/property&gt; &lt;property name=&quot;usingDecrypt&quot;&gt;1&lt;/property&gt; &lt;!-- 表级 DML 权限设置 &lt;privileges check=&quot;true&quot;&gt; &lt;schema name=&quot;ITCAST&quot; dml=&quot;1111&quot; &gt; &lt;table name=&quot;TB_TEST&quot; dml=&quot;1110&quot;&gt;&lt;/table&gt; &lt;/schema&gt; &lt;/privileges&gt; --&gt; &lt;/user&gt; 4). 在各个MySQL数据库实例中创建数据库 1234MySQL-1 : v_goodsMySQL-2 : v_orderMySQL-3 : v_logMySQL-4 : v_log 5). 导出本地的SQL脚本 , 在MyCat中执行SQL脚本 , 创建数据表 ,并导入数据 6). 连接测试 微服务连接MyCat12345datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://192.168.192.157:8066/V_SHOP?useUnicode=true&amp;characterEncoding=UTF-8&amp;serverTimezone=UTC username: root password: 123456 配置MyCat-Web监控1). 启动Zookeeper 2). 启动MyCat-Web 3). 访问 http://192.168.192.157:8082/mycat 界面:","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://zsc-cloud.github.io/categories/MySQL/"},{"name":"MyCat","slug":"MySQL/MyCat","permalink":"https://zsc-cloud.github.io/categories/MySQL/MyCat/"}],"tags":[{"name":"MyCat","slug":"MyCat","permalink":"https://zsc-cloud.github.io/tags/MyCat/"},{"name":"分库分表","slug":"分库分表","permalink":"https://zsc-cloud.github.io/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"}]},{"title":"SQL语句","slug":"SQL语句","date":"2021-06-01T08:00:50.000Z","updated":"2021-06-06T03:28:12.373Z","comments":true,"path":"2021/06/01/SQL语句/","link":"","permalink":"https://zsc-cloud.github.io/2021/06/01/SQL%E8%AF%AD%E5%8F%A5/","excerpt":"","text":"1234567891011121314151617181920212223242526# 直接将查询结果导入或复制到新创建的表CREATE TABLE n SELECT * FROM m;# 删除一个存在表DROP TABLE IF EXISTS m;# 更改存在表的名称ALTER TABLE n RENAME m;# 添加列ALTER TABLE table_name ADD 列名 INT（11）# 删除列ALTER TABLE mytable DROP COLUMN col;# 插入数据INSERT INTO mytable(col1, col2) VALUES(val1, val2);# 修改数据UPDATE mytable SET col = val WHERE id = 1;# DESTINCT:去重。相同值只会出现一次。它作用于所有列，也就是说**所有列的值都相同才算相同SELECT DISTINCT col1, col2 FROM mytable;# 添加索引ALTER TABLE n ADD INDEX i_age (age) 模糊查询通常使用拼接字符串形式： 1like concat(‘%’，#&#123;xxx&#125;,&#x27;%&#x27;) WHERE 过滤行，HAVING 过滤分组，行过滤应当先于分组过滤 除了汇总字段外，SELECT 语句中的每一字段都必须在 GROUP BY 子句中给出； 12345SELECT col, COUNT(*) AS numFROM mytableWHERE col &gt; 2GROUP BY colHAVING num &gt;= 2; UNION ：组合查询 使用 UNION 来组合两个查询，如果第一个查询返回 M 行，第二个查询返回 N 行，那么组合查询的结果一般为 M+N 行。 每个查询必须包含相同的列、表达式和聚集函数。 默认会去除相同行，如果需要保留相同行，使用 UNION ALL 只能包含一个 ORDER BY 子句，并且必须位于语句的最后。 **IFNULL(expr1,expr2)**：如果第一个参数不为空，则返回第一个参数，否则返回第二个参数。 **ISNULL(expr)**：判断是否是空，是空则返回1，否则返回0。 **IF(expr1,expr2,expr3)**：如果第一个表达式的值为TRUE（不为0或null），则返回第二个参数的值，否则返回第三个参数的值。 SQL的执行顺序12345678910(1) SELECT(2) DISTINCT &lt;select_list&gt;(3) FROM &lt;left_table&gt;(4) &lt;join_type&gt; JOIN &lt;right_table&gt;(5) ON &lt;join_condition&gt;(6) WHERE &lt;where_condition&gt;(7) GROUP BY &lt;group_by_list&gt;(8) HAVING &lt;having_condition&gt;(9) ORDER BY &lt;order_by_condition&gt;(10) LIMIT &lt;limit_number&gt; case when then else end语句用于查询满足多种条件的情况，类似java中的if…else，还有的就是用于进行行转列的查询，这个是放在select 子句后面的，是充当的是字段的作用。 具体用法就是：分为两种，一种是简单的函数形式，另一种就是表达式的形式。 简单的函数形式： 1case 字段 when 值 then 结果 else 其他情况 end； 表达式的形式： 1case when 字段=值（这里写表达式，例如 score=80） then 结果 else 其他情况 end； 注意：THEN后边的值与ELSE后边的值类型应一致，否则会报错 Other函数1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071# 聚合函数SELECT count(id) AS total FROM n; # 总数SELECT sum(age) AS all_age FROM n; # 总和SELECT avg(age) AS all_age FROM n; # 平均值SELECT max(age) AS all_age FROM n; # 最大值SELECT min(age) AS all_age FROM n; # 最小值# 数学函数SELECT abs(-5); # 绝对值SELECT bin(15), oct(15), hex(15); # 二进制，八进制，十六进制SELECT pi(); # 圆周率3.141593SELECT ceil(5.5); # 大于x的最小整数值6SELECT floor(5.5); # 小于x的最大整数值5SELECT greatest(3,1,4,1,5,9,2,6); # 返回集合中最大的值9SELECT least(3,1,4,1,5,9,2,6); # 返回集合中最小的值1SELECT mod(5,3); # 余数2SELECT rand(); # 返回０到１内的随机值，每次不一样SELECT rand(5); # 提供一个参数(种子)使RAND()随机数生成器生成一个指定的值。SELECT round(1415.1415); # 四舍五入1415SELECT round(1415.1415, 3); # 四舍五入三位数1415.142SELECT round(1415.1415, -1); # 四舍五入整数位数1420SELECT truncate(1415.1415, 3); # 截短为3位小数1415.141SELECT truncate(1415.1415, -1); # 截短为-1位小数1410SELECT sign(-5); # 符号的值负数-1SELECT sign(5); # 符号的值正数1SELECT sqrt(9); # 平方根3SELECT sqrt(9); # 平方根3# 字符串函数SELECT concat(&#x27;a&#x27;, &#x27;p&#x27;, &#x27;p&#x27;, &#x27;le&#x27;); # 连接字符串-appleSELECT concat_ws(&#x27;,&#x27;, &#x27;a&#x27;, &#x27;p&#x27;, &#x27;p&#x27;, &#x27;le&#x27;); # 连接用&#x27;,&#x27;分割字符串-a,p,p,leSELECT insert(&#x27;chinese&#x27;, 3, 2, &#x27;IN&#x27;); # 将字符串&#x27;chinese&#x27;从3位置开始的2个字符替换为&#x27;IN&#x27;-chINeseSELECT left(&#x27;chinese&#x27;, 4); # 返回字符串&#x27;chinese&#x27;左边的4个字符-chinSELECT right(&#x27;chinese&#x27;, 3); # 返回字符串&#x27;chinese&#x27;右边的3个字符-eseSELECT substring(&#x27;chinese&#x27;, 3); # 返回字符串&#x27;chinese&#x27;第三个字符之后的子字符串-ineseSELECT substring(&#x27;chinese&#x27;, -3); # 返回字符串&#x27;chinese&#x27;倒数第三个字符之后的子字符串-eseSELECT substring(&#x27;chinese&#x27;, 3, 2); # 返回字符串&#x27;chinese&#x27;第三个字符之后的两个字符-inSELECT trim(&#x27; chinese &#x27;); # 切割字符串&#x27; chinese &#x27;两边的空字符-&#x27;chinese&#x27;SELECT ltrim(&#x27; chinese &#x27;); # 切割字符串&#x27; chinese &#x27;两边的空字符-&#x27;chinese &#x27;SELECT rtrim(&#x27; chinese &#x27;); # 切割字符串&#x27; chinese &#x27;两边的空字符-&#x27; chinese&#x27;SELECT repeat(&#x27;boy&#x27;, 3); # 重复字符&#x27;boy&#x27;三次-&#x27;boyboyboy&#x27;SELECT reverse(&#x27;chinese&#x27;); # 反向排序-&#x27;esenihc&#x27;SELECT length(&#x27;chinese&#x27;); # 返回字符串的长度-7SELECT upper(&#x27;chINese&#x27;), lower(&#x27;chINese&#x27;); # 大写小写 CHINESE chineseSELECT ucase(&#x27;chINese&#x27;), lcase(&#x27;chINese&#x27;); # 大写小写 CHINESE chineseSELECT position(&#x27;i&#x27; IN &#x27;chinese&#x27;); # 返回&#x27;i&#x27;在&#x27;chinese&#x27;的第一个位置-3SELECT position(&#x27;e&#x27; IN &#x27;chinese&#x27;); # 返回&#x27;i&#x27;在&#x27;chinese&#x27;的第一个位置-5SELECT strcmp(&#x27;abc&#x27;, &#x27;abd&#x27;); # 比较字符串，第一个参数小于第二个返回负数- -1SELECT strcmp(&#x27;abc&#x27;, &#x27;abb&#x27;); # 比较字符串，第一个参数大于第二个返回正数- 1# 时间函数SELECT current_date, current_time, now(); # 2018-01-13 12:33:43 2018-01-13 12:33:43SELECT hour(current_time), minute(current_time), second(current_time); # 12 31 34SELECT year(current_date), month(current_date), week(current_date); # 2018 1 1SELECT quarter(current_date); # 1SELECT monthname(current_date), dayname(current_date); # January SaturdaySELECT dayofweek(current_date), dayofmonth(current_date), dayofyear(current_date); # 7 13 13# 控制流函数SELECT if(3&gt;2, &#x27;t&#x27;, &#x27;f&#x27;), if(3&lt;2, &#x27;t&#x27;, &#x27;f&#x27;); # t fSELECT ifnull(NULL, &#x27;t&#x27;), ifnull(2, &#x27;t&#x27;); # t 2SELECT isnull(1), isnull(1/0); # 0 1 是null返回1，不是null返回0SELECT nullif(&#x27;a&#x27;, &#x27;a&#x27;), nullif(&#x27;a&#x27;, &#x27;b&#x27;); # null a 参数相同或成立返回null，不同或不成立则返回第一个参数SELECT CASE 2 WHEN 1 THEN &#x27;first&#x27; WHEN 2 THEN &#x27;second&#x27; WHEN 3 THEN &#x27;third&#x27; ELSE &#x27;other&#x27; END ; # second# 系统信息函数SELECT database(); # 当前数据库名-testSELECT connection_id(); # 当前用户id-306SELECT user(); # 当前用户-root@localhostSELECT version(); # 当前mysql版本SELECT found_rows(); # 返回上次查询的检索行数 用户1234567891011121314151617# 增加用户CREATE USER &#x27;test&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;test&#x27;;INSERT INTO mysql.user(Host, User, Password) VALUES (&#x27;localhost&#x27;, &#x27;test&#x27;, Password(&#x27;test&#x27;)); # 在用户表中插入用户信息，直接操作User表不推荐# 删除用户DROP USER &#x27;test&#x27;@&#x27;localhost&#x27;;DELETE FROM mysql.user WHERE User=&#x27;test&#x27; AND Host=&#x27;localhost&#x27;;FLUSH PRIVILEGES ;# 更改用户密码SET PASSWORD FOR &#x27;test&#x27;@&#x27;localhost&#x27; = PASSWORD(&#x27;test&#x27;);UPDATE mysql.user SET Password=Password(&#x27;t&#x27;) WHERE User=&#x27;test&#x27; AND Host=&#x27;localhost&#x27;;FLUSH PRIVILEGES ;# 用户授权GRANT ALL PRIVILEGES ON *.* TO test@localhost IDENTIFIED BY &#x27;test&#x27;;# 授予用&#x27;test&#x27;密码登陆成功的test@localhost用户操作所有数据库的所有表的所有的权限FLUSH PRIVILEGES ; # 刷新系统权限表,使授予权限生效# 撤销用户授权REVOKE DELETE ON *.* FROM &#x27;test&#x27;@&#x27;localhost&#x27;; # 取消该用户的删除权限","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://zsc-cloud.github.io/categories/MySQL/"},{"name":"SQL语句","slug":"MySQL/SQL语句","permalink":"https://zsc-cloud.github.io/categories/MySQL/SQL%E8%AF%AD%E5%8F%A5/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://zsc-cloud.github.io/tags/MySQL/"},{"name":"数据库","slug":"数据库","permalink":"https://zsc-cloud.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"Linux定时备份MySQL数据库文件","slug":"Linux定时备份MySQL数据库文件","date":"2021-05-23T12:51:36.000Z","updated":"2022-03-26T03:42:17.259Z","comments":true,"path":"2021/05/23/Linux定时备份MySQL数据库文件/","link":"","permalink":"https://zsc-cloud.github.io/2021/05/23/Linux%E5%AE%9A%E6%97%B6%E5%A4%87%E4%BB%BDMySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6/","excerpt":"","text":"记录一下定时备份数据库的方法 Linux里有一个 crontab 命令被用来提交和管理用户的需要周期性执行的任务，就像Windows里的定时任务一样，用这个就可以设置定时任务去执行相应的操作。 所以，我们通过创建一个shell文件，把执行的命令放在里面，然后再用crontab去定时执行就可以达到我们想要的效果了。 创建一个文件夹存放备份文件这里我是放在/home/deployer路径下 12cd /home/deployermkdir backup 创建备份的shell文件touch back_sql.sh 编辑这个脚本：vim back_mysql.sh 如果没有vim在安装一下：yum -y install vim* 脚本内容格式如下： 123#!/bin/bash/usr/local/mysql/bin/mysqldump(这个路径是你mysqldump所在路径) -u用户名 -p密码 数据库名 &gt; /home/backup/数据库名_$(date +%Y%m%d_%H%M%S).sql 如果你要备份成压缩文件的话，可以写成下面这个命令 123#!/bin/bash/usr/local/mysql/bin/mysqldump -u用户名 -p密码 数据库名 | gzip &gt; /home/backup/数据库名_$(date +%Y%m%d_%H%M%S).sql.gz 这个是我的sh 1234#!/bin/bash/home/server/mysql/bin/mysqldump -uroot -p123456 xh_wx &gt; /home/deployer/backup/xh_wx_$(date +%Y%m%d).sql 添加好后记得保存 1234:wq -保存文件，退出 vim:wq! -强制保存文件，退出 vim:q -不保存文件，退出 vim:q! -不保存文件，强制退出 vim 修改脚本权限123chmod 777 back_sql.sh或者chmod u+x back_sql.sh 测试测试一下这个shell是否能执行，输入文件名即可直接执行 ./back_mysql.sh 执行后去backup文件夹里看看，是否有导出来的文件 在crontab中设置定时任务1234567先检查一下是否安装：如果已安装则请略过安装命令yum -y install vixie-cronyum -y install crontabs在CentOS系统中加入开机自动启动: chkconfig --level 345 crond on 输入命令进入crontab任务设置 : crontab -e 在里面添加以下命令: 00 02 * * * /home/deployer/backup/back_sql.sh 然后保存退出 “ 00 02 * * * ”是crontab的时间规则，即执行周期，我写的这句解析后就是每天的 02:00 执行一次该目录下的那个bk_mysql.sh文件. 执行周期可以按照自己的需求来设定 crontab的格式很灵活，每天每小时，具体哪一天都可以设置。在这里就不展开说明了 运行一段时间的效果，这是我服务器上的备份文件","categories":[{"name":"问题随笔","slug":"问题随笔","permalink":"https://zsc-cloud.github.io/categories/%E9%97%AE%E9%A2%98%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zsc-cloud.github.io/tags/Linux/"}]},{"title":"Redis持久化","slug":"Redis持久化","date":"2021-05-14T08:25:38.000Z","updated":"2022-03-26T03:42:17.308Z","comments":true,"path":"2021/05/14/Redis持久化/","link":"","permalink":"https://zsc-cloud.github.io/2021/05/14/Redis%E6%8C%81%E4%B9%85%E5%8C%96/","excerpt":"","text":"redis持久化的意义redis的数据全部在内存中，如果突然宕机，数据就会全部丢失，因此必须有一种机制来保证redis的数据在遇到突发状况的时候不会丢失，或者只丢失少量，于是必须根据一些策略来把redis内存中的数据写到磁盘中，这样当redis服务重启中，就可以根据磁盘中的数据来恢复数据到内存中。 redis持久化机制redis有两种持久化机制：AOF和RDB (1) RDBRDB是一次的全量备份，即周期性的把redis当前内存中的全量数据写入到一个快照文件中。redis是单线程程序，这个线程要同时负责多个客户端的读写请求，还要负责周期性的把当前内存中的数据写到快照文件中RDB中，数据写到RDB文件是IO操作，IO操作会严重影响redis的性能，甚至在持久化的过程中，读写请求会阻塞，为了解决这些问题，redis需要同时进行读写请求和持久化操作，这样又会导致另外的问题，持久化的过程中，内存中的数据还在改变，假如redis正在进行持久化一个大的数据结构，在这个过程中客户端发送一个删除请求，把这个大的数据结构删掉了，这时候持久化的动作还没有完成，那么redis该怎么办呢？ redis使用操作系统的多进程COW机制(Copy On Write)机制来实现快照的持久化，在持久化过程中调用 glibc(Linux下的C函数库) 的函数fork()产生一个子进程，快照持久化完全交给子进程来处理，父进程继续处理客户端的读写请求。子进程刚刚产生时，和父进程共享内存里面的代码段和数据段，这是Linux操作系统的机制，为了节约内存资源，所以尽可能让父子进程共享内存，这样在进程分离的一瞬间，内存的增长几乎没有明显变化。 子进程对当前内存中的数据进行持久化，并不会修改当前的数据结构，如果父进程收到了读写请求，那么会把处理的那一部分数据复制一份到内存，对复制后的数据进行修改，所以即使对某个数据进行了修改，redis持久化到RDB中的数据也是未修改的数据，这也是把RDB文件称为”快照”文件的原因，子进程所看到的数据在它被创建的一瞬间就固定下来了，父进程修改的某个数据只是该数据的复制品。 实际上，内存中的全量数据由一个个的”数据段页面“组成，每个数据段页面的大小为4K，客户端要修改的数据在哪个页面中，就会复制一份这个页面到内存中，这个复制的过程称为”页面分离“，在持久化过程中，随着分离出的页面越来越多，内存就会持续增长，但是不会超过原内存的2倍，因为在一次持久化的过程中，几乎不会出现所有的页面都会分离的情况，读写请求针对的只是原数据中的小部分，大部分redis数据还是”冷数据“。 (2) AOFAOF日志存储的是redis服务器的顺序指令序列，即对内存中数据进行修改的指令记录。当redis收到客户端修改指令后，先进行参数校验，如果校验通过，先把该指令存储到AOF日志文件中，也就是先存到磁盘，然后再执行该修改指令。 当redis宕机后重启后，可以读取该AOF文件中的指令，进行数据恢复，恢复的过程就是把记录的指令再顺序执行一次，这样就可以恢复到宕机之前的状态。 redis在长期运行过程中，AOF日志会越来越大，如果redis服务重启后根据很大的AOF文件来顺序执行指令，将会非常耗时，导致redis服务长时间无法对外提供服务，所以需要对AOF文件进行”瘦身”。”瘦身”的过程称作AOF重写(rewrite)。 AOF Rewrite 的原理是，主进程fork一个子进程，对当前内存中的数据进行遍历，转换成一系列的redis操作指令，并序列化到一个新的AOF日志中，然后把序列化操作期间新收到的操作指令追加到新的AOF文件中，追加完毕后就立即替换旧的AOF文件，这样就完成了”瘦身”工作，即AOF Rewrite。 redis把操作指令追加到AOF文件这个过程，并不是直接写到AOF文件中，而是先写到操作系统的内存缓存中，这个内存缓存是由操作系统内核分配的，然后操作系统内核会异步地把内存缓存中的redis操作指令刷写到AOF文件中。 一个新问题是，假如内存缓存中的redis指令还没有来得及刷写到AOF文件中就宕机了，那么这部分未刷写的指令就会丢失，不过，glibc函数库提供了 fsync() 函数，该函数可以将指定文件的内容强制从内存缓存中刷写到磁盘上。fsync操作的周期对redis的性能有很大影响，如何配置将在本文后续的内容中给出建议。 AOF过程 AOF Rewrite过程 (3) redis-4.x 混合持久化重启redis时，我们很少使用RDB来恢复内存状态，因为会丢失大量数据。我们通常使用AOF日志重放，但是重放AOF日志性能相对RDB来说要慢很多，这样在redis实例很大的情况下，启动需要花费很长的时间。redis-4.0为了解决这个问题，带来了一个新的持久化选项——混合持久化。将RDB文件的内容和增量的AOF日志文件存在一起。这里的AOF日志不再是全量的日志，而是自持久化开始到持久化结束的这段时间发生的增量AOF日志，通常这部分AOF日志很小。 redis-4.x混合持久化机制 redis重启的时候，可以先加载RDB的内容，然后再重放增量AOF日志，就可以完全替代之前的AOF全量文件重放，恢复效率因此大幅得到提升。 redis 持久化机制对比(1) RDB的优缺点优点： RDB会生成多个数据文件，每个数据文件都代表了某一个时刻中redis的数据，这种多个数据文件的方式，非常适合做冷备，可以将这种完整的数据文件发送到一些远程的安全存储上去。 当进行RDB持久化时，对redis服务处理读写请求的影响非常小，可以让redis保持高性能，因为redis主进程只需要fork一个子进程，让子进程执行磁盘IO操作来进行RDB持久化即可。生成一次RDB文件的过程就是把当前时刻内存中的数据一次性写入文件中，而AOF则需要先把当前内存中的小量数据转换为操作指令，然后把指令写到内存缓存中，然后再刷写入磁盘。 相对于AOF持久化机制来说，直接基于RDB数据文件来重启和恢复redis的数据会更加快速。AOF，存放的是指令日志，做数据恢复的时候，要回放和执行所有的指令日志，从而恢复内存中的所有数据。而RDB，就是一份数据文件，恢复的时候，直接加载到内存中即可。 缺点： 如果想要在redis故障时，尽可能少的丢失数据，那么RDB没有AOF好。一般来说，RDB数据快照文件，都是每隔5分钟，或者更长时间生成一次，这个时候就得接受一旦redis进程宕机，那么会丢失最近5分钟的数据。这个问题，也是RDB最大的缺点，就是不适合做第一优先的恢复方案，如果你依赖RDB做第一优先恢复方案，会导致数据丢失的比较多。 RDB每次在fork子进程来执行RDB快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，甚至数秒。所以一般不要让生成RDB文件的间隔太长，否则每次生成的RDB文件太大了，对redis本身的性能会有影响。 (2) AOF的优缺点优点： AOF可以更好的保护数据不丢失，一般AOF会每隔1秒，通过一个后台线程执行一次fsync操作，最多丢失1秒钟的数据。 AOF日志文件以append-only模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复。 AOF日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在rewrite的时候，会对其中的指令进行压缩，会创建出一份需要恢复数据的最小日志出来。 AOF日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用flushall命令清空了所有数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝AOF文件，将最后一条flushall命令给删了，然后再将该AOF文件放回去，就可以通过恢复机制，自动恢复所有数据。 缺点： 对于同一份数据来说，AOF日志文件通常比RDB数据快照文件更大。 AOF的写性能比RDB的写性能低，因为AOF一般会配置成每秒fsync一次日志文件，当然，每秒一次fsync，性能也还是很高的，只不过比起RDB来说性能低，如果要保证一条数据都不丢，也是可以的，AOF的fsync设置成每写入一条数据，fsync一次，但是这样，redis的性能会大大下降。 基于AOF文件做恢复的速度不如基于RDB文件做恢复的速度。 (3) 混合持久化的优缺点优点：结合了RDB和AOF的优点，使得数据恢复的效率大幅提升 缺点：兼容性不好，redis-4.x新增，虽然最终的文件也是.aof格式的文件，但在4.0之前版本都不识别该aof文件，同时由于前部分是RDB格式，阅读性较差。 如何选择redis持久化机制RDB和AOF到底该如何选择 不要仅仅使用RDB，因为那样会导致你丢失很多数据 也不要仅仅使用AOF，一是数据恢复慢，二是可靠性也不如RDB，毕竟RDB文件中存储的就是某一时刻实实在在的数据，而AOF只是操作指令，把数据转换为操作指令不一定是百分百没问题的。 综合使用AOF和RDB两种持久化机制，用AOF来保证数据不丢失，作为数据恢复的第一选择; 用RDB来做不同程度的冷备，在AOF文件都丢失或损坏不可用的时候，还可以使用RDB来进行快速的数据恢复 redis重启的时候，先加载RDB的内容，然后再重放增量AOF日志， (5) AOF和RDB同时工作 redis在写RDB文件的时候不会执行AOF rewrite; redis在执行AOF rewrite的时候不会生成新的RDB; 如果redis正在生成新的RDB文件，此时用户执行bgrewriteaof命令手动重写AOF文件，那么等RDB快照生成之后，才会去执行AOF rewrite； 同时有RDB文件和AOF日志文件，那么redis重启的时候，会优先使用AOF进行数据恢复，因为其中的日志更完整。 redis 持久化机制的配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556######################### 通用 ########################## 持久化文件(包括RDB文件和AOF文件)的存储目录，默认.dir dir /home/hadoop/data/redis/6379######################### RDB ########################## RDB文件的文件名称，默认dump.rdbdbfilename dump.rdb# 生成RDB文件的策略，默认为以下3种，意思是：# 每隔60s(1min)，如果有超过10000个key发生了变化，就写一份新的RDB文件# 每隔300s(5min)，如果有超过10个key发生了变化，就写一份新的RDB文件# 每隔900s(15min)，如果有超过1个key发生了变化，就写一份新的RDB文件# 配置多种策略可以同时生效，无论满足哪一种条件都会写一份新的RDB文件save 900 1save 300 10save 60 10000# 是否开启RDB文件压缩，该功能可以节约磁盘空间，默认为yesrdbcompression yes# 在写入文件和读取文件时是否开启rdb文件检查，检查是否有无损坏# 如果在启动时检查发现文件损坏，则停止启动，默认yesrdbchecksum yes######################### AOF ########################## 是否开启AOF机制，默认为noappendonly yes# AOF文件的名称，默认为appendonly.aofappendfilename &quot;appendonly.aof&quot;# fsync的策略，默认为everysec# everysec：每秒fsync一次# no：redis不主动fsync，完全交由操作系统决定# always：1条指令fsync一次appendfsync everysec# AOF文件rewrite策略# 当上一次重写后的AOF文件的增长比例达到100%# 比如上一次重写AOF文件后，新文件大小为128M# 当新文件再次增长了100%，达到了256M# 并且增长了100%后的文件的大小大于64M，那么开始重写AOF文件auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb# 是否加载破损的AOF文件，默认为yes，如果设置为no# 那么redis启动时如果发现AOF文件破损，就会报错并且拒绝启动redis服务。aof-load-truncated yes######################### 混合持久化 ########################## 是否开启混合持久化机制，默认为noaof-use-rdb-preamble no 建议配置：把appendonly设置为yes，根据需要修改dir，其他均保持默认即可。 其他相关命令 手动生成新的RDB文件 1234# 阻塞主进程，直到生成新的RDB文件save # 异步生成RDB文件，fork子进程去生成新的RDB文件，主进程不阻塞bgsave 手动重写AOF文件 1bgrewriteaof 停止redis服务 1234# 安全停止redis服务，在停止之前会生成一份新的RDB文件redis-cli SHUTDOWN# 不安全，会造成数据丢失kill -9 redis_pid 检查持久化文件 1234# 检查AOF文件redis-check-aof /your/path/appendonly.aof# 检查RDB文件redis-check-rdb /your/path/dump.rdb 修复AOF文件 12# 如果redis在append数据到AOF文件时，机器宕机了，可能会导致AOF文件破损，使用以下命令修复AOF文件$REDIS_HOME/bin/redis-check-aof --fix 查看持久化信息 1234# 查看持久化信息info Persistence# 查看状态信息info stats","categories":[{"name":"Java","slug":"Java","permalink":"https://zsc-cloud.github.io/categories/Java/"},{"name":"Redis","slug":"Java/Redis","permalink":"https://zsc-cloud.github.io/categories/Java/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://zsc-cloud.github.io/tags/Redis/"}]},{"title":"MySQL中的索引","slug":"MySQL中的索引","date":"2021-05-13T05:47:39.000Z","updated":"2022-03-26T03:42:17.410Z","comments":true,"path":"2021/05/12/MySQL中的索引/","link":"","permalink":"https://zsc-cloud.github.io/2021/05/12/MySQL%E4%B8%AD%E7%9A%84%E7%B4%A2%E5%BC%95/","excerpt":"","text":"什么是索引 帮助MySQL高效获取数据的数据结构。更通俗的说，数据库索引好比是一本书前面的目录，能加快数据库的查询速度。 一般来说索引本身也很大，不可能全部存储在内存中，因此索引往往是存储在磁盘上的文件中的（可能存储在单独的索引文件中，也可能和数据一起存储在数据文件中） 索引的优势和劣势优势 可以 提高数据检索的效率，降低数据库的IO成本，类似于书的目录。 通过索引列对数据进行排序，降低数据排序的成本，降低了CPU的消耗。 被索引的列会自动进行排序，包括【单列索引】和【组合索引】，只是组合索引的排序要复杂一些。 如果按照索引列的顺序进行排序，对应order by语句来说，效率就会提高很多。 劣势 索引会占据磁盘空间 索引虽然会提高查询效率，但是会降低更新表的效率。比如每次对表进行增删改操作，MySQL不仅要保存数据，还有保存或者更新对应的索引文件。 索引类型主键索引索引列中的值必须是唯一的，不允许有空值。 普通索引（NORMAL）MySQL中基本索引类型，没有什么限制，允许在定义索引的列中插入重复值和空值。 唯一索引（UNIQUE）索引列中的值必须是唯一的，但是允许为空值。 全文索引（FULLTEXT）只能在文本类型CHAR,VARCHAR,TEXT类型字段上创建全文索引。字段长度比较大时，如果创建普通索引，在进行like模糊查询时效率比较低，这时可以创建全文索引。 MyISAM和InnoDB中都可以使用全文索引。 空间索引（SPATIAL）MySQL在5.7之后的版本支持了空间索引，而且支持OpenGIS几何数据模型。MySQL在空间索引这方面遵循OpenGIS几何数据模型规则。 了解即可 前缀索引在文本类型如CHAR,VARCHAR,TEXT类列上创建索引时，可以指定索引列的长度，但是数值类型不能指定。 12alter table user add index index1(email) //普通索引alter table user add index index2(email(6)) //前缀索引 其他（按照索引列数量分类）单列索引组合索引组合索引的使用，需要遵循最左匹配原则。一般情况下在条件允许的情况下使用组合索引替代多个单列索引使用。 索引的数据结构 Innnodb中支持的只有Hash结构和B+结构，如果没有特别说明的话，一般是使用B+结构的 下面的分析依次是Hash –&gt; 普通二叉树 –&gt; 平衡二叉树 –&gt; B树 –&gt; B+树 HashHash表，在Java中的HashMap，TreeMap就是Hash表结构，以键值对的方式存储数据。我们使用Hash表存储表数据Key可以存储索引列，Value可以存储行记录或者行磁盘地址。Hash表在等值查询时效率很高，时间复杂度为O(1)；但是不支持范围快速查找，范围查找时还是只能通过扫描全表方式。 字段值所对应的数组下标是哈希算法随机算出来的，所以可能出现哈希冲突。 hash索引检索一次到位，而不需要想B+树那样从根节点访问到叶子节点。不过在有大量重复值得情况下，hash索引的效率极低，因为要频发地处理Hash冲突。 那Hash表在哪些场景比较适合 : 等值查询的场景，就只有KV（Key，Value）的情况，例如Redis、Memcached等这些NoSQL的中间件。 二叉树 二叉树特点： 每个节点最多有2个分叉，左子树和右子树数据顺序左小右大。 缺陷 这个特点就是为了保证每次查找都可以这折半而减少IO次数，但是二叉树就很考验第一个根节点的取值，因为很容易在这个特点下出现我们并发想发生的情况“树不分叉了”，这就很难受很不稳定。 显然这种情况不稳定的我们再选择设计上必然会避免这种情况的 平衡二叉树平衡二叉树是采用二分法思维，平衡二叉查找树除了具备二叉树的特点，最主要的特征是树的左右两个子树的层级最多相差1。在插入删除数据时通过左旋/右旋操作保持二叉树的平衡，不会出现左子树很高、右子树很矮的情况。 使用平衡二叉查找树查询的性能接近于二分查找法，时间复杂度是 O(log2n)。查询id=6，只需要两次IO。 平衡二叉树存在的问题 时间复杂度和树高相关。树有多高就需要检索多少次，每个节点的读取，都对应一次磁盘 IO 操作。树的高度就等于每次查询数据时磁盘 IO 操作的次数。 平衡二叉树不支持范围查询快速查找，范围查询时需要从根节点多次遍历，查询效率不高。 B树：改造二叉树MySQL的数据是存储在磁盘文件中的，查询处理数据时，需要先把磁盘中的数据加载到内存中，磁盘IO 操作非常耗时，所以我们优化的重点就是尽量减少磁盘 IO 操作。访问二叉树的每个节点就会发生一次IO，如果想要减少磁盘IO操作，就需要尽量降低树的高度。那如何降低树的高度呢？ 假如key为bigint=8字节，每个节点有两个指针，每个指针为4个字节，一个节点占用的空间16个字节（8+4*2=16）。 因为在MySQL的InnoDB存储引擎一次IO会读取的一页（默认一页16K）的数据量，而二叉树一次IO有效数据量只有16字节，空间利用率极低。为了最大化利用一次IO空间，一个简单的想法是在每个节点存储多个元素，在每个节点尽可能多的存储数据。每个节点可以存储1000个索引（16k/16=1000），这样就将二叉树改造成了多叉树，通过增加树的叉树，将树从高瘦变为矮胖。构建1百万条数据，树的高度只需要2层就可以（1000*1000=1百万），也就是说只需要2次磁盘IO就可以查询到数据。磁盘IO次数变少了，查询数据的效率也就提高了 这种数据结构我们称为B树，B树是一种多叉平衡查找树，如下图主要特点： B树的节点中存储着多个元素，每个内节点有多个分叉。 节点中的元素包含键值和数据，节点中的键值从大到小排列。也就是说，在所有的节点都储存数据。 父节点当中的元素不会出现在子节点中。 所有的叶子结点都位于同一层，叶节点具有相同的深度，叶节点之间没有指针连接。 举个例子，在b树中查询数据的情况： 假如我们查询值等于10的数据。查询路径磁盘块1-&gt;磁盘块2-&gt;磁盘块5。 第一次磁盘IO：将磁盘块1加载到内存中，在内存中从头遍历比较，10&lt;15，走左路，到磁盘寻址磁盘块2。 第二次磁盘IO：将磁盘块2加载到内存中，在内存中从头遍历比较，7&lt;10，到磁盘中寻址定位到磁盘块5。 第三次磁盘IO：将磁盘块5加载到内存中，在内存中从头遍历比较，10=10，找到10，取出data，如果data存储的行记录，取出data，查询结束。如果存储的是磁盘地址，还需要根据磁盘地址到磁盘中取出数据，查询终止。 相比二叉平衡查找树，在整个查找过程中，虽然数据的比较次数并没有明显减少，但是磁盘IO次数会大大减少。同时，由于我们的比较是在内存中进行的，比较的耗时可以忽略不计。B树的高度一般2至3层就能满足大部分的应用场景，所以使用B树构建索引可以很好的提升查询的效率。 缺点： B树不支持范围查询的快速查找，你想想这么一个情况如果我们想要查找10和35之间的数据，查找到15之后，需要回到根节点重新遍历查找，需要从根节点进行多次遍历，查询效率有待提高。 如果data存储的是行记录，行的大小随着列数的增多，所占空间会变大。这时，一个页中可存储的数据量就会变少，树相应就会变高，磁盘IO次数就会变大。 B+树：改造B树B+树，作为B树的升级版，在B树基础上，MySQL在B树的基础上继续改造，使用B+树构建索引。B+树和B树最主要的区别在于非叶子节点是否存储数据的问题 B树：非叶子节点和叶子节点都会存储数据。 B+树：只有叶子节点才会存储数据，非叶子节点至存储键值。叶子节点之间使用双向指针连接，最底层的叶子节点形成了一个双向有序链表。 B+树的最底层叶子节点包含了所有的索引项。从图上可以看到，B+树在查找数据的时候，由于数据都存放在最底层的叶子节点上，所以每次查找都需要检索到叶子节点才能查询到数据。所以在需要查询数据的情况下每次的磁盘的IO跟树高有直接的关系，但是从另一方面来说，由于数据都被放到了叶子节点，所以放索引的磁盘块锁存放的索引数量是会跟这增加的，所以相对于B树来说，B+树的树高理论上情况下是比B树要矮的。也存在索引覆盖查询的情况，在索引中数据满足了当前查询语句所需要的全部数据，此时只需要找到索引即可立刻返回，不需要检索到最底层的叶子节点。 等值查询：假如我们查询值等于9的数据。查询路径磁盘块1-&gt;磁盘块2-&gt;磁盘块6。 第一次磁盘IO：将磁盘块1加载到内存中，在内存中从头遍历比较，9&lt;15，走左路，到磁盘寻址磁盘块2。 第二次磁盘IO：将磁盘块2加载到内存中，在内存中从头遍历比较，7&lt;9&lt;12，到磁盘中寻址定位到磁盘块6。 第三次磁盘IO：将磁盘块6加载到内存中，在内存中从头遍历比较，在第三个索引中找到9，取出data，如果data存储的行记录，取出data，查询结束。如果存储的是磁盘地址，还需要根据磁盘地址到磁盘中取出数据，查询终止。（这里需要区分的是在InnoDB中Data存储的为行数据，而MyIsam中存储的是磁盘地址。） 过程如图： 范围查询：假如我们想要查找9和26之间的数据。查找路径是磁盘块1-&gt;磁盘块2-&gt;磁盘块6-&gt;磁盘块7。 首先查找值等于9的数据，将值等于9的数据缓存到结果集。这一步和前面等值查询流程一样，发生了三次磁盘IO。 查找到15之后，底层的叶子节点是一个有序列表，我们从磁盘块6，键值9开始向后遍历筛选所有符合筛选条件的数据。 第四次磁盘IO：根据磁盘6后继指针到磁盘中寻址定位到磁盘块7，将磁盘7加载到内存中，在内存中从头遍历比较，9&lt;25&lt;26，9&lt;26&lt;=26，将data缓存到结果集。 主键具备唯一性（后面不会有&lt;=26的数据），不需再向后查找，查询终止。将结果集返回给用户。 可以看到B+树可以保证等值和范围查询的快速查找，MySQL的索引就采用了B+树的数据结构。 B+ 树简介一个很好的博客：https://blog.csdn.net/qq_26222859/article/details/80631121 总结： Hash不支持范围查询，二叉树树高很高，只有B树跟B+有的一比。 B树一个节点可以存储多个元素，相对于完全平衡二叉树整体的树高降低了，磁盘IO效率提高了。 而B+树是B树的升级版，只是把非叶子节点冗余一下，这么做的好处是为了提高范围查找的效率。提高了的原因也无非是会有指针指向下一个节点的叶子节点。 Mysql选用B+树这种数据结构作为索引，可以提高查询索引时的磁盘IO效率，并且可以提高范围查询的效率，并且B+树里的元素也是有序的。 InnoDB索引的实现主键索引（聚簇索引）每个InnoDB表都有一个聚簇索引 ，聚簇索引使用B+树构建，叶子节点存储的数据是整行记录。一般情况下，聚簇索引等同于主键索引，当一个表没有创建主键索引时，InnoDB会自动创建一个ROWID字段来构建聚簇索引。InnoDB创建索引的具体规则如下： 在表上定义主键PRIMARY KEY，InnoDB将主键索引用作聚簇索引。 如果表没有定义主键，InnoDB会选择第一个不为NULL的唯一索引列用作聚簇索引。 如果以上两个都没有，InnoDB 会使用一个6 字节长整型的隐式字段 ROWID字段构建聚簇索引。该ROWID字段会在插入新行时自动递增。 除聚簇索引之外的所有索引都称为辅助索引。在中InnoDB，辅助索引中的叶子节点存储的数据是该行的主键值都。 在检索时，InnoDB使用此主键值在聚簇索引中搜索行记录。 这里以user_innodb为例，user_innodb的id列为主键，age列为普通索引。 InnoDB的数据和索引存储在一个文件t_user_innodb.ibd中。InnoDB的数据组织方式，是聚簇索引。 主键索引的叶子节点会存储数据行，辅助索引只会存储主键值。 等值查询数据： select * from user_innodb where id = 28; 先在主键树中从根节点开始检索，将根节点加载到内存，比较28&lt;75，走左路。（1次磁盘IO） 将左子树节点加载到内存中，比较16&lt;28&lt;47，向下检索。（1次磁盘IO） 检索到叶节点，将节点加载到内存中遍历，比较16&lt;28，18&lt;28，28=28。查找到值等于28的索引项，直接可以获取整行数据。将改记录返回给客户端。（1次磁盘IO） 磁盘IO数量：3次。 辅助索引除聚簇索引之外的所有索引都称为辅助索引，InnoDB的辅助索引只会存储主键值而非磁盘地址。 MyIsam是存储磁盘地址 以表user_innodb的age列为例，age索引的索引结果如下图。 底层叶子节点的按照（age，id）的顺序排序，先按照age列从小到大排序，age列相同时按照id列从小到大排序。 使用辅助索引需要检索两遍索引：首先检索辅助索引获得主键，然后使用主键到主索引中检索获得记录。 画图分析等值查询的情况： select * from t_user_innodb where age=19; 根据在辅助索引树中获取的主键id，到主键索引树检索数据的过程称为回表查询。 磁盘IO数：辅助索引3次+获取记录回表3次 组合索引还是以自己创建的一个表为例：表 abc_innodb，id为主键索引，创建了一个联合索引idx_abc(a,b,c)。 select * from abc_innodb order by a, b, c, id; 组合索引的数据结构： 组合索引的查询过程： select * from abc_innodb where a = 13 and b = 16 and c = 4; 最左匹配原则：最左前缀匹配原则和联合索引的索引存储结构和检索方式是有关系的。 在组合索引树中，最底层的叶子节点按照第一列a列从左到右递增排列，但是b列和c列是无序的，b列只有在a列值相等的情况下小范围内递增有序，而c列只能在a，b两列相等的情况下小范围内递增有序。 就像上面的查询，B+树会先比较a列来确定下一步应该搜索的方向，往左还是往右。如果a列相同再比较b列。但是如果查询条件没有a列，B+树就不知道第一步应该从哪个节点查起。 可以说创建的idx_abc(a,b,c)索引，相当于创建了(a)、（a,b）（a,b,c）三个索引。、 组合索引的最左前缀匹配原则：使用组合索引查询时，mysql会一直向右匹配直至遇到范围查询(&gt;、&lt;、between、like)就停止匹配。**如果查询条件是b a c 顺序的话也可以命中索引，因为优化器会自动调整a，b，c的顺序 ** 覆盖索引覆盖索引并不是说是索引结构，覆盖索引是一种很常用的优化手段。因为在使用辅助索引的时候，我们只可以拿到主键值，相当于获取数据还需要再根据主键查询主键索引再获取到数据。但是试想下这么一种情况，在上面abc_innodb表中的组合索引查询时，如果我只需要abc字段的，那是不是意味着我们查询到组合索引的叶子节点就可以直接返回了，而不需要回表。这种情况就是覆盖索引。 可以看一下执行计划： 未使用到覆盖索引： 避免回表在InnoDB的存储引擎中，使用辅助索引查询的时候，因为辅助索引叶子节点保存的数据不是当前记录的数据而是当前记录的主键索引，索引如果需要获取当前记录完整数据就必然需要根据主键值从主键索引继续查询。这个过程我们成位回表。想想回表必然是会消耗性能影响性能。那如何避免呢？ 使用索引覆盖，举个例子：现有User表（id(PK),name(key),sex,address,hobby…） 如果在一个场景下，select id,name,sex from user where name =’zhangsan’;这个语句在业务上频繁使用到，而user表的其他字段使用频率远低于它，在这种情况下，如果我们在建立 name 字段的索引的时候，不是使用单一索引，而是使用联合索引（name，sex）这样的话再执行这个查询语句是不是根据辅助索引查询到的结果就可以获取当前语句的完整数据。这样就可以有效地避免了回表再获取sex的数据。 回表大概就是我们有个主键为ID的索引，和一个普通name字段的索引，我们在普通字段上搜索： select * from tableName where name = &#39;tom&#39; 执行的流程是先查询到name索引上的“tom”，然后找到他的id是2，最后去主键索引，找到id为2对应的值。 回到主键索引树搜索的过程，就是回表。不过也有方法避免回表，那就是覆盖索引。 联合索引的使用联合索引，在建立索引的时候，尽量在多个单列索引上判断下是否可以使用联合索引。联合索引的使用不仅可以节省空间，还可以更容易的使用到索引覆盖。试想一下，索引的字段越多，是不是更容易满足查询需要返回的数据呢。比如联合索引（a_b_c），是不是等于有了索引：a，a_b，a_b_c三个索引，这样是不是节省了空间，当然节省的空间并不是三倍于（a，a_b，a_b_c）三个索引，因为索引树的数据没变，但是索引data字段的数据确实真实的节省了。 联合索引的创建原则，在创建联合索引的时候因该把频繁使用的列、区分度高的列放在前面，频繁使用代表索引利用率高，区分度高代表筛选粒度大，这些都是在索引创建的需要考虑到的优化场景，也可以在常需要作为查询返回的字段上增加到联合索引中，如果在联合索引上增加一个字段而使用到了覆盖索引，那建议这种情况下使用联合索引。 总结： 考虑当前是否已经存在多个可以合并的单列索引，如果有，那么将当前多个单列索引创建为一个联合索引。 当前索引存在频繁使用作为返回字段的列，这个时候就可以考虑当前列是否可以加入到当前已经存在索引上，使其查询语句可以使用到覆盖索引。 B+树索引一个B+树的节点中到底存多少个元素最合适？B+树中一个节点为一页或页的倍数最为合适。 因为如果一个节点的大小小于1页，那么读取这个节点的时候其实也会读出1页，造成资源的浪费。 如果一个节点的大小大于1页，比如1.2页，那么读取这个节点的时候会读出2页，也会造成资源的浪费。 所以为了不造成浪费，所以最后把一个节点的大小控制在1页、2页、3页、4页等倍数页大小最为合适。 页的概念首先Mysql的基本存储结构是页(记录都存在页里边)： 一页16KB 各个数据页可以组成一个双向链表 而每个数据页中的记录又可以组成一个单向链表 每个数据页都会为存储在它里边儿的记录生成一个页目录，在通过主键查找某条记录的时候可以在页目录中使用二分法快速定位到对应的槽，然后再遍历该槽对应分组中的记录即可快速找到指定的记录 以其他列(非主键)作为搜索条件：只能从最小记录开始依次遍历单链表中的每条记录。 所以说，如果我们写 select * from user where username=’tom’这样没有进行任何优化的sql语句，默认会这样做： 需要遍历双向链表，找到所在的页，定位到记录所在的页 从所在的页内中查找相应的记录 由于不是根据主键查询，只能遍历所在页的单链表了 很明显，在数据量很大的情况下这样查找会很慢！看起来跟回表有点点像。 最左匹配原则： 索引可以简单如一个列 (a)，也可以复杂如多个列 (a,b,c,d)，即联合索引。 如果是联合索引，那么key也由多个列组成，同时，索引只能用于查找key是否存在（相等），遇到范围查询 (&gt;、&lt;、between、like左匹配)等就不能进一步匹配了，后续退化为线性查找。 因此，列的排列顺序决定了可命中索引的列数。 例子 如有索引 (a,b,c,d)，查询条件 a=1 and b=2 and c&gt;3 and d=4，索引会从左到右依次命中，直到碰到范围查询，即会在每个节点依次命中a、b、c，无法命中d。(c已经是范围查询了，d肯定是排不了序了) b = 2 如果建立(a,b)顺序的索引，是匹配不到(a,b)索引的；但是如果查询条件是a = 1 and b = 2或者a=1(又或者是b = 2 and b = 1)就可以，因为 聚簇索引和非聚簇索引聚簇索引 聚簇索引并不是一种单独的索引类型，而是一种数据存储方式。具体细节依赖于其实现方式。 简单来说就是跟数据行绑定的索引就叫聚簇索引，而其他跟绑定的数据为主键的为非聚簇索引 聚簇索引就是按照每张表的主键构造一颗B+树，同时叶子节点中存放的就是整张表的行记录数据，也将聚集索引的叶子节点称为数据页。这个特性决定了索引组织表中数据也是索引的一部分，每张表只能拥有一个聚簇索引。 Innodb通过默认主键聚集数据，如果没有定义主键，innodb会选择非空的唯一索引代替。如果没有这样的索引，innodb会隐式的定义一个主键来作为聚簇索引。 聚簇索引的优缺点 优点： 数据访问更快，因为聚簇索引将索引和数据保存在同一个B+树中，因此从聚簇索引中获取数据比非聚簇索引更快 聚簇索引对于主键的排序查找和范围查找速度非常快 缺点 插入速度严重依赖于插入顺序，按照主键的顺序插入是最快的方式，否则将会出现页分裂，严重影响性能。因此，对于InnoDB表，我们一般都会定义一个自增的ID列为主键 更新主键的代价很高，因为将会导致被更新的行移动。因此，对于InnoDB表，我们一般定义主键为不可更新 非聚簇索引也就是辅助索引 在聚簇索引之上创建的索引称之为辅助索引，辅助索引访问数据总是需要二次查找。辅助索引叶子节点存储的不再是行的物理位置，而是主键值。通过辅助索引首先找到的是主键值，再通过主键值找到数据行的数据页，再通过数据页中的Page Directory找到数据行。 Innodb辅助索引的叶子节点并不包含行记录的全部数据，叶子节点除了包含键值外，还包含了相应行数据的聚簇索引键。 辅助索引的存在不影响数据在聚簇索引中的组织，所以一张表可以有多个辅助索引。在innodb中有时也称辅助索引为二级索引。 非聚簇索引查询可以通过覆盖索引的方式提高查询速度，避免回表操作 总结同时要创建出好的索引要顾及到很多的方面： 最左前缀匹配原则。这是非常重要、非常重要、非常重要（重要的事情说三遍）的原则，MySQL会一直向右匹配直到遇到范围查询 （&gt;,&lt;,BETWEEN,LIKE）就停止匹配。 对字符串进行索引，应该定制一个前缀长度，可以节省大量的索引空间。 避免创建过多的索引，索引会额外占用磁盘空间，降低写操作效率。 尽量选择区分度高的列作为索引，区分度的公式是 COUNT(DISTINCT col)/COUNT(*)。表示字段不重复的比率，比率越大我们扫描的记录数就越少。 索引列不能参与计算，尽量保持列“干净”。比如， FROM_UNIXTIME(create_time)=’2016-06-06’ 就不能使用索引，原因很简单，B+树中存储的都是数据表中的字段值，但是进行检索时，需要把所有元素都应用函数才能比较，显然这样的代价太大。所以语句要写成 ： create_time=UNIX_TIMESTAMP(‘2016-06-06’)。 尽可能的扩展索引，不要新建立索引。比如表中已经有了a的索引，现在要加（a,b）的索引，那么只需要修改原来的索引即可。 单个多列组合索引和多个单列索引的检索查询效果不同，因为在执行SQL时，MySQL只能使用一个索引，会从多个单列索引中选择一个限制最为严格的索引(经指正，在MySQL5.0以后的版本中，有“合并索引”的策略，翻看了《高性能MySQL 第三版》，书作者认为：还是应该建立起比较好的索引，而不应该依赖于“合并索引”这么一个策略)。 “合并索引”策略简单来讲，就是使用多个单列索引，然后将这些结果用“union或者and”来合并起来 ​","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://zsc-cloud.github.io/categories/MySQL/"},{"name":"索引","slug":"MySQL/索引","permalink":"https://zsc-cloud.github.io/categories/MySQL/%E7%B4%A2%E5%BC%95/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://zsc-cloud.github.io/tags/MySQL/"},{"name":"索引","slug":"索引","permalink":"https://zsc-cloud.github.io/tags/%E7%B4%A2%E5%BC%95/"}]},{"title":"MySQL中的事务","slug":"MySQL中的事务","date":"2021-05-13T05:47:39.000Z","updated":"2022-03-26T03:42:17.385Z","comments":true,"path":"2021/05/12/MySQL中的事务/","link":"","permalink":"https://zsc-cloud.github.io/2021/05/12/MySQL%E4%B8%AD%E7%9A%84%E4%BA%8B%E5%8A%A1/","excerpt":"","text":"什么是事务事务是由一条或者多条DML语句组成逻辑执行单元，这系列操作要么全部执行成功，要么全部执行失败。通常一个事务对应一个完整的业务(例如银行账户转账业务，该业务就是一个最小的工作单元) 事务的特性（ACID）原子性(atomicity)： 事务的最小工作单元，要么全成功，要么全失败。 一致性(consistency)： 事务开始和结束后，数据库的完整性不会被破坏。（最重要） 隔离性(isolation)： 不同事务之间互不影响，四种隔离级别为RU（读未提交）、RC（读已提交）、RR（可重复读）、SERIALIZABLE （串行化）。隔离级别由低到高，性能由高到低。隔离级别总是和性能相违背。 持久性(durability)： 事务提交后，对数据的修改是永久性的，即使系统故障也不会丢失。 ACID之间的关系： 只有满足一致性，事务的结果才是正确的。 在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要能满足原子性，就一定能满足一致性。在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还需要满足隔离性，才能满足一致性。 事务满足持久化是为了能应对数据库崩溃的情况。 Innodb的隔离性有哪些 未提交读（READ UNCOMMITTED） 事务中的修改，即使没有提交，对其他事务也是可见的。 提交读（READ COMMITTED） 一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其他事务是不可见的。 又称为不可重复读，一个事务因为读取到另一个事务已提交的修改数据，导致在当前事务的不同时间读取同一条数据获取的结果不一致。 可重复读（REPEATABLE READ） 保证在同一个事务中多次读取同样数据的结果是一样的。 在当前事务中，不论读取多少次，数据任然是第一次读取的值，不会因为在第一次读取之后，其他事务再修改提交此数据而产生改变。 串行化（SERIALIZABLE） 强制事务串行执行。 所有的数据库的读或者写操作都为串行执行，读加读锁，写加写锁。当前隔离级别下只支持单个请求同时执行，所有的操作都需要队列执行。所以种隔离级别下所有的数据是最稳定的，但是性能也是最差的。 每个隔离性会造成什么问题 脏读： （针对未提交数据）如果一个事务中对数据进行了更新，但事务还没有提交，另一个事务可以“看到”该事务没有提交的更新结果，这样造成的问题就是，如果第一个事务回滚，那么，第二个事务在此之前所“看到”的数据就是一笔脏数据。 不可重复读 （针对其他提交前后，读取数据本身的对比）不可重复读取是指同一个事务在整个事务过程中对同一笔数据进行读取，每次读取结果都不同。如果事务1在事务2的更新操作之前读取一次数据，在事务2的更新操作之后再读取同一笔数据一次，两次结果是不同的，所以，Read Uncommitted也无法避免不可重复读取的问题。 幻读 （针对其他提交前后，读取数据条数的对比） 幻读是指同样一笔查询在整个事务过程中多次执行后，查询所得的结果集是不一样的。幻读针对的是多笔记录。在Read Uncommitted隔离级别下， 不管事务2的插入操作是否提交，事务1在插入操作之前和之后执行相同的查询，取得的结果集是不同的，所以，Read Uncommitted同样无法避免幻读的问题。 不可重复读的重点是修改:同样的条件, 你读取过的数据, 再次读取出来发现值不一样了 幻读的重点在于新增或者删除 (数据条数变化) 比如： select * from tableName where id = 1 ； 前后前次读取该id=1的数据字段值值不一致，不可重复读； select * from tableName where id &gt; 3 ; 前后两次读取数据条数不一致，幻读； 隔离级别 脏读 不可重复读 幻读 未提交读 √ √ √ 提交读 × √ √ 可重复读 × × √（在MySQL中，加入临键锁可以防止） 可串行化 × × × 事务怎么保证ACID事务怎么保证一致性这个问题分为两个层面来说。 从数据库层面，数据库通过原子性、隔离性、持久性来保证一致性。也就是说ACID四大特性之中，C(一致性)是目的，A(原子性)、I(隔离性)、D(持久性)是手段，是为了保证一致性，数据库提供的手段。数据库必须要实现AID三大特性，才有可能实现一致性。例如，原子性无法保证，显然一致性也无法保证。 但是，如果你在事务里故意写出违反约束的代码，一致性还是无法保证的。例如，你在转账的例子中，你的代码里故意不给B账户加钱，那一致性还是无法保证。因此，还必须从应用层角度考虑。 从应用层面，通过代码判断数据库数据是否有效，然后决定回滚还是提交数据！ 事务怎么保证原子性是利用Innodb的undo log。 undo-log名为回滚日志，是实现原子性的关键，当事务回滚时能够撤销所有已经执行成功的SQL语句，他需要记录你要回滚的相应日志信息。实际上就是记录SQL操作的相反SQL操作，SQL为insert，undolog中记录一条delete。rollback操作实际就是执行undolog的SQL起到覆盖作用。 例如 (1)当你delete一条数据的时候，就需要记录这条数据的信息，回滚的时候，insert这条旧数据 (2)当你update一条数据的时候，就需要记录之前的旧值，回滚的时候，根据旧值执行update操作 (3)当年insert一条数据的时候，就需要这条记录的主键，回滚的时候，根据主键执行delete操作 undo log记录了这些回滚需要的信息，当事务执行失败或调用了rollback，导致事务需要回滚，便可以利用undo log中的信息将数据回滚到修改之前的样子。 事务怎么保证持久性 在Mysql中，为了解决CPU和磁盘速度不一致问题，Mysql是将磁盘上的数据加载到内存，对内存进行操作，然后再回写磁盘。好，假设此时宕机了，在内存中修改的数据全部丢失了，持久性就无法保证。 是利用Innodb中的redolog。 正如上面所说，MySQL是先把磁盘上的数据加载到内存当中。当做数据修改的时候，不仅在内存中操作，还会在redolog中记录这次的操作。当事务提交的时候，会将redolog日志进行刷盘（redolog一部分在内存中（redolog buffer ），一部分在磁盘中）。当数据库宕机重启的时候，会将redolog中的内容回复到数据库中。在根据binlog和undolog内容决定回滚数据还是提交事务。 为什么要采用redolog刷盘，而不是每次提交事务进行数据刷盘？ MySQL加载的内存中Buffer pool 的数据最小单位是页。一页有16K大小。只修改一个页的几个字节，就要将整个页面刷入磁盘，太浪费性能和资源。而且一个事务中的SQL可能牵涉到多个数据页的修改，而这次数据页可能也不是相邻的。也就是刷盘的时候要进行随机IO，速度会比较慢。 而redo log 体积小，毕竟只记录了哪一页修改了啥，因此体积小，刷盘快。redo log是一直向末尾进行追加，输入顺序IO，效率快（这个刷盘指的是redo log内存中的数据刷盘到磁盘中的redolog。若MySQL服务器正常，则redolog不会对数据库进行操作，只有当mysql出现宕机重启，才会触发redolog写入数据库中。） MySQL会预读数据，能把一些“可能要访问”的页提前加入缓冲池buffer poll，避免未来的磁盘IO操作；管理算法是LRU 具体详解：https://blog.csdn.net/suo082407128/article/details/102580630 Redo log刷盘机制 redo log日志在磁盘的大小是固定的，即记录满了以后就从头循环写。 参数：innodb_flush_log_at_trx_commit innodb事物提交的重要参数，取值只有0、1、2，默认为1，动态参数。 该参数是用来控制提交操作和高性能的，如果需要更高的性能，在crash时可能存在数据丢失风险，也就是不具备ACID的持久性。 0：log每秒写入磁盘。crash时可能会丢失数据（因为那些已提交完成的事物还没有落盘） 1：默认值是1，在事务提交时刷脏数据到盘 2：log每秒写入磁盘，且在每次提交时写入磁盘。此状态时也不会丢失数据。 Buffer Pool的刷盘机制 1、当innodb中的脏页比例超过innodb_max_dirty_pages_pct_lwm的值时（默认值为75），这个时候就会开始刷新脏页到磁盘。 2、当innodb中的脏页比例超过innodb_max_dirty_pages_pct_lwm的值，而且还超过innodb_max_dirty_pages_pct时 innodb就会进入勤快刷新模式(agressively flush）这个模式下innodb会把脏页更快的刷新到磁盘。 3、还有一种情况叫做sharp checkpoint ,当innodb要重用它之前的redo文件时，就会把innodb_buffer_pool中所有与这 个文件有关的页面都要刷新到磁盘；这样做就有可能引起磁盘的IO风暴了，轻者影响性能，重者影响可用性。 可以简单的理解为：每秒都会进行一次刷盘（checkpoint：定期将db buffer的内容刷盘）。当脏页数据太快的时候，会触发innodb的勤快刷新模式。 参考文章： https://blog.csdn.net/molaifeng/article/details/113820047 https://www.cnblogs.com/JiangLe/p/7419835.html?utm_source=itdadao&amp;utm_medium=referral https://www.jianshu.com/p/06d09aa71a15 事务怎么保证隔离性RC,RR–MVCC 因为READ UNCOMMITIED总是读取最新的数据行，而不是符合当前事务版本的数据行。 而SERIALIZABLE则会对所有读取的行都加锁。 MVCC是什么MVCC的概念多版本并发控制（Multi-Version Concurrency Control, MVCC）是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。 而未提交读隔离级别总是读取最新的数据行，无需使用 MVCC。 可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。 MVCC是一种用来解决读-写冲突的无锁并发控制，其基本思想是为每次事务生成一个新版本的数据，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照。 这样在读操作不用阻塞写操作，写操作不用阻塞读操作的同时，避免了脏读和不可重复读。 MVCC 在mysql 中的实现依赖的是 undo log 与 read view 。 名词解释： 版本号 系统版本号：是一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。 事务版本号：事务开始时的系统版本号。 隐藏的列 MVCC 在每行记录后面都保存着两个隐藏的列，用来存储两个版本号： trx_id：每次一个事务对某条记录进行修改时，都会把该事务的事务id赋值给trx_id隐藏列； roll_pointer：每次对一个记录进行修改时，都会把旧版本写入undo日志中，然后把这个隐藏列就相当于一个指针，可以通过它来找到该记录修改前的信息； 创建版本号：指示创建一个数据行的快照时的系统版本号； 删除版本号：如果该快照的删除版本号大于当前事务版本号表示该快照有效，否则表示该快照已经被删除了。 MVCC是怎么保证隔离级别的以下实现过程针对可重复读隔离级别： SELECT InnoDB 会根据以下两个条件检查每行记录： InnoDB只查找版本早于当前事务版本的数据行（也就是，行的事务编号小于或等于当前事务的事务编号），这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的。 删除的行要事务ID判断，读取到事务开始之前状态的版本，只有符合上述两个条件的记录，才能返回作为查询结果。 INSERT InnoDB为新插入的每一行保存当前事务编号作为行版本号。 DELETE InnoDB为删除的每一行保存当前事务编号作为行删除标识。 UPDATE InnoDB为插入一行新记录，保存当前事务编号作为行版本号，同时保存当前事务编号到原来的行作为行删除标识。 保存这两个额外事务编号，使大多数读操作都可以不用加锁。这样设计使得读数据操作很简单，性能很好，并且也能保证只会读取到符合标准的行。不足之处是每行记录都需要额外的存储空间，需要做更多的行检查工作，以及一些额外的维护工作。 MVCC 在mysql 中的实现MVCC 在mysql 中的实现依赖的是 undo log 与 read view 。 undo log根据行为的不同，undo log分为两种： insert undo log 和 update undo log insert undo log insert 操作中产生的undo log，因为insert操作记录只对当前事务本身可见，对于其他事务此记录不可见，所以 insert undo log 可以在事务提交后直接删除而不需要进行purge操作。 purge的主要任务是将数据库中已经 mark del 的数据删除，另外也会批量回收undo pages 数据库 Insert时的数据初始状态：此时回滚指针是null; update undo log： update 或 delete 操作中产生的 undo log。 因为会对已经存在的记录产生影响，为了提供 MVCC机制，因此update undo log 不能在事务提交时就进行删除，而是将事务提交时放到入 history list 上，等待 purge 线程进行最后的删除操作。 数据第一次被修改时： 当另一个事务第二次修改当前数据： 为了保证事务并发操作时，在写各自的undo log时不产生冲突，InnoDB采用回滚段的方式来维护undo log的并发写入和持久化。回滚段实际上是一种 Undo 文件组织方式 ReadView对于 RU(READ UNCOMMITTED) 隔离级别下，所有事务直接读取数据库的最新值即可，和 SERIALIZABLE 隔离级别，所有请求都会加锁，同步执行。所以这对这两种情况下是不需要使用到 Read View 的版本控制。 对于 RC(READ COMMITTED) 和 RR(REPEATABLE READ) 隔离级别的实现就是通过上面的版本控制来完成。两种隔离界别下的核心处理逻辑就是判断所有版本中哪个版本是当前事务可见的处理。针对这个问题InnoDB在设计上增加了ReadView的设计，ReadView中主要包含当前系统中还有哪些活跃的读写事务，把它们的事务id放到一个列表中，我们把这个列表命名为为m_ids。 对于查询时的版本链数据是否看见的判断逻辑： 如果被访问版本的 trx_id 属性值小于 m_ids 列表中最小的事务id，表明生成该版本的事务在生成 ReadView 前已经提交，所以该版本可以被当前事务访问。 如果被访问版本的 trx_id 属性值大于 m_ids 列表中最大的事务id，表明生成该版本的事务在生成 ReadView 后才生成，所以该版本不可以被当前事务访问。 如果被访问版本的 trx_id 属性值在 m_ids 列表中最大的事务id和最小事务id之间，那就需要判断一下 trx_id 属性值是不是在 m_ids 列表中，如果在，说明创建 ReadView 时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建 ReadView 时生成该版本的事务已经被提交，该版本可以被访问。 这个ReadView可以理解为一个读视图。 当隔离级别为RR时：只会在第一次快照读的时候生成ReadView,之后执行的快照读都是用第一次生成的readView，在该级别的事务中，两次相同的select查询返回的结果是相同的，无关其他事务已经提交的修改结果。（保证可重复读）。当时进行update，insert，delete，以及select…for update 操作时，更新一次readView视图。（保证其他事务修改记录不会丢失） 当隔离级别为RC是：每次进行快照读的时候都会生成一个ReadView，所以其他事务已经提交的数据能够看到。这时执行相同的select语句返回的结果可能不是相同的，因为两次执行之间可能存在别的事务提交了当前查询列的修改，第二次select时刷新到最新的一个ReadView。（造成不可重复读） MVCC总结：所谓的MVCC（Multi-Version Concurrency Control ，多版本并发控制）指的就是在使用 READ COMMITTD 、REPEATABLE READ 这两种隔离级别的事务在执行普通的 SEELCT 操作时访问记录的版本链的过程，这样子可以使不同事务的 读-写 、 写-读 操作并发执行，从而提升系统性能。 在 MySQL 中， READ COMMITTED 和 REPEATABLE READ 隔离级别的的一个非常大的区别就是它们生成 ReadView 的时机不同。在 READ COMMITTED 中每次快照读都会生成一个实时的 ReadView，做到保证每次提交后的数据是处于当前的可见状态。而 REPEATABLE READ 中，在当前事务第一次查询时生成当前的 ReadView，并且当前的 ReadView 会一直沿用到当前事务提交，以此来保证可重复读（REPEATABLE READ）。 快照读和当前读在可重复读级别中，通过MVCC机制，虽然让数据变得可重复读，但我们读到的数据可能是历史数据，是不及时的数据，不是数据库当前的数据！这在一些对于数据的时效特别敏感的业务中，就很可能出问题。 对于这种读取历史数据的方式，我们叫它快照读 (snapshot read)，而读取数据库当前版本数据的方式，叫当前读 (current read)。很显然，在MVCC中： 快照读 MVCC 的 SELECT 操作是快照中的数据，不需要进行加锁操作。 1select * from table ….; 当前读 MVCC 其它会对数据库进行修改的操作（INSERT、UPDATE、DELETE）需要进行加锁操作，从而读取最新的数据。可以看到 MVCC 并不是完全不用加锁，而只是避免了 SELECT 的加锁操作。 12345678INSERT;UPDATE;DELETE;在进行 SELECT 操作时，可以强制指定进行加锁操作。以下第一个语句需要加 S 锁，第二个需要加 X 锁。- select * from table where ? lock in share mode; 共享锁 允许多个线程读取数据，不允许修改数据（仅可读）- select * from table where ? for update; 排他锁 只允许一个线程读写。其他线程阻塞 S锁 和 X锁 都是悲观锁 事务的隔离级别实际上都是定义的当前读的级别，MySQL为了减少锁处理（包括等待其它锁）的时间，提升并发能力，引入了快照读的概念，使得select不用加锁。而update、insert这些“当前读”的隔离性，就需要通过加锁来实现了。 RR隔离级别下解决幻读–临键锁Record Lock 行锁单个行记录上的锁我们通常讲的行锁，它的实质是通过对索引的加锁实现；只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁。在事务隔离级别为读已提交下，仅采用Record Lock。 如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks 依然可以使用。 Gap Lock 间隙锁锁定索引之间的间隙，但是不包含索引本身。例如当一个事务执行以下语句，其它事务就不能在 t.c 中插入 15。 1SELECT c FROM t WHERE c BETWEEN 10 and 20 FOR UPDATE; Next-Key Lock 临键锁它是 Record Locks 和 Gap Locks 的结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙。例如一个索引包含以下值：10, 11, 13, and 20，那么就需要锁定以下区间： 12345(-∞, 10](10, 11](11, 13](13, 20](20, +∞) 在 InnoDB 存储引擎中，SELECT 操作的幻读问题通过 MVCC 的快照读得到了解决， 而 UPDATE、DELETE 的幻读问题通过 Record Lock 解决，INSERT 的不可重复读问题是通过 Next-Key Lock（Record Lock + Gap Lock）解决的。间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的。 我们总是牺牲性能来换取安全稳定。 串行化是怎么加锁的串行化就相当于给操作的记录上一个共享锁（读写锁），即当读某条记录时就占用这条记录的读锁，此时其它事务一样可以申请到这条记录的读锁来读取，但是不能写（读锁被占的话，写锁就不能被占；读锁可以被多个事务同时占有） MySQL中锁MySQL锁概述相对其他数据库而言，MySQL的锁机制比较简单，其最 显著的特点是不同的存储引擎支持不同的锁机制。比如，MyISAM和MEMORY存储引擎采用的是表级锁（table-level locking）；BDB存储引擎采用的是页面锁（page-level locking），但也支持表级锁；InnoDB存储引擎既支持行级锁（row-level locking），也支持表级锁，但默认情况下是采用行级锁。表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般从上述特点可见，很难笼统地说哪种锁更好，只能就具体应用的特点来说哪种锁更合适！仅从锁的角度 来说：表级锁更适合于以查询为主，只有少量按索引条件更新数据的应用，如Web应用；而行级锁则更适合于有大量按索引条件并发更新少量不同数据，同时又有 并发查询的应用，如一些在线事务处理（OLTP）系统。 死锁和死锁检测在并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁 当出现死锁以后，有两种策略： 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数innodb_lock_wait_timeout来设置另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑 乐观锁和悲观锁乐观锁不是数据库自带的，需要我们自己去实现。乐观锁是指操作数据库时(更新操作)，想法很乐观，认为这次的操作不会导致冲突，在操作数据时，并不进行任何其他的特殊处理（也就是不加锁），而在进行更新后，再去判断是否有冲突了。通常实现是这样的：在表中的数据进行操作时(更新)，先给数据表加一个版本(version)字段，每操作一次，将那条记录的版本号加1。也就是先查询出那条记录，获取出version字段,如果要对那条记录进行操作(更新),则先判断此刻version的值是否与刚刚查询出来时的version的值相等，如果相等，则说明这段期间，没有其他程序对其进行操作，则可以执行更新，将version字段的值加1；如果更新时发现此刻的version值与刚刚获取出来的version的值不相等，则说明这段期间已经有其他程序对其进行操作了，则不进行更新操作。 与乐观锁相对应的就是悲观锁了。悲观锁就是在操作数据时，认为此操作会出现数据冲突，所以在进行每次操作时都要通过获取锁才能进行对相同数据的操作，这点跟java中的synchronized很相似，所以悲观锁需要耗费较多的时间。另外与乐观锁相对应的，悲观锁是由数据库自己实现了的，要用的时候，我们直接调用数据库的相关语句就可以了。 共享锁和排它锁共享锁(S锁)和排它锁（X锁）是悲观锁的不同的实现，它俩都属于悲观锁的范畴。 共享锁指的就是对于多个不同的事务，对同一个资源共享同一个锁。相当于对于同一把门，它拥有多个钥匙一样 如果事务T对数据A加上共享锁后，则其他事务只能对A再加共享锁，不能加排他锁。获准共享锁的事务只能读数据，不能修改数据。 对于悲观锁，一般数据库已经实现了，共享锁也属于悲观锁的一种，那么共享锁在mysql中是通过什么命令来调用呢。通过查询资料，了解到通过在执行语句后面加上 lock in share mode就代表对某些资源加上共享锁了。 排它锁与共享锁相对应，就是指对于多个不同的事务，对同一个资源只能有一把锁。 如果事务T对数据A加上排他锁后，则其他事务不能再对A加任任何类型的封锁。获准排他锁的事务既能读数据，又能修改数据。 与共享锁类型，在需要执行的语句后面加上 for update就可以了 共享锁 允许多个线程读取数据，不允许修改数据,所有的线程都是仅可读 排他锁 只允许一个线程读写。其他线程阻塞 InnoDB默认采用行锁，在未使用索引字段查询时升级为表锁。MySQL这样设计并不是给你挖坑。它有自己的设计目的。即便你在条件中使用了索引字段，MySQL会根据自身的执行计划，考虑是否使用索引(所以explain命令中会有possible_key 和 key)。如果MySQL认为全表扫描效率更高，它就不会使用索引，这种情况下InnoDB将使用表锁，而不是行锁。因此，在分析锁冲突时，别忘了检查SQL的执行计划，以确认是否真正使用了索引。 第一种情况：全表更新。事务需要更新大部分或全部数据，且表又比较大。若使用行锁，会导致事务执行效率低，从而可能造成其他事务长时间锁等待和更多的锁冲突。 第二种情况：多表查询。事务涉及多个表，比较复杂的关联查询，很可能引起死锁，造成大量事务回滚。这种情况若能一次性锁定事务涉及的表，从而可以避免死锁、减少数据库因事务回滚带来的开销。 一致性锁定读和一致性非锁定读在默认配置下innodb的隔离级别是repeatable read，innodb的select操作使用的是一致性非锁定读 一致性的非锁定行读（consistent nonlocking read，简称CNR）是指InnoDB存储引擎通过行多版本控制（multi versioning）的方式来读取当前执行时间数据库中运行的数据。如果读取的行正在执行delete、update操作，这时读取操作不会因此而会等待行上锁的释放，相反，InnoDB存储引擎会去读取行的一个快照数据。 之所以称为非锁定度，是因为不需要等待访问数据行上的X锁的释放。快照数据是指该行之前版本的数据，通过undo段来实现（undo用来在事务中回滚数据）。 在Read Committed和Repeatable Read模式下，innodb存储引擎使用默认的一致性非锁定读。在Read Committed隔离级别下，对于快照数据，一致性非锁定读总是读取被锁定行的最新一份快照数据；而在Repeatable Read隔离级别下，对于快照数据，一致性非锁定读总是读取事务开始时的行数据版本。 一致性锁定读默认情况下，innodb存储引擎的select操作使用一致性非锁定读，但是在某些情况下，需要对读操作进行加锁以保证数据逻辑的一致性。Innodb存储引擎对select语句支持2种一致性锁定读(locking read)操作; SELECT … FOR UPDATE对于读取的行记录加一个X排它锁，其他事务不能对锁定的行加任何锁。 SELECT … LOCK IN SHARE MODE对于读取的行记录添加一个S共享锁。其它事务可以向被锁定的行加S锁，但是不允许添加X锁，否则会被阻塞。 简单理解就是一致性非锁定读就是快照读 : select….; 一致性锁定读就是当前读: select…for update; MySQL的三种日志重做日志（redo log）确保事务的持久性。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。 回滚日志（undo log）保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC） 在数据修改的时候，不仅记录了redo，还记录了相对应的undo，如果因为某些原因导致事务失败或回滚了，可以借助该undo进行回滚。 undo log和redo log记录物理日志不一样，它是逻辑日志。可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录。 二进制日志（binlog）用于复制，在主从复制中，从库利用主库上的binlog进行重播，实现主从同步。用于数据库的基于时间点的还原。 Mysql的日志系统主要有redo log（重做日志）和binlog （归档日志）。redo log是Innodb存储引擎层面的日志，binlog是MySQL Server层的记录日志。两者都是记录了某种操作的日志，自然会有写重复。 MySQL的逻辑架构图： redo log日志模块redo log是InnoDB存储引擎层的日志，又称重做日志文件，用于记录事务操作的变化，记录的是数据修改之后的值，不管事务是否提交都会记录下来。在实例和介质失败（media failure）时，redo log文件就能派上用场，如数据库掉电，InnoDB存储引擎会使用redo log恢复到掉电前的时刻，以此来保证数据的完整性。 在一条更新语句进行执行的时候，InnoDB引擎会把更新记录写到redo log日志中，然后更新内存，此时算是语句执行完了，然后在空闲的时候或者是按照设定的更新策略将redo log中的内容更新到磁盘中，这里涉及到WAL即Write Ahead logging技术，他的关键点是先写日志，再写磁盘。兵马未动，粮草先行 有了redo log日志，那么在数据库进行异常重启的时候，可以根据redo log日志进行恢复，也就达到了crash-safe。 redo log日志的大小是固定的，即记录满了以后就从头循环写。 binlog日志模块binlog是属于MySQL Server层面的，又称为归档日志，属于逻辑日志，是以二进制的形式记录的是这个语句的原始逻辑，依靠binlog是没有crash-safe能力的 binlog是记录所有数据库表结构变更（例如CREATE、ALTER TABLE…）以及表数据修改（INSERT、UPDATE、DELETE…）的二进制日志。，如果update操作没有造成数据变化，也是会记入binlog。 MySQL binlog的三种工作模式：ROW（行模式）, Statement（语句模式）, Mixed（混合模式） redo log和binlog区别 redo log是属于innoDB层面，binlog属于MySQL Server层面的，这样在数据库用别的存储引擎时可以达到一致性的要求。 redo log是物理日志，记录该数据页更新的内容；binlog是逻辑日志，记录的是这个更新语句的原始逻辑 redo log是循环写，日志空间大小固定；binlog是追加写，是指一份写到一定大小的时候会更换下一个文件，不会覆盖。 binlog可以作为恢复数据使用，主从复制搭建，redo log作为异常宕机或者介质故障后的数据恢复使用。 一条更新语句执行的顺序二阶段提交 update T set c=c+1 where ID=2; 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。 WAL WAL（Write-ahead logging，预写式日志）是数据库系统提供原子性和持久化的一系列技术。 在使用 WAL 的系统中，所有的修改在提交之前都要先写入 log 文件中。 MySQL的WAL（Write Ahead Log）在InnoDB中被称作redo log 「修改并不直接写入到数据库文件中，而是写入到另外一个称为 WAL 的文件中；如果事务失败，WAL 中的记录会被忽略，撤销修改；如果事务成功，它将在随后的某个时间被写回到数据库文件中，提交修改。」 WAL 的优点 读和写可以完全地并发执行，不会互相阻塞（但是写之间仍然不能并发）。 WAL 在大多数情况下，拥有更好的性能（因为无需每次写入时都要写两个文件）。 磁盘 I/O 行为更容易被预测。 使用更少的 fsync()操作，减少系统脆弱的问题。 二阶段提交（prepare ，commit） 两阶段提交原理描述:阶段1：InnoDB redo log 写盘，InnoDB 事务进入 prepare 状态 阶段2：如果前面prepare成功，binlog 写盘，那么再继续将事务日志持久化到binlog，如果持久化成功，那么InnoDB 事务 则进入 commit 状态(实际是在redo log里面写上一个commit记录) 备注: 每个事务binlog的末尾，会记录一个 XID event，标志着事务是否提交成功，也就是说，recovery 过程中，binlog 最后一个 XID event 之后的内容都应该被 purge。 最终:mysql在落盘日志的时候,先落盘binlog,再落盘redo. 组提交组提交概念：将多个刷盘操作合并成一个，最大化每次刷盘手里，提升性能，降低资源开销。 在没有开启binlog时：Redo log的刷盘操作将会是最终影响MySQL TPS的瓶颈所在。为了缓解这一问题，MySQL使用了组提交，将多个刷盘操作合并成一个，如果说10个事务依次排队刷盘的时间成本是10，那么将这10个事务一次性一起刷盘的时间成本则近似于1。 当开启binlog时：为了保证Redo log和binlog的数据一致性，MySQL使用了二阶段提交，由binlog作为事务的协调者。而 引入二阶段提交 使得binlog又成为了性能瓶颈，先前的Redo log 组提交 也成了摆设。为了再次缓解这一问题，MySQL增加了binlog的组提交，目的同样是将binlog的多个刷盘操作合并成一个，结合Redo log本身已经实现的 组提交，分为三个阶段(Flush 阶段、Sync 阶段、Commit 阶段)完成binlog 组提交，最大化每次刷盘的收益，弱化磁盘瓶颈，提高性能。 组提交参考文章：https://blog.csdn.net/n88Lpo/article/details/81187372","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://zsc-cloud.github.io/categories/MySQL/"},{"name":"事务","slug":"MySQL/事务","permalink":"https://zsc-cloud.github.io/categories/MySQL/%E4%BA%8B%E5%8A%A1/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://zsc-cloud.github.io/tags/MySQL/"},{"name":"数据库","slug":"数据库","permalink":"https://zsc-cloud.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"Java实现微信小程序获取unionID","slug":"Java实现微信小程序获取unionID","date":"2021-05-13T03:01:45.000Z","updated":"2021-06-06T03:19:39.532Z","comments":true,"path":"2021/05/12/Java实现微信小程序获取unionID/","link":"","permalink":"https://zsc-cloud.github.io/2021/05/12/Java%E5%AE%9E%E7%8E%B0%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E8%8E%B7%E5%8F%96unionID/","excerpt":"","text":"前言：微信开发平台为开发者提供openId用来区分用户的唯一性，但是openId只是在独立的应用内是唯一的，如果开发者拥有多个移动应用、网站应用、和公众帐号（包括小程序），可通过 UnionID 来区分用户的唯一性，因为只要是同一个微信开放平台帐号下所有应用，用户的 UnionID 是唯一的。换句话说，同一用户，对同一个微信开放平台下的不同应用，UnionID是相同的。微信官方文档：官方文档 获取UnionID的两种方式： 如果开发者帐号下存在同主体的公众号，并且该用户已经关注了该公众号。开发者可以直接通过 wx.login + code2Session 获取到该用户 UnionID 从加密数据中获取UnionID ps : 这里要注意的是微信开放平台如果没有绑定微信小程序，不可能获取到unionId，无论哪种方式 1. 已经关注公众号获取UnionID这种方式对于开发者来说是获取unionID最简单的方式，开发者可以直接通过 wx.login + code2Session 获取到该用户 UnionID。以下代码只针对于Java语言来演示 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package com.jinke.applets.common;import com.alibaba.fastjson.JSONObject;import com.jinke.utils.HttpUtil;import lombok.extern.slf4j.Slf4j;import java.util.HashMap;import java.util.Map;/** * @author zsc * @date 2020/7/17 */@Slf4jpublic class AppletsWeChatUtil &#123; // 登录凭证校验地址 public final static String GetPageAccessTokenUrl = &quot;https://api.weixin.qq.com/sns/jscode2session?appid=APPID&amp;secret=SECRET&amp;js_code=CODE&amp;grant_type=authorization_code&quot;; // 小程序的appId以及appSecret private static final String appId = &quot;xxxxxxxxxxxxx&quot;; private static final String appSecret = &quot;xxxxxxxxxxxxxxx&quot;; /** * 小程序授权获取openID和unionID * @param code 前端通过wx.login获取的wxCode * @return */ public static Map&lt;String, String&gt; oauth2GetUnion(String code) &#123; String requestUrl = GetPageAccessTokenUrl.replace(&quot;APPID&quot;, appId).replace(&quot;SECRET&quot;, appSecret).replace(&quot;CODE&quot;, code); Map&lt;String, String&gt; result = new HashMap&lt;&gt;(); try &#123; /** * HttpUtil工具类会在下方贴出，此处也可换成自己的写法，只要是get请求就可以 * 此处请求返回的json数据包为： * openid string 用户唯一标识 * session_key string 会话密钥 * unionid string 用户在开放平台的唯一标识符 * errcode number 错误码 * errmsg string 错误信息 */ String response = HttpUtil.get(requestUrl); JSONObject jsonResult = JSONObject.parseObject(response); String openid = String.valueOf(jsonResult.get(&quot;openid&quot;)); // 若用户没有改小程序同主体公众号，则此处unionID为空 String unionid = String.valueOf(jsonResult.get(&quot;unionid&quot;)); result.put(&quot;openid&quot;, openid); result.put(&quot;unionid&quot;,unionid); &#125; catch (Exception e) &#123; log.info(&quot;授权获取unionid出现异常&quot;); e.printStackTrace(); &#125; return result; &#125;&#125; 2. 解密数据获取UnionID此方式针对于没有主体公众号或者做不到让用户都关注公众号的情况下获取UnionID.大致流程如下 前端js调取公开接口wx.getUserInfo获取encryptedData和iv 根据code2Session获取session_key和openid，如果有unionid直接返回 根据session_key,encryptedData和iv进行AES解密 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package com.jinke.rusi.utils;import com.alibaba.fastjson.JSONObject;import com.jinke.utils.HttpUtil;import lombok.extern.slf4j.Slf4j;import java.util.HashMap;import java.util.Map;/** * @author zsc * @date 2020/7/17 */@Slf4jpublic class AppletsWeChatUtil &#123; // 登录凭证校验地址 public final static String GetPageAccessTokenUrl = &quot;https://api.weixin.qq.com/sns/jscode2session?appid=APPID&amp;secret=SECRET&amp;js_code=CODE&amp;grant_type=authorization_code&quot;; // 小程序的appId以及appSecret private static final String appId = &quot;xxxxxxxxxxxxx&quot;; private static final String appSecret = &quot;xxxxxxxxxxxxxxx&quot;; /** * 小程序授权 * @param code WxCode * @param encryptedData 加密数据 * @param iv 偏移量iv * @return */ public static Map&lt;String, String&gt; oauth2GetUnionId(String code,String encryptedData,String iv) &#123; String requestUrl = GetPageAccessTokenUrl.replace(&quot;APPID&quot;, appId).replace(&quot;SECRET&quot;, appSecret).replace(&quot;CODE&quot;, code); Map&lt;String, String&gt; result = new HashMap&lt;&gt;(); try &#123; String response = HttpUtil.get(requestUrl); JSONObject jsonObject = JSONObject.parseObject(response); String openid = String.valueOf(jsonObject.get(&quot;openid&quot;)); // 获取解密所需的session_key String session_key = String.valueOf(jsonObject.get(&quot;session_key&quot;)); // 通过AES解密encryptedData 获取union_id，工具类见下方 String encryptedResult = AESUtil.decrypt(encryptedData, session_key, iv, &quot;UTF-8&quot;); /** * 此处解密之后数据包格式为： * openid string 用户唯一标识 * nickName string 昵称 * gender string 性别 * city string 城市 * province string 省份 * country string 国家 * avatarUrl string 头像 * unionId string 用户在开放平台的唯一标识符 * watermark JSON 数据水印，包括appid，timestamp字段 为了校验数据的有效性 */ JSONObject parseObject = JSONObject.parseObject(encryptedResult); // ps:此处一定要注意解密的出来的字段名为驼峰命名的unionId,openId，并非直接授权的unionid String unionid = String.valueOf(parseObject.get(&quot;unionId&quot;)); result.put(&quot;openid&quot;, openid); result.put(&quot;unionid&quot;,unionid); &#125; catch (Exception e) &#123; log.info(&quot;授权获取unionid出现异常&quot;); e.printStackTrace(); &#125; return result; &#125;&#125; 工具类及依赖AESUtil: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778package com.jinke.rusi.utils;import net.sf.json.JSONObject;import org.apache.commons.codec.binary.Base64;import org.bouncycastle.jce.provider.BouncyCastleProvider;import javax.crypto.BadPaddingException;import javax.crypto.Cipher;import javax.crypto.IllegalBlockSizeException;import javax.crypto.NoSuchPaddingException;import javax.crypto.spec.IvParameterSpec;import javax.crypto.spec.SecretKeySpec;import java.io.UnsupportedEncodingException;import java.security.*;import java.security.spec.InvalidParameterSpecException;/** * @author zsc * @date 2020/07/17 * AES-128-CBC 加密方式 * AES-128-CBC可以自己定义“密钥”和“偏移量“。 * AES-128是jdk自动生成的“密钥”。 */public class AESUtil &#123; static &#123; Security.addProvider(new BouncyCastleProvider()); &#125; /** * AES解密 * @param data 密文，被加密的数据 * @param key 秘钥 * @param iv 偏移量 * @param encodingFormat 解密后的结果需要进行的编码 * @return * @throws Exception */ public static String decrypt(String data, String key, String iv, String encodingFormat) throws Exception &#123; //被加密的数据 byte[] dataByte = Base64.decodeBase64(data); //加密秘钥 byte[] keyByte = Base64.decodeBase64(key); //偏移量 byte[] ivByte = Base64.decodeBase64(iv); try &#123; Cipher cipher = Cipher.getInstance(&quot;AES/CBC/PKCS7Padding&quot;); SecretKeySpec spec = new SecretKeySpec(keyByte, &quot;AES&quot;); AlgorithmParameters parameters = AlgorithmParameters.getInstance(&quot;AES&quot;); parameters.init(new IvParameterSpec(ivByte)); cipher.init(Cipher.DECRYPT_MODE, spec, parameters);// 初始化 byte[] resultByte = cipher.doFinal(dataByte); if (null != resultByte &amp;&amp; resultByte.length &gt; 0) &#123; String result = new String(resultByte, encodingFormat); return result; &#125; return null; &#125; catch (NoSuchAlgorithmException e) &#123; e.printStackTrace(); &#125; catch (NoSuchPaddingException e) &#123; e.printStackTrace(); &#125; catch (InvalidParameterSpecException e) &#123; e.printStackTrace(); &#125; catch (InvalidKeyException e) &#123; e.printStackTrace(); &#125; catch (InvalidAlgorithmParameterException e) &#123; e.printStackTrace(); &#125; catch (IllegalBlockSizeException e) &#123; e.printStackTrace(); &#125; catch (BadPaddingException e) &#123; e.printStackTrace(); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; HttpUtil: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091package com.jinke.utils;import com.alibaba.fastjson.JSON;import org.apache.http.HttpEntity;import org.apache.http.StatusLine;import org.apache.http.client.methods.CloseableHttpResponse;import org.apache.http.client.methods.HttpGet;import org.apache.http.client.methods.HttpPost;import org.apache.http.client.methods.HttpRequestBase;import org.apache.http.entity.StringEntity;import org.apache.http.impl.client.CloseableHttpClient;import org.apache.http.message.BasicNameValuePair;import org.apache.http.util.EntityUtils;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.io.IOException;import java.io.UnsupportedEncodingException;import java.util.*;public class HttpUtil &#123; private static final Logger LOGGER = LoggerFactory.getLogger(HttpUtil.class); public static int DATA_JSON = 1; public static int DATA_FORM = 2; private static String JSON_CONTENT_TYPE = &quot;application/json&quot;; private static String CHARACTER = &quot;UTF-8&quot;; private static String CONTENT_TYPE_NAME = &quot;Content-Type&quot;; public static String get(String url) &#123; return send(new HttpGet(url)); &#125; public static String post(String url, Map&lt;String, Object&gt; param, Integer dataType) &#123; return post(url, param, dataType, null); &#125; public static String post(String url, Map&lt;String, Object&gt; param, Integer dataType, Map&lt;String, String&gt; headers) &#123; HttpPost post = new HttpPost(url); if (dataType == DATA_FORM) &#123; Iterator localIterator; Map.Entry&lt;String, String&gt; entries; if (headers != null) for (localIterator = headers.entrySet().iterator(); localIterator.hasNext(); ) &#123; entries = (Map.Entry) localIterator.next(); post.setHeader((String) entries.getKey(), (String) entries.getValue()); &#125; Object paramList = new ArrayList(); for (Map.Entry&lt;String, Object&gt; entry : param.entrySet()) &#123; ((List) paramList).add(new BasicNameValuePair((String) entry.getKey(), entry.getValue().toString())); &#125; try &#123; post.setEntity(new org.apache.http.client.entity.UrlEncodedFormEntity((List) paramList)); &#125; catch (UnsupportedEncodingException e) &#123; LOGGER.info(e.getMessage()); &#125; &#125; else if (dataType.intValue() == DATA_JSON) &#123; post.setHeader(CONTENT_TYPE_NAME, JSON_CONTENT_TYPE); post.setEntity(new StringEntity(JSON.toJSONString(param), CHARACTER)); &#125; return send(post); &#125; private static String send(HttpRequestBase request) &#123; CloseableHttpClient client = org.apache.http.impl.client.HttpClients.createDefault(); String result = null; try &#123; CloseableHttpResponse response = client.execute(request); HttpEntity entity = response.getEntity(); StatusLine status = response.getStatusLine(); if (status.getStatusCode() == 200) &#123; result = EntityUtils.toString(entity); EntityUtils.consume(entity); &#125; else &#123; result = String.valueOf(status); &#125; LOGGER.info(&quot;http response ------------&quot; + result); response.close(); &#125; catch (IOException e) &#123; LOGGER.info(e.getMessage()); &#125; return result; &#125;&#125; AES加密依赖的包123456789101112131415161718这里需要注意的是，AES解密的时候需要用到javax.crypto.*包的类，在jdk的 jce.jar中提供，是jdk自带的库。如果是MAVEN项目，则需要在pom.xml文件中配置指定编译路径jce.jar如果配置路径麻烦，可以选择去maven或者gradle自行下载。Maven依赖:&lt;!-- https://mvnrepository.com/artifact/org.bouncycastle/bcprov-jdk15on --&gt;&lt;dependency&gt; &lt;groupId&gt;org.bouncycastle&lt;/groupId&gt; &lt;artifactId&gt;bcprov-jdk15on&lt;/artifactId&gt; &lt;version&gt;1.50&lt;/version&gt;&lt;/dependency&gt;Gradle依赖：// https://mvnrepository.com/artifact/org.bouncycastle/bcprov-jdk15oncompile group: &#x27;org.bouncycastle&#x27;, name: &#x27;bcprov-jdk15on&#x27;, version: &#x27;1.50&#x27;","categories":[{"name":"问题随笔","slug":"问题随笔","permalink":"https://zsc-cloud.github.io/categories/%E9%97%AE%E9%A2%98%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"微信小程序","slug":"微信小程序","permalink":"https://zsc-cloud.github.io/tags/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F/"}]},{"title":"Redis基础知识","slug":"Redis基础知识","date":"2021-05-07T08:23:39.000Z","updated":"2022-03-26T03:42:17.252Z","comments":true,"path":"2021/05/07/Redis基础知识/","link":"","permalink":"https://zsc-cloud.github.io/2021/05/07/Redis%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","excerpt":"","text":"Redis概念Redis是一个使用C语言编写的，开源的高性能非关系型的数据库，键值对形式 应用场景在日常的 Web 应用对数据库的访问中，读操作的次数远超写操作，比例大概在 1:9 到 3:7，所以需要读的可能性是比写的可能大得多的。当我们使用 SQL 语句去数据库进行读写操作时，数据库就会 去磁盘把对应的数据索引取回来，这是一个相对较慢的过程。 如果我们把数据放在 Redis 中，也就是直接放在内存之中，让服务端直接去读取内存中的数据，那么这样 速度 明显就会快上不少 *(高性能)*，并且会 极大减小数据库的压力 *(特别是在高并发情况下)*。 但是使用内存进行数据存储开销也是比较大的，限于成本 的原因，一般我们只是使用 Redis 存储一些 常用和主要的数据，比如用户登录的信息等。 高并发的情况下，MySQL不适合存取数据，效率太低。 做缓存，比如我们将用户登陆信息存进redis,这样我们可以更加方便的管理用户的权限，将用户信息存进Redis中，每次用户登陆的时候在http请求头Header中携带一个token ,访问其他地址的时候，后端直接用这个token解析用户数据，判断是否有权限访问。 数据类型常用字符串Stringstring 类型是 Redis 最基本的数据类型，string 类型的值最大能存储 512MB。 常用命令：set、get、decr、incr、mget等。 字典HashRedis hash 是一个键值(key=&gt;value)对集合；是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象。 常用命令：hget、hset、hgetall等。 应用场景：存储一些结构化的数据，比如用户的昵称、年龄、性别、积分等，存储一个用户信息对象数据。 当然也可以JSON序列号一下存入string 列表ListRedis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。 list类型经常会被用于消息队列的服务，以完成多程序之间的消息交换。 常用命令：lpush、rpush、lpop、rpop、lrange等。 集合SetRedis的Set是string类型的无序集合。和列表一样，在执行插入和删除和判断是否存在某元素时，效率是很高的。集合最大的优势在于可以进行交集并集差集操作 集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。 应用场景： 1、利用交集求共同好友。 2、利用唯一性，可以统计访问网站的所有独立IP。 3、好友推荐的时候根据tag求交集，大于某个threshold（临界值的）就可以推荐。 常用命令：sadd、spop、smembers、sunion等。 有序集合SortedSet。Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。 不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。 zset的成员是唯一的,但分数(score)却可以重复。 sorted set是插入有序的，即自动排序。 常用命令：zadd、zrange、zrem、zcard等。 当你需要一个有序的并且不重复的集合列表时，那么可以选择sorted set数据结构。 应用举例： （1）例如存储全班同学的成绩，其集合value可以是同学的学号，而score就可以是成绩。（2）排行榜应用，根据得分列出topN的用户等。 扩展HyperLogLog基数统计(Cardinality Counting) 通常是用来统计一个集合中不重复的元素个数。 HyperLogLog是一个概率算法。会有一定的误差性。 一个 HyperLogLog 实际占用的空间大约是 12 KB，但 Redis 对于内存的优化非常变态，当 计数比较小 的时候，大多数桶的计数值都是 零，这个时候 Redis 就会适当节约空间，转换成另外一种 稀疏存储方式，与之相对的，正常的存储模式叫做 密集存储，这种方式会恒定地占用 12 KB。 HyperLoglog 也只需要 12 K 内存，在 标准误差 0.81% 的前提下，能够统计 2的64次方 个数据！ 在大量统计数据的时候可以替代Set，极大极大的压缩了内存占用情况 HyperLogLog 提供了两个指令 PFADD 和 PFCOUNT，字面意思就是一个是增加，另一个是获取计数。PFADD 和 set 集合的 SADD 的用法是一样的，来一个用户 ID，就将用户 ID 塞进去就是，PFCOUNT 和 SCARD 的用法是一致的，直接获取计数值 参考：https://www.wmyskxz.com/2020/03/02/reids-4-shen-qi-de-hyperloglog-jie-jue-tong-ji-wen-ti/ GeoHash这是业界比较通用的，用于 地理位置距离排序 的一个算法，Redis 也采用了这样的算法。GeoHash 算法将 二维的经纬度 数据映射到 一维 的整数，这样所有的元素都将在挂载到一条线上，距离靠近的二维坐标映射到一维后的点之间距离也会很接近。当我们想要计算 「附近的人时」，首先将目标位置映射到这条线上，然后在这个一维的线上获取附近的点就行了。 它的核心思想就是把整个地球看成是一个 二维的平面，然后把这个平面不断地等分成一个一个小的方格，每一个 坐标元素都位于其中的 唯一一个方格 中，等分之后的 方格越小，那么坐标也就 越精确 这个数据类型可以实现一些功能，如附近的人，附近的公司等等操作 参考：https://www.wmyskxz.com/2020/03/12/redis-6-geohash-cha-zhao-fu-jin-de-ren/ Pub/SubBloomFilter布隆过滤器（Bloom Filter） 是 1970 年由布隆提出的。它 实际上 是一个很长的二进制向量和一系列随机映射函数 *(下面详细说)*，实际上你也可以把它 简单理解 为一个不怎么精确的 set 结构，当你使用它的 contains 方法判断某个对象是否存在时，它可能会误判。但是布隆过滤器也不是特别不精确，只要参数设置的合理，它的精确度可以控制的相对足够精确，只会有小小的误判概率。 当布隆过滤器说某个值存在时，这个值 可能不存在；当它说不存在时，那么 一定不存在。打个比方，当它说不认识你时，那就是真的不认识，但是当它说认识你的时候，可能是因为你长得像它认识的另外一个朋友 *(脸长得有些相似)*，所以误判认识你。 布隆过滤器的使用场景 基于上述的功能，我们大致可以把布隆过滤器用于以下的场景之中： 大数据判断是否存在：这就可以实现出上述的去重功能，如果你的服务器内存足够大的话，那么使用 HashMap 可能是一个不错的解决方案，理论上时间复杂度可以达到 O(1 的级别，但是当数据量起来之后，还是只能考虑布隆过滤器。 解决缓存穿透：我们经常会把一些热点数据放在 Redis 中当作缓存，例如产品详情。 通常一个请求过来之后我们会先查询缓存，而不用直接读取数据库，这是提升性能最简单也是最普遍的做法，但是 如果一直请求一个不存在的缓存，那么此时一定不存在缓存，那就会有 大量请求直接打到数据库 上，造成 缓存穿透，布隆过滤器也可以用来解决此类问题。 爬虫/ 邮箱等系统的过滤：平时不知道你有没有注意到有一些正常的邮件也会被放进垃圾邮件目录中，这就是使用布隆过滤器 误判 导致的。 参考：https://www.wmyskxz.com/2020/03/11/redis-5-yi-ji-shu-ju-guo-lu-he-bu-long-guo-lu-qi/ https://juejin.cn/post/6844903982209449991 持久化什么是持久化？Redis 的数据 全部存储 在 内存 中，如果 突然宕机，数据就会全部丢失，因此必须有一套机制来保证 Redis 的数据不会因为故障而丢失，这种机制就是 Redis 的 持久化机制，它会将内存中的数据库状态 保存到磁盘 中。 持久化发生了什么我们来稍微考虑一下 Redis 作为一个 “内存数据库” 要做的关于持久化的事情。通常来说，从客户端发起请求开始，到服务器真实地写入磁盘，需要发生如下几件事情： 客户端向数据库 发送写命令 (数据在客户端的内存中) 数据库 接收 到客户端的 写请求 (数据在服务器的内存中) 数据库 调用系统 API 将数据写入磁盘 (数据在内核缓冲区中) 操作系统将 写缓冲区 传输到 磁盘控控制器 (数据在磁盘缓存中) 操作系统的磁盘控制器将数据 写入实际的物理媒介 中 (数据在磁盘中) Redis 中的两种持久化方式RDB（快照）Redis 快照 是最简单的 Redis 持久性模式。当满足特定条件时，它将生成数据集的时间点快照，例如，如果先前的快照是在 2 分钟前创建的，并且现在已经至少有 100 次新写入，则将创建一个新的快照。此条件可以由用户配置 Redis 实例来控制，也可以在运行时修改而无需重新启动服务器。快照作为包含整个数据集的单个 .rdb 文件生成。 AOF快照不是很持久。如果运行 Redis 的计算机停止运行，电源线出现故障或者您 kill -9 的实例意外发生，则写入 Redis 的最新数据将丢失。尽管这对于某些应用程序可能不是什么大问题，但有些使用案例具有充分的耐用性，在这些情况下，快照并不是可行的选择。 AOF(Append Only File - 仅追加文件) 它的工作方式非常简单：每次执行 修改内存 中数据集的写操作时，都会 记录 该操作。假设 AOF 日志记录了自 Redis 实例创建以来 所有的修改性指令序列，那么就可以通过对一个空的 Redis 实例 顺序执行所有的指令，也就是 「重放」，来恢复 Redis 当前实例的内存数据结构的状态。 Redis 4.0 的混合持久化重启 Redis 时，我们很少使用 rdb 来恢复内存状态，因为会丢失大量数据。我们通常使用 AOF 日志重放，但是重放 AOF 日志性能相对 rdb 来说要慢很多，这样在 Redis 实例很大的情况下，启动需要花费很长的时间。 Redis 4.0 为了解决这个问题，带来了一个新的持久化选项——混合持久化。将 rdb 文件的内容和增量的 AOF 日志文件存在一起。这里的 AOF 日志不再是全量的日志，而是 自持久化开始到持久化结束 的这段时间发生的增量 AOF 日志，通常这部分 AOF 日志很小： 于是在 Redis 重启的时候，可以先加载 rdb 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，重启效率因此大幅得到提升。 参考：https://www.wmyskxz.com/2020/03/13/redis-7-chi-jiu-hua-yi-wen-liao-jie/ RDB 和 AOF 各自有什么优缺点？RDB | 优点 只有一个文件 dump.rdb，方便持久化。 容灾性好，一个文件可以保存到安全的磁盘。 性能最大化，fork 子进程来完成写操作，让主进程继续处理命令，所以使 IO 最大化。使用单独子进程来进行持久化，主进程不会进行任何 IO 操作，保证了 Redis 的高性能 相对于数据集大时，比 AOF 的 启动效率 更高。 RDB | 缺点 数据安全性低。RDB 是间隔一段时间进行持久化，如果持久化之间 Redis 发生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候； AOF | 优点 数据安全，aof 持久化可以配置 appendfsync 属性，有 always，每进行一次命令操作就记录到 aof 文件中一次。 通过 append 模式写文件，即使中途服务器宕机，可以通过 redis-check-aof 工具解决数据一致性问题。 AOF 机制的 rewrite 模式。AOF 文件没被 rewrite 之前（文件过大时会对命令 进行合并重写），可以删除其中的某些命令（比如误操作的 flushall） AOF | 缺点 AOF 文件比 RDB 文件大，且 恢复速度慢。 数据集大 的时候，比 rdb 启动效率低。 恢复过程拷贝 AOF 文件到 Redis 的数据目录，启动 redis-server AOF 的数据恢复过程：Redis 虚拟一个客户端，读取 AOF 文件恢复 Redis 命令和参数，然后执行命令从而恢复数据，这些过程主要在 loadAppendOnlyFile() 中实现。 拷贝 RDB 文件到 Redis 的数据目录，启动 redis-server 即可，因为 RDB 文件和重启前保存的是真实数据而不是命令状态和参数。 分布式锁为何需要分布式锁一般情况下，我们使用分布式锁主要有两个场景： 避免不同节点重复相同的工作：比如用户执行了某个操作有可能不同节点会发送多封邮件； 避免破坏数据的正确性：如果两个节点在同一条数据上同时进行操作，可能会造成数据错误或不一致的情况出现； 原理基于 Redis 的单线程：由于 Redis 是单线程，所以命令会以串行的方式执行，并且本身提供了像 SETNX(set if not exists) 这样的指令，本身具有互斥性； 分布式锁必须满足一下条件 互斥性。在任意时刻，只有一个客户端能持有锁。 不会发生死锁。即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。 有容错性。只要大部分的Redis节点正常运行，客户端就可以加锁和解锁。 加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了。 实现方式加锁就一行代码： jedis.set(String key, String value, String nxxx, String expx, int time)这个set()方法一共有五个形参： 第一个为key，我们使用key来当锁，因为key是唯一的。 第二个为value，我们传的是requestId，有key作为锁不就够了吗，为什么还要用到value？原因就是我们在上面讲到可靠性时，分布式锁要满足第四个条件，通过给value赋值为requestId，我们就知道这把锁是哪个请求加的了，在解锁的时候就可以有依据。requestId可以使用UUID.randomUUID().toString()方法生成。 第三个为nxxx，这个参数我们填的是NX，意思是SET IF NOT EXIST，即当key不存在时，我们进行set操作；若key已经存在，则不做任何操作； 第四个为expx，这个参数我们传的是PX，意思是我们要给这个key加一个过期的设置，具体时间由第五个参数决定。 第五个为time，与第四个参数相呼应，代表key的过期时间。 总的来说，执行上面的set()方法就只会导致两种结果： 当前没有锁（key不存在），那么就进行加锁操作，并对锁设置个有 效期，同时value表示加锁的客户端。 已有锁存在，不做任何操作。 我们的加锁代码满足我们可靠性里描述的三个条件。首先，set()加入了NX参数，可以保证如果已有key存在，则函数不会调用成功，也就是只有一个客户端能持有锁，满足互斥性。其次，由于我们对锁设置了过期时间，即使锁的持有者后续发生崩溃而没有解锁，锁也会因为到了过期时间而自动解锁（即key被删除），不会发生死锁。最后，因为我们将value赋值为requestId，代表加锁的客户端请求标识，那么在客户端在解锁的时候就可以进行校验是否是同一个客户端 正确的加锁方式：123456789101112131415161718192021222324public class RedisTool &#123; private static final String LOCK_SUCCESS = &quot;OK&quot;; private static final String SET_IF_NOT_EXIST = &quot;NX&quot;; private static final String SET_WITH_EXPIRE_TIME = &quot;PX&quot;; /** * 尝试获取分布式锁 * @param jedis Redis客户端 * @param lockKey 锁 * @param requestId 请求标识 * @param expireTime 超期时间 * @return 是否获取成功 */ public static boolean tryGetDistributedLock(Jedis jedis, String lockKey, String requestId, int expireTime) &#123; String result = jedis.set(lockKey, requestId, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, expireTime); if (LOCK_SUCCESS.equals(result)) &#123; return true; &#125; return false; &#125;&#125; 错误的加锁方式：setnx()方法作用就是SET IF NOT EXIST，expire()方法就是给锁加一个过期时间。乍一看好像和前面的set()方法结果一样，然而由于这是两条Redis命令，不具有原子性，如果程序在执行完setnx()之后突然崩溃，导致锁没有设置过期时间。那么将会发生死锁。网上之所以有人这样实现，是因为低版本的jedis并不支持多参数的set()方法。 123456789public static void wrongGetLock1(Jedis jedis, String lockKey, String requestId, int expireTime) &#123; Long result = jedis.setnx(lockKey, requestId); if (result == 1) &#123; // 若在这里程序突然崩溃，则无法设置过期时间，将发生死锁 jedis.expire(lockKey, expireTime); &#125;&#125; 正确解锁方式1234567891011121314151617181920212223242526public class RedisTool &#123; private static final Long RELEASE_SUCCESS = 1L; /** * 释放分布式锁 * @param jedis Redis客户端 * @param lockKey 锁 * @param requestId 请求标识 * @return 是否释放成功 */ public static boolean releaseDistributedLock(Jedis jedis, String lockKey, String requestId) &#123; // LUA脚本 String script = &quot;if redis.call(&#x27;get&#x27;, KEYS[1]) == ARGV[1] then return redis.call(&#x27;del&#x27;, KEYS[1]) else return 0 end&quot;; Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(requestId)); if (RELEASE_SUCCESS.equals(result)) &#123; return true; &#125; return false; &#125;&#125; 第一行代码，我们写了一个简单的Lua脚本代码，上一次见到这个编程第二行代码，我们将Lua代码传到jedis.eval()方法里，并使参数KEYS[1]赋值为lockKey，ARGV[1]赋值为requestId。eval()方法是将Lua代码交给Redis服务端执行。 那么这段Lua代码的功能是什么呢? 首先获取锁对应的value值，检查是否与requestId相等，如果相等则删除锁（解锁）。那么为什么要使用Lua语言来实现呢？因为要确保上述操作是原子性的。那么为什么执行eval()方法可以确保原子性，源于Redis的特性 简单来说，就是在eval命令执行Lua代码的时候，Lua代码将被当成一个命令去执行，并且直到eval命令执行完成，Redis才会执行其他命令。 错误示例这种解锁代码乍一看也是没问题，与正确姿势差不多，唯一区别的是分成两条命令去执行，代码如下： 12345678public static void wrongReleaseLock2(Jedis jedis, String lockKey, String requestId) &#123; // 判断加锁与解锁是不是同一个客户端 if (requestId.equals(jedis.get(lockKey))) &#123; // 若在此时，这把锁突然不是这个客户端的，则会误解锁 jedis.del(lockKey); &#125;&#125; 问题在于如果调用jedis.del()方法的时候，这把锁已经不属于当前客户端的时候会解除他人加的锁。那么是否真的有这种场景？答案是肯定的，比如客户端A加锁，一段时间之后客户端A解锁，在执行jedis.del()之前，锁突然过期了，此时客户端B尝试加锁成功，然后客户端A再执行del()方法，则将客户端B的锁给解除了。 Redis 分布式锁的问题1）锁超时假设现在我们有两台平行的服务 A B，其中 A 服务在 获取锁之后 由于未知神秘力量突然 挂了，那么 B 服务就永远无法获取到锁了： 所以我们需要额外设置一个超时时间，来保证服务的可用性。 但是另一个问题随即而来：如果在加锁和释放锁之间的逻辑执行得太长，以至于超出了锁的超时限制，也会出现问题。因为这时候第一个线程持有锁过期了，而临界区的逻辑还没有执行完，与此同时第二个线程就提前拥有了这把锁，导致临界区的代码不能得到严格的串行执行。 为了避免这个问题，Redis 分布式锁不要用于较长时间的任务。如果真的偶尔出现了问题，造成的数据小错乱可能就需要人工的干预。 有一个稍微安全一点的方案是 将锁的 value 值设置为一个随机数，释放锁时先匹配随机数是否一致，然后再删除 key，这是为了 确保当前线程占有的锁不会被其他线程释放，除非这个锁是因为过期了而被服务器自动释放的。 但是匹配 value 和删除 key 在 Redis 中并不是一个原子性的操作，也没有类似保证原子性的指令，所以可能需要使用像 Lua 这样的脚本来处理了，因为 Lua 脚本可以 保证多个指令的原子性执行。 2）单点/多点问题如果 Redis 采用单机部署模式，那就意味着当 Redis 故障了，就会导致整个服务不可用。 而如果采用主从模式部署，我们想象一个这样的场景：服务 A 申请到一把锁之后，如果作为主机的 Redis 宕机了，那么 服务 B 在申请锁的时候就会从从机那里获取到这把锁，为了解决这个问题，Redis 作者提出了一种 RedLock 红锁 的算法 *(Redission 同 Jedis)*： 123456789// 三个 Redis 集群RLock lock1 = redissionInstance1.getLock(&quot;lock1&quot;);RLock lock2 = redissionInstance2.getLock(&quot;lock2&quot;);RLock lock3 = redissionInstance3.getLock(&quot;lock3&quot;);RedissionRedLock lock = new RedissionLock(lock1, lock2, lock2);lock.lock();// do something....lock.unlock(); 缓存雪崩，击穿，穿透缓存雪崩产生的原因 同一时间内，大量Redis中的缓存同时失效。 举个简单的例子：如果所有首页的Key失效时间都是12小时，中午12点刷新的，我零点有个秒杀活动大量用户涌入，假设当时每秒 6000 个请求，本来缓存在可以扛住每秒 5000 个请求，但是缓存当时所有的Key都失效了。此时 1 秒 6000 个请求全部落数据库，数据库必然扛不住。这就是我理解的缓存雪崩。 解决方式 处理缓存雪崩简单，在批量往Redis存数据的时候，把每个Key的失效时间都加个随机值就好了，这样可以保证数据不会在同一时间大面积失效。 1setRedis（Key，value，time + Math.random() * 10000）； 缓存穿透缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求，我们数据库的 id 都是1开始自增上去的，如发起为id值为 -1 的数据或 id 为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大，严重会击垮数据库。 像这种你如果不对参数做校验，数据库id都是大于0的，我一直用小于0的参数去请求你，每次都能绕开Redis直接打到数据库，数据库也查不到，每次都这样，并发高点就容易崩掉了。 解决方式 在接口层增加校验，比如用户鉴权校验，参数做校验，不合法的参数直接代码Return，比如：id 做基础校验，id &lt;=0的直接拦截等 这里我想提的一点就是，我们在开发程序的时候都要有一颗“不信任”的心，就是不要相信任何调用方，比如你提供了API接口出去，你有这几个参数，那我觉得作为被调用方，任何可能的参数情况都应该被考虑到，做校验，因为你不相信调用你的人，你不知道他会传什么参数给你。 从缓存取不到的数据，在数据库中也没有取到，这时也可以将对应Key的Value对写为null、位置错误、稍后重试这样的值具体取啥问产品，或者看具体的场景，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。 Redis还有一个高级用法布隆过滤器（Bloom Filter）这个也能很好的防止缓存穿透的发生，他的原理也很简单就是利用高效的数据结构和算法快速判断出你这个Key是否在数据库中存在，不存在你return就好了，存在你就去查了DB刷新KV再return。 缓存击穿缓存击穿嘛，这个跟缓存雪崩有点像，但是又有一点不一样，缓存雪崩是因为大面积的缓存失效，打崩了DB，而缓存击穿不同的是缓存击穿是指一个Key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个Key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个完好无损的桶上凿开了一个洞。 解决：设置热点数据永远不过期。或者加上互斥锁就能搞定了 Redis 淘汰策略Redis key过期的方式有三种： 惰性删除：当读/写一个已经过期的key时，会触发惰性删除策略，直接删除掉这个过期key（无法保证冷数据被及时删掉） 定期删除：Redis会定期主动淘汰一批已过期的key（随机抽取一批key检查） 内存淘汰机制：当前已用内存超过maxmemory限定时，触发主动清理策略 如果没有设置有效期，即使内存用完，redis 自动回收机制也是看设置了有效期的，不会动没有设定有效期的，如果清理后内存还是满的，就不再接受写操作。 redis最大内存不足”时,数据清除策略,默认为”volatile-lru”。 策略 描述 volatile-lru 从已设置过期时间的 KV 集中优先对最近最少使用(less recently used)的数据淘汰（默认） volitile-ttl 从已设置过期时间的 KV 集中优先对剩余时间短(time to live)的数据淘汰 random 从已设置过期时间的 KV 集中随机选择数据淘汰 allkeys-lru 从已设置过期时间的 KV 集中随机选择数据淘汰 allKeys-random 从所有 KV 集中随机选择数据淘汰 noeviction 从所有 KV 集中随机选择数据淘汰 4.0 版本后增加以下两种 volatile-lfu：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰 allkeys-lfu：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key OtherRedis 为什么早期版本选择单线程？官方解释因为 Redis 是基于内存的操作，CPU 不是 Redis 的瓶颈，Redis 的瓶颈最有可能是 机器内存的大小 或者 网络带宽。既然单线程容易实现，而且 CPU 不会成为瓶颈，那就顺理成章地采用单线程的方案了。 简单总结一下 使用单线程模型能带来更好的 可维护性，方便开发和调试； 使用单线程模型也能 并发 的处理客户端的请求；(I/O 多路复用机制) Redis 服务中运行的绝大多数操作的 性能瓶颈都不是 CPU； Redis 为什么这么快？ 纯内存操作：读取不需要进行磁盘 I/O，所以比传统数据库要快上不少；*(但不要有误区说磁盘就一定慢，例如 Kafka 就是使用磁盘顺序读取但仍然较快)* 单线程，无锁竞争：这保证了没有线程的上下文切换，不会因为多线程的一些操作而降低性能； 多路 I/O 复用模型，非阻塞 I/O：采用多路 I/O 复用技术可以让单个线程高效的处理多个网络连接请求（尽量减少网络 IO 的时间消耗）； 高效的数据结构，加上底层做了大量优化：Redis 对于底层的数据结构和内存占用做了大量的优化，例如不同长度的字符串使用不同的结构体表示，HyperLogLog 的密集型存储结构等等.. 缓存一致性 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。 更新的时候，先更新数据库，然后再删除缓存。 redis的线程模型Redis 内部使用文件事件处理器 file event handler，这个文件事件处理器是单线程的，所以 Redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 Socket，根据 Socket 上的事件来选择对应的事件处理器进行处理。","categories":[{"name":"Java","slug":"Java","permalink":"https://zsc-cloud.github.io/categories/Java/"},{"name":"Redis","slug":"Java/Redis","permalink":"https://zsc-cloud.github.io/categories/Java/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://zsc-cloud.github.io/tags/Redis/"}]},{"title":"Lock","slug":"Lock","date":"2021-05-03T07:41:11.000Z","updated":"2022-03-26T03:42:17.417Z","comments":true,"path":"2021/05/02/Lock/","link":"","permalink":"https://zsc-cloud.github.io/2021/05/02/Lock/","excerpt":"","text":"Locklock锁是什么Lock是JDK中的一个接口，两个直接实现类 ReentrantLock（重入锁）, ReentrantReadWriteLock（读写锁）。 Lock锁，使用时手动获取锁和释放锁，比synchronized更加灵活；可中断的获取锁；超时获取锁。 12345678 //默认情况下 锁是不公平的; 公平锁(参数true)表示等待时间长优先获取到锁 private final static Lock lock = new ReentrantLock(true);lock.lock(); // 上锁try &#123; // access the resource protected by this lock&#125; finally &#123; lock.unlock(); // 解锁&#125; Lock锁的常用API lock（） 获得锁。 unlock() 释放锁。 tryLock(long time, TimeUnit unit) 尝试获取锁，参数为等待时长，超时将不等待 Lock和synchronized的简单对比 synchronized是Java的关键字，在JVM层面； Lock是一个接口，JDK层面 synchronized不管代码运行是否异常，都会释放锁； lock必须在finally中释放锁，不然容易造成死锁 synchronized没有获取到锁的线程会一直等待 ； lock可以选择不等待，或者设置等待时间 synchronized无法判断锁的状态； lock可以通过 tryLock判断锁的状态 synchronized是非公平锁，不可中断；lock可以选择是否公平，通过lock.lockInterruptibly();中断 ReentrantLock可重入锁。如果当前线程t1通过调用lock方法获取了锁之后，再次调用lock，是不会再阻塞去获取锁的，直接增加重入次数就行了。与每次lock对应的是unlock，unlock会减少重入次数，重入次数减为0才会释放锁。 ReentrantLock构造器为一个公平锁或者不公平锁 123public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; 12// new FairSync() : new NonfairSync()又继承了Sync锁static final class NonfairSync extends Sync 12// Sync继承了AQSabstract static class Sync extends AbstractQueuedSynchronizer &#123; 源码解析：https://www.cnblogs.com/lixuwu/p/10788297.html ReentrantReadWriteLock123private final ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); lock.writeLock().lock(); 写锁 lock.readLock().lock(); 读锁 可重入读写锁。读写锁维护了一个读锁，一个写锁。 读锁同一时刻允许多个读线程访问。 写锁同一时刻只允许一个写线程，其他读/写线程都需要阻塞。 CopyOnWrite容器什么是CopyOnWrite容器 CopyOnWrite容器（简称COW容器）即写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。 从JDK1.5开始Java并发包里提供了两个使用CopyOnWrite机制实现的并发容器,它们是CopyOnWriteArrayList和CopyOnWriteArraySet。 CopyOnWrite并发容器用于读多写少的并发场景。比如：白名单，黑名单。假如我们有一个搜索网站，用户在这个网站的搜索框中，输入关键字搜索内容，但是某些关键字不允许被搜索。这些不能被搜索的关键字会被放在一个黑名单当中，黑名单一定周期才会更新一次。 缺点：内存占用问题。写的时候会创建新对象添加到新容器里，而旧容器的对象还在使用，所以有两份对象内存。通过压缩容器中的元素的方法来减少大对象的内存消耗，比如，如果元素全是10进制的数字，可以考虑把它压缩成36进制或64进制。或者不使用CopyOnWrite容器，而使用其他的并发容器，如ConcurrentHashMap。 数据一致性问题。CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。所以如果你希望写入的的数据，马上能读到，请不要使用CopyOnWrite容器。 CAS机制CAS机制全称compare and swap，翻译为比较并交换，是一种有名的无锁（lock-free）算法。也是一种现代 CPU 广泛支持的CPU指令级的操作，只有一步原子操作，所以非常快。而且CAS避免了请求操作系统来裁定锁的问题，直接在CPU内部就完成了。 CAS是乐观锁的一种实现方式，是一种轻量级锁 Unsafe类是CAS的核心类，提供硬件级别的原子操作（目前所有CPU基本都支持硬件级别的CAS操作） 12// 对象、对象的地址、预期值、修改值public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); CAS 是怎么实现线程安全的？执行函数：CAS(V,E,N) 其包含3个参数 V表示要更新的变量 E表示预期值 N表示新值 如果V值等于E值，则将V的值设为N。若V值和E值不同，则说明已经有其他线程做了更新，则当前线程什么都不做。通俗的理解就是CAS操作需要我们提供一个期望值，当期望值与当前线程的变量值相同时，说明还没线程修改该值，当前线程可以进行修改，也就是执行CAS操作，但如果期望值与当前线程不符，则说明该值已被其他线程修改，此时不执行更新操作，但可以选择重新读取该变量再尝试再次修改该变量，也可以放弃操作，原理图如下 比如：我们要更新一个字段的值，由A更新到B ,这个时候，我们那A，B去更新，先拿到A的值跟原数据比较，如果数据还是A值，说明没有操作过这个数据，那么修改为B成功，若此时字段的值变成了C，则说明有人操作过，操作失败，重新再执行一次。 由于CAS操作属于乐观派，它总认为自己可以成功完成操作，当多个线程同时使用CAS操作一个变量时，只有一个会胜出，并成功更新，其余均会失败，但失败的线程并不会被挂起，仅是被告知失败，并且允许再次尝试（自旋），当然也允许失败的线程放弃操作，这点从图中也可以看出来。基于这样的原理，CAS操作即使没有锁，同样知道其他线程对共享资源操作影响，并执行相应的处理措施。同时从这点也可以看出，由于无锁操作中没有锁的存在，因此不可能出现死锁的情况，也就是说无锁操作天生免疫死锁。 CAS产生的问题：ABA问题解决方案：加标志位，例如搞个自增的字段，操作一次就自增加一，或者搞个时间戳，比较时间戳的值。 举个栗子：现在我们去要求操作数据库，根据CAS的原则我们本来只需要查询原本的值就好了，现在我们一同查出他的标志位版本字段vision。 在atomic包中有一个类：AtomicStampedReference，参数可以设置时间戳 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * @author zsc * @date 2021/5/24 * AtomicStampedReference时间戳解决aba问题 */public class ABADemo &#123; public static void main(String[] args) &#123; Integer stamped = 1; User user = new User(100, &quot;小明&quot;); User user1 = new User(110, &quot;小明2&quot;); User user2 = new User(2000, &quot;小明3&quot;); User user3 = new User(3000, &quot;小明4&quot;); AtomicStampedReference&lt;User&gt; reference = new AtomicStampedReference&lt;User&gt;(user,stamped); System.out.println(reference.getReference());//获取值 System.out.println(reference.getStamp());// 获取时间戳 boolean b = reference.compareAndSet(user, user2, 1, 2); System.out.println(b); System.out.println(reference.getReference());//获取值 System.out.println(reference.getStamp());// 获取时间戳 boolean c = reference.compareAndSet(user2, user3, 3, 4); System.out.println(c); System.out.println(reference.getReference());//获取值 System.out.println(reference.getStamp());// 获取时间戳 &#125;&#125;@Dataclass User&#123; private Integer age; private String name; public User(Integer age, String name) &#123; this.age = age; this.name = name; &#125; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; User user = (User) o; return Objects.equals(age, user.age) &amp;&amp; Objects.equals(name, user.name); &#125; @Override public int hashCode() &#123; return Objects.hash(age, name); &#125;&#125; 自旋时间过长使用CAS时非阻塞同步，也就是说不会将线程挂起，会自旋（无非就是一个死循环）进行下一次尝试，如果这里自旋时间过长对性能是很大的消耗。如果JVM能支持处理器提供的pause指令，那么在效率上会有一定的提升。 只能保证一个共享变量的原子操作当对一个共享变量执行操作时CAS能保证其原子性，如果对多个共享变量进行操作，CAS就不能保证其原子性。有一个解决方案是利用对象整合多个共享变量，即一个类中的成员变量就是这几个共享变量。然后将这个对象做CAS操作就可以保证其原子性。atomic中提供了AtomicReference来保证引用对象之间的原子性。 AQS概述：AbstractQueuedSynchronizer抽象队列同步器简称AQS，它是实现同步器的基础组件（框架），juc下面Lock的实现以及一些并发工具类（Semaphore、CountDownLatch、CyclicBarrier等）就是通过AQS来实现的。具体用法是通过继承AQS实现其模板方法，然后将子类作为同步组件的内部类。 实现过程：AQS的核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并将共享资源设置为锁定状态，如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。CLH（Craig，Landin，and Hagersten）队列是一个虚拟的双向队列，虚拟的双向队列即不存在队列实例，仅存在节点之间的关联关系。AQS是将每一条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node），来实现锁的分配。 用大白话来说，AQS就是基于CLH队列，用volatile修饰共享变量state，线程通过CAS去改变状态符，成功则获取锁成功，失败则进入等待队列，等待被唤醒。 AQS 定义了两种资源共享方式：1.Exclusive：独占，只有一个线程能执行，如ReentrantLock2.Share：共享，多个线程可以同时执行，如Semaphore、CountDownLatch、ReadWriteLock，CyclicBarrier 类似于Synchronized争抢监视器monitor 这里AQS队列中的线程争抢资源state AQS详解：https://blog.csdn.net/javazejian/article/details/75043422 乐观锁：CAS 自旋锁：do while(!CAS) 悲观锁：AQS底层 + volatile state ReentrantLock 阻塞队列（BlockingQueue）什么是BlockingQueue在多线程领域：所谓阻塞，在某些情况下会挂起线程（即阻塞），一旦条件满足，被挂起的线程又会自动被唤起 BlockingQueue即阻塞队列，是java.util.concurrent下的一个接口，因此不难理解，BlockingQueue是为了解决多线程中数据高效安全传输而提出的。从阻塞这个词可以看出，在某些情况下对阻塞队列的访问可能会造成阻塞。被阻塞的情况主要有如下两种： 当队列满了的时候进行入队列操作 当队列空了的时候进行出队列操作 因此，当一个线程试图对一个已经满了的队列进行入队列操作时，它将会被阻塞，除非有另一个线程做了出队列操作；同样，当一个线程试图对一个空队列进行出队列操作时，它将会被阻塞，除非有另一个线程进行了入队列操作。 阻塞队列主要用在生产者/消费者的场景，下面这幅图展示了一个线程生产、一个线程消费的场景： ​ 为什么需要BlockingQueue 好处是我们不需要关心什么时候需要阻塞线程，什么时候需要唤醒线程，因为这一切BlockingQueue都给你一手包办了。在concurrent包发布以前，在多线程环境下，我们每个程序员都必须去自己控制这些细节，尤其还要兼顾效率和线程安全，而这会给我们的程序带来不小的复杂度。 认识BlockingQueuejava.util.concurrent 包里的 BlockingQueue是一个接口，继承Queue接口，Queue接口继承 Collection。 实现类 BlockingQueue接口主要有以下7个实现类： ArrayBlockingQueue：由数组结构组成的有界阻塞队列。 LinkedBlockingQueue：由链表结构组成的有界（但大小默认值为integer.MAX_VALUE）阻塞队列。 PriorityBlockingQueue：支持优先级排序的无界阻塞队列。 DelayQueue：使用优先级队列实现的延迟无界阻塞队列。 SynchronousQueue：不存储元素的阻塞队列，也即单个元素的队列。 LinkedTransferQueue：由链表组成的无界阻塞队列。 LinkedBlockingDeque：由链表组成的双向阻塞队列。","categories":[{"name":"Java","slug":"Java","permalink":"https://zsc-cloud.github.io/categories/Java/"},{"name":"JUC","slug":"Java/JUC","permalink":"https://zsc-cloud.github.io/categories/Java/JUC/"}],"tags":[{"name":"JUC","slug":"JUC","permalink":"https://zsc-cloud.github.io/tags/JUC/"},{"name":"并发编程","slug":"并发编程","permalink":"https://zsc-cloud.github.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"锁","slug":"锁","permalink":"https://zsc-cloud.github.io/tags/%E9%94%81/"}]},{"title":"GC机制(一)","slug":"GC机制-一","date":"2021-05-01T07:47:18.000Z","updated":"2022-03-26T03:42:17.279Z","comments":true,"path":"2021/04/30/GC机制-一/","link":"","permalink":"https://zsc-cloud.github.io/2021/04/30/GC%E6%9C%BA%E5%88%B6-%E4%B8%80/","excerpt":"","text":"对象怎么什么时候被回收？JVM判断对象回收有两种方式： 引用记数引用记数比较简单，JVM为每个对象维护一个引用计数，假设A对象引用计数为零说明没有任务对象引用A对象，那A对象就可以被回收了，但是引用计数有个缺点就是无法解决循环引用**的问题。 循环引用就是两个孤零零的对象互相引用，a对象引用b,b对象引用a ，他们的引用计数都不为零，故此处陷入死循环 GC Roots(标记)可达性分析算法，也叫标记 GC Roots通过一系列的名为GC Roots的对象作为起始点，从这些节点开始向下搜索，搜索过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连时，则证明对象是不可用的。 标记的过程其实就是，从根对象开始遍历所有的对象，然后将所有存活的对象标记为可达的对象。 在Java中，可以作为GC Roots的对象包括下面几种： 虚拟机栈中引用的对象（正在运行的方法使用到的变量、参数等） 方法区中类静态属性引用的对象（static关键字声明的字段） 方法区中常量引用的对象，(也就是final关键字声明的字段) 本地方法栈中引用的对象（native方法） Java虚拟机内部的引用。（系统内部的东西当然能作为根了） 例如： GC Roots算法是从离散数学中的图论引入的，程序把所有的引用关系看作一张图，从一个节点 GC ROOT 开始，寻找对应的引用节点，找到这个节点以后，继续寻找这个节点的引用节点，当所有的引用节点寻找完毕之后，剩余的节点则被认为是没有被引用到的节点，即无用的节点。如上图中的 ObjF、ObjD、ObjE通过 GC Root 是无法找到的，所以它们是无用节点。 总的来说就是当一个对象通过GC Roots搜索不到时，说明对象可以被回收了 垃圾回收算法 四大基本算法：引用计数法，标记清除法，标记整理法，复制算法 分带算法，分区算法 引用计数法引用计数算法很简单，它实际上是通过在对象头中分配一个空间来保存该对象被引用的次数。如果该对象被其它对象引用，则它的引用计数加一，如果删除对该对象的引用，那么它的引用计数就减一，当该对象的引用计数为0时，那么该对象就会被回收。 有代码如下: String p = new String(“abc”); abc这个字符串对象的引用计数值为1. 将引用变量p的值设置为0 p = null; 引用计数垃圾收集机制，它只是在引用计数变化为0时即刻发生，而且只针对某一个对象以及它所依赖的其它对象。所以，我们一般也称呼引用计数垃圾收集为直接的垃圾收集机制.垃圾收集的开销被分摊到整个应用程序的运行当中了，而不是在进行垃圾收集时，要挂起整个应用的运行，直到对堆中所有对象的处理都结束。因此，采用引用计数的垃圾收集不属于严格意义上的”Stop-The-World”的垃圾收集机制。 优点: 实时性较高, 不需要等到内存不够时才回收 垃圾回收时不用挂起整个程序, 不影响程序正常运行. 缺点: 回收时不移动对象, 所以会造成内存碎片问题. 解决不了对象相互引用 标记清除它的做法是当堆中的有效内存空间被耗尽的时候，就会停止整个程序（也被成为stop the world），然后进行两项工作，第一项则是标记，第二项则是清除。标记：从根集合（GC Root)开始扫描，每到达一个对象就会标记该对象为存活状态， 清除：过程将遍历堆中所有的对象，将没有标记的对象全部清除掉。 优点 : 实现简单 缺点 : 效率低, 因为标记和清除两个动作都要遍历所有的对象 垃圾收集后有可能会造成大量的内存碎片, 垃圾回收时会造成应用程序暂停. 标记整理既然叫标记-整理算法，那么它也分为两个阶段，一个是标记(mark)，一个是整理(compact). 标记 : 标记的过程其实就是，从根对象开始遍历所有的对象，然后将所有存活的对象标记为可达的对象。 压缩 : 移动所有的可达对象到堆内存的同一个区域中，使他们紧凑的排列在一起，从而将所有非可达对象释放出来的空闲内存都集中在一起，通过这样的方式来达到减少内存碎片的目的。 标记整理就没有内存碎片的问题了，也是从根集合（GC Root)开始扫描进行标记然后清除无用的对象，清除完成后它会整理内存。 优点 : 标记压缩算法是对标记清除算法的优化, 解决了碎片化的问题 缺点 : 还是效率问题, 在标记清除算法上又多加了一步, 效率可想而知会更慢 复制算法复制算法的核心就是，将原有的内存空间一分为二，每次只用其中的一块，在垃圾回收时，将正在使用的对象复制到另一个内存空间中，并以此排列, 然后将该内存空间清空，交换两个内存的角色，完成垃圾的回收。 复制算法会将JVM堆分成二等分，如果堆设置的是1g，那使用复制算法的时候堆就会有被划分为两块区域各512m。给对象分配内存的时候总是使用其中的一块来分配，分配满了以后，GC就会进行标记，然后将存活的对象移动到另外一块空白的区域，然后清除掉所有没有存活的对象，这样重复的处理，始终就会有一块空白的区域没有被合理的利用到。 优点: 在垃圾多的情况下(新生代), 效率较高 清理后, 内存无碎片 缺点: 浪费了一半的内存空间 在存活对象较多的情况下(老年代), 效率较差 分代收集算法分代收集算法是目前大部分 JVM 的垃圾收集器采用的算法。 核心思想是根据对象存活的生命周期将内存划分为若干个不同的区域。一般情况下将堆区划分为老年代（Old Generation）和新生代（Young Generation），老年代的特点是每次垃圾收集时只有少量对象需要被回收，而新生代的特点是每次垃圾回收时都有大量的对象需要被回收，那么就可以根据不同代的特点采取最适合的收集算法。 分代算法其实就是这样的，根据回收对象的特点进行选择，在jvm中， • 新生代适合使用复制算法， • 老年代适合使用标记整理算法 区域划分：新生代占1/3 老年代占2/3 年轻代: 所有新生成的对象首先都是放在年轻代的。年轻代的目标就是尽可能快速的收集掉那些生命周期短的对象。 新生代内存按照8:1:1的比例分为一个 eden 区和两个 survivor(幸存区) 区（from survivor，to survivor）。大部分对象在 Eden 区中生成。回收时先将 eden 区存活对象复制到from 区，然后清空 eden 区，当这个 from 区也存放满了时，则将 eden 区和 from 区存活对象复制到另一个 to 区，然后清空 eden 和这个 from 区，此时 from 区是空的，然后将 from 区和 to 区交换，即保持 to 区为空， 如此往复。 新生代这样划分是为了更好的管理堆内存中的对象，方便GC算法—复制算法来进行垃圾回收。JVM每次只会使用eden和其中一块survivor来为对象服务，所以无论什么时候，都会有一块survivor空间，因此新生代实际可用空间只有90%。 当 to区不足以存放 eden 和 from 的存活对象时，就将存活对象直接存放到老年代。若是老年代也满了就会触发一次 Full GC ，也就是新生代、老年代都进行回收。 新生代发生的 GC 也叫做 Minor GC ，Minor GC 发生频率比较高(不一定等 Eden 区满了才触发)，也叫小GC，每一次Full GC都会产生小GC 老年代 在年轻代中经历了 N 次垃圾回收后仍然存活的对象，就会被放到年老代中。因此，可以认为年老代中存放的都是一些生命周期较长的对象。 内存比新生代也大很多(大概比例是1:2)，当老年代内存满时触发 Major GC 即 Full GC，Full GC 发生频率比较低，老年代对象存活时间比较长，存活率标记高。 什么时候对象会进入老年代？ 1. 根据对象年龄 JVM会给对象增加一个年龄（age）的计数器，对象每“熬过”一次GC，年龄就要+1，待对象到达设置的阈值（默认为15岁）就会被移移动到老年代，可通过-XX:MaxTenuringThreshold调整这个阈值。 即 一次Minor GC后，对象年龄就会+1，达到阈值的对象就移动到老年代，其他存活下来的对象会继续保留在新生代中。 2. 动态年龄判断 根据对象年龄有另外一个策略也会让对象进入老年代，不用等待15次GC之后进入老年代，他的大致规则就是，假如当前放对象的Survivor，一批对象的总大小大于这块Survivor内存的50%，那么大于这批对象年龄的对象，就可以直接进入老年代了。 现有A（age=2）、B(age=2)、D(age=10)、E(age=11)这四个对象，假如from区是100m，如果A + B + D的内存大小超过50m，现在D的年龄是10，那E都会被移动到老年代。实际上这个计算逻辑是这样的：年龄1 + 年龄2 + 年龄n的多个对象总和超过Survivor区的50%，那就会把年龄n以上的对象都放入老年代。 3. 大对象直接进入老年代 如果设置了-XX:PretenureSizeThreshold这个参数，那么如果你要创建的对象大于这个参数的值，比如分配一个超大的字节数组，此时就直接把这个大对象放入到老年代，不会经过新生代。 这么做就可以避免大对象在新生代，屡次躲过GC，还得把他们来复制来复制去的，最后才进入老年代，这么大的对象来回复制，是很耗费时间的。 GC 类型： Minor GC(新生代 GC):新生代 GC，指发生在新生代的垃圾收集动作，因为 Java 对象大多都具备朝生熄灭的特点，所以 Minor GC 十分频繁，回收速度也较快。 Major GC(老年代 GC):老年代 GC，指发生在老年代的垃圾收集动作，当出现 Major GC 时，一般也会伴有至少一次的 Minor GC（并非绝对，例如 Parallel Scavenge 收集器会单独直接触发 Major GC 的机制）。 Major GC 的速度一般会比 Minor GC 慢十倍以上。 Full GC:清理整个堆空间—包括年轻代和老年代。Major GC == Full GC。 产生 Full GC 可能的原因： 年老代被写满。 System.gc() 被显示调用。 上一次 GC 之后 Heap（堆） 的各域分配策略动态变化。 分区收集算法上面介绍的分代收集算法是将对象的生命周期按长短划分为两个部分, 而分区算法则将整个堆空间划分为连续的不同小区间, 每个小区间独立使用, 独立回收. 这样做的好处是可以控制一次回收多少个小区间. 在相同条件下, 堆空间越大, 一次GC耗时就越长, 从而产生的停顿也越长. 为了更好地控制GC产生的停顿时间, 将一块大的内存区域分割为多个小块, 根据目标停顿时间, 每次合理地回收若干个小区间(而不是整个堆), 从而减少一次GC所产生的停顿. 垃圾回收器的分类串行垃圾回收器Serial 收集器 新生代串行回收器SerialGC : 采用复制算法实现, 单线程垃圾回收, 独占式垃圾回收器 老年代串行回收器SerialOldGC : 采用标记压缩算法, 单线程独占式垃圾回收器 并行垃圾回收器Parallel收集器 新生代Parallel ScavengeGC回收器: 采用复制算法多线程独占式回收器 老年代Parallel OldGC回收器: 采用标记压缩算法, 多线程独占式回收器 我的本机使用jconsole，查看是PS MarkSweep JDK版本为：jdk1.8.0_91 CMS回收器CMS全称 (Concurrent Mark Sweep)，是一款并发的、使用标记-清除算法的垃圾回收器. 启用CMS回收器参数 : -XX:+UseConcMarkSweepGC。 使用场景：GC过程短暂停，适合对时延要求较高的服务，用户线程不允许长时间的停顿。 优点: CMS收集器是一种以获取最短回收停顿时间为目标的收集器. 并发收集，低停顿 缺点：服务长时间运行，造成严重的内存碎片化。算法实现比较复杂；CMS收集器对CPU资源非常敏感 G1回收器 G1(Garbage-First)是一款面向服务端应用的并发垃圾回收器, 主要目标用于配备多颗CPU的服务器治理大内存. 是 JDK1.7 提供的一个新收集器，是当今收集器技术发展的最前沿成果之一 G1计划作为并发标记-清除收集器的长期替代品 启用G1收集器参数: -XX:+UseG1GC 启用G1收集器. G1将整个Java堆划分为多个大小相等的独立区域(Region), 虽然还保留有新生代和老年代的概念, 但新生代和老年代不再是物理隔离的了, 它们都是一部分Region(不需要连续)的集合. 每块区域既有可能属于Old区、也有可能是Young区, 因此不需要一次就对整个老年代/新生代回收. 而是当线程并发寻找可回收的对象时, 有些区块包含可回收的对象要比其他区块多很多. 虽然在清理这些区块时G1仍然需要暂停应用线程, 但可以用相对较少的时间优先回收垃圾较多的Region(这也是G1命名的来源). 这种方式保证了G1可以在有限的时间内获取尽可能高的收集效率. JDK8的垃圾回收器我们通过查看Java参数的方式查询到默认的垃圾回收器为ParallelGC 引用《深入理解Java虚拟机：JVM高级特性与最佳实践》的介绍： UseParallelGC = Parallel Scavenge + PS MarkSweep。 PS MarkSweep和Serial Old很像，一般书上会把他们当做一个去讲解。 这个PS MarkSweep默认的实现实际上是一层皮，它底下真正做mark-sweep-compact工作的代码是跟分代式GC框架里的serial old（这个collector名字叫做MarkSweepCompact）是共用同一份代码的。也就是说实际上PS MarkSweep与MarkSweepCompact在HotSpot VM里是同一个collector实现，包了两张不同的皮；这个collector是串行的。 其实也可以通过jconsole工具直接看到使用的垃圾收集器 设置参数如下： ​","categories":[{"name":"Java","slug":"Java","permalink":"https://zsc-cloud.github.io/categories/Java/"},{"name":"JVM","slug":"Java/JVM","permalink":"https://zsc-cloud.github.io/categories/Java/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://zsc-cloud.github.io/tags/JVM/"},{"name":"GC","slug":"GC","permalink":"https://zsc-cloud.github.io/tags/GC/"}]},{"title":"JVM内存结构","slug":"JVM内存结构","date":"2021-04-30T07:50:31.000Z","updated":"2022-03-26T03:42:17.318Z","comments":true,"path":"2021/04/29/JVM内存结构/","link":"","permalink":"https://zsc-cloud.github.io/2021/04/29/JVM%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84/","excerpt":"","text":"本文都是基于JDK1.8讨论 类加载器什么是类加载器Java中的所有类，都需要由类加载器装载到JVM中才能运行。类加载器本身也是一个类，而它的工作就是把class文件从硬盘读取到内存中。在写程序的时候，我们几乎不需要关心类的加载，因为这些都是隐式装载的，除非我们有特殊的用法，像是反射，就需要显式的加载所需要的类。 Java类的加载是动态的，它并不会一次性将所有类全部加载后再运行，而是保证程序运行的基础类(像是基类)完全加载到jvm中，至于其他类，则在需要的时候才加载。这当然就是为了节省内存开销。 类加载类型Java的类加载器有三个，对应Java的三种类: Bootstrap Loader(启动类加载器)由C++写的,由JVM启动 启动类加载器，也叫引导加载器。是虚拟机自身的一部分。负责将存放在\\lib目录中的类库加载到虚拟机中。其无法被Java程序直接引用。 负责加载系统类 (指的是内置类 像是String) ExtClassLoader(扩展加载器)是一个Java类,继承自URLClassLoader 扩展类加载器, 负责加载扩展类(如所有javax.*开头的类和存放在%JAVA_HOME%\\lib\\ext目录中的jar和class等 AppClassLoader(应用加载器)Java类,继承自URLClassLoader 系统类加载器, 负责加载用户类路径（ClassPath）上所指定的类库(程序员自定义的类) 自定义加载器这个由程序员自己来写 双亲委派机制三个加载器各自完成自己的工作，但它们是如何协调工作呢？哪一个类该由哪个类加载器完成呢？为了解决这个问题，Java采用了委托模型机制。(双亲委派模式) 工作原理当某个类加载器需要加载某个.class文件时，它首先把这个任务委托给他的上级类加载器，递归这个操作，如果上级的类加载器没有加载，自己才会去加载这个类 双亲委派机制的作用 防止重复加载同一个.class。通过委托去向上面问一问，加载过了，就不用再加载一遍。保证数据安全。 保证核心.class不能被篡改。通过委托方式，不会去篡改核心.class，即使篡改也不会去加载，即使加载也不会是同一个.class对象了。不同的加载器加载同一个.class也不是同一个Class对象。这样保证了Class执行安全 我们可以通过这样的代码来获取类加载器: 12ClassLoader loader = ClassName.class.getClassLoader();ClassLoader ParentLoader = loader.getParent(); 注意一个很重要的问题，就是Java在逻辑上并不存在BootstrapKLoader的实体！因为它是用C++编写的，所以打印其内容将会得到null。 类加载的过程前面是对类加载器的简单介绍，它的原理机制非常简单，就是下面几个步骤: 装载:查找和导入class文件; 连接: 检查:检查载入的class文件数据的正确性; 准备:为类的静态变量分配存储空间; 解析:将符号引用转换成直接引用(这一步是可选的) 初始化:初始化静态变量，静态代码块 使用：代码中根据Class类型new对象或执行其它操作。 卸载：虚拟机通过垃圾回收将类信息及相关的实例数据从虚拟机内存区域中移除。 JVM中的内存结构JVM内存结构可以大致可划分为线程私有区域和共享区域，线程私有区域由虚拟机栈、本地方法栈、程序计数器组成，而共享区域由堆、元数据空间（方法区）组成。 ps：在JDK1.8中，Sun HotSpot虚拟机把虚拟机栈和本地方法栈合并为 Java栈 方法区是jdk1.7之前的叫法，在1.8中叫做元空间 虚拟机栈虚拟机栈是用于描述java方法执行的内存模型。 作用：每个java方法在执行时，会创建一个“栈帧（stack frame）”，栈帧的结构分为“局部变量表、操作数栈、动态链接、方法出口”几个部分。我们常说的“堆内存、栈内存”中的“栈内存”指的便是虚拟机栈，确切地说，指的是虚拟机栈的栈帧中的局部变量表，因为这里存放了一个方法的所有局部变量。 栈中放置以下内容：栈中存放基本类型的原值和引用类型的地址值. 基本类型包括：byte,short,int,long,char,float,double,Boolean,returnAddress ；引用类型包括：类类型，接口类型和数组。 方法调用时，创建栈帧，并压入虚拟机栈；方法执行完毕，栈帧出栈并被销毁，如下图所示： 局部变量表 : 保存函数参数,局部变量(当前函数有效,函数执行结束它销毁) 操作数栈 : 存中间运算结果, 临时存储空间 帧数据区 : 保存访问常量池指针, 异常处理表 虚拟机栈是线程隔离的，即每个线程都有自己独立的虚拟机栈。 若单个线程请求的栈深度大于虚拟机允许的深度，则会抛出StackOverflowError（栈溢出错误）。 举个粟子：如下图 ，假设JVM参数-Xss设置为1m，如果某个方法里面创建一个128kb的数组，那这个方法在同一个线程中只能递归4次，再递归第五次的时候就会报StackOverflowException异常，因为虚拟机栈的大小只有1m，每次递归都需要为方法在虚拟机栈中分配128kb的空间，很显示到第五次的时候就空间不足了。 本地方法栈本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的， 用于本地方法调用, JDK源码中好多使用了Native关键字, 也就是调用底层C语言编写的方法. 与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常 程序计数器也叫PC寄存器 是一个记录着当前线程所执行的字节码的行号指示器。JVM的多线程是通过CPU时间片轮转（即线程轮流切换并分配处理器执行时间）算法来实现的。也就是说，某个线程在执行过程中可能会因为时间片耗尽而被挂起，而另一个线程获取到时间片开始执行。 简单的说程序计数器的主要功能就是记录着当前线程所执行的字节码的行号指示器。 方法区在JDK8叫元数据区 方法区存储了类的元数据信息、静态变量、常量等数据。 方法区的大小决定系统可以保存多少个类。如果系统定义太多的类，导致方法区溢出。虚拟机同样会抛出内存溢出的错误。 堆（heap)平常大家使用new关键字创建的对象都会进入堆中，堆也是GC重点照顾的区域，堆会被划分为：新生代、老年代，而新生代还会被进一步划分为Eden区和Survivor区： 在堆中产生了一个数组或者对象后，还可以在栈中定义一个特殊的变量，这个变量的取值等于数组或者对象在堆内存中的首地址，在栈中的这个特殊的变量就变成了数组或者对象的引用变量，以后就可以在程序中使用栈内存中的引用变量来访问堆中的数组或者对象，引用变量相当于为数组或者对象起的一个别名或者代号 String a = new Stirng(“123”) 此时new出来的对象放在heap中，但是这个引用a要放在栈中 在JDK1.8之前还有一个永久区，在1.8中去掉，永久区的数据现在保存在元空间中 新生代中的Eden区和Survivor（From区和To区）区，是根据 JVM回收算法来的，只是现在大部分都是使用的分代回收算法，所以在介绍堆的时候会直接将新生代归纳为Eden区和Survivor区。 堆的详情信息会在GC中说明 直接内存作用 : 提高一些场景中的性能. 直接内存并不是虚拟机运行时数据区的一部分，也不是Java 虚拟机规范中农定义的内存区域。 在JDK1.4 中新加入了NIO(New Input/Output)类，引入了一种基于通道(Channel)与缓冲区（Buffer）的I/O 方式，它可以使用native 函数库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByteBuffer 对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。 本机直接内存的分配不会受到Java 堆大小的限制，受到本机总内存大小限制 配置虚拟机参数时，不要忽略直接内存 防止出现OutOfMemoryError异常 直接内存（堆外内存）与堆内存比较 直接内存申请空间耗费更高的性能，当频繁申请到一定量时尤为明显 直接内存IO读写的性能要优于普通的堆内存，在多次读写操作的情况下差异明显 JVM内存模型小结： JVM内存模型划分为线程私有区域和共享区域 虚拟机栈/本地方法栈负责存放线程执行方法栈帧 程序计数器用于记录线程执行指令的位置 元空间区存储类的元数据信息、静态变量、常量等数据 堆（heap)使用new关键字创建的对象都会进入堆中，堆被划分为新生代和老年代 内存模型以及分区，需要详细到每个区放什么？ 方法区：主要是存储类信息，常量池（static 常量和 static 变量），编译后的代码（字节码）等数 堆：初始化的对象，成员变量 （那种非 static 的变量），所有的对象实例和数组都要在堆上分配 栈：引用放在栈里面；栈的结构是栈帧组成的，调用一个方法就压入一帧，帧上面存储局部变量表，操作数栈，方法出口等信息，局部变量表存放的是 8 大基础类型加上一个应用类型，所以还是一个指向地址的指针 程序计数器：记录当前线程执行的行号 直接内存：NIO的操作 创建一个对象在内存中的变化java在new一个对象的时候，会先查看对象所属的类有没有被加载到内存，如果没有的话，就会先通过类的全限定名来加载。加载并初始化类完成后，再进行对象的创建工作。 我们先假设是第一次使用该类，这样的话new一个对象就可以分为两个过程：加载并初始化类和创建对象。 类加载过程（第一次使用该类）java是使用双亲委派模型来进行类的加载的，所以在描述类加载过程前，我们先看一下它的工作过程： 双亲委托模型的工作过程是：如果一个类加载器（ClassLoader）收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委托给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父类加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需要加载的类）时，子加载器才会尝试自己去加载。 使用双亲委托机制的好处是：能够有效确保一个类的全局唯一性，当程序中出现多个限定名相同的类时，类加载器在执行加载时，始终只会加载其中的某一个类。 1、加载由类加载器负责根据一个类的全限定名来读取此类的二进制字节流到JVM内部，并存储在运行时内存区的方法区，然后将其转换为一个与目标类型对应的java.lang.Class对象实例 2、验证 格式验证：验证是否符合class文件规范 语义验证：检查一个被标记为final的类型是否包含子类；检查一个类中的final方法是否被子类进行重写；确保父类和子类之间没有不兼容的一些方法声明（比如方法签名相同，但方法的返回值不同） 操作验证：在操作数栈中的数据必须进行正确的操作，对常量池中的各种符号引用执行验证（通常在解析阶段执行，检查是否可以通过符号引用中描述的全限定名定位到指定类型上，以及类成员信息的访问修饰符是否允许访问等） 3、准备为类中的所有静态变量分配内存空间，并为其设置一个初始值（由于还没有产生对象，实例变量不在此操作范围内） 被final修饰的static变量（常量），会直接赋值； 4、解析将常量池中的符号引用转为直接引用（得到类或者字段、方法在内存中的指针或者偏移量，以便直接调用该方法），这个可以在初始化之后再执行。解析需要静态绑定的内容。 // 所有不会被重写的方法和域都会被静态绑定 以上2、3、4三个阶段又合称为链接阶段，链接阶段要做的是将加载到JVM中的二进制字节流的类数据信息合并到JVM的运行时状态中。 5、初始化（先父后子） 4.1 为静态变量赋值 4.2 执行static代码块 注意：static代码块只有jvm能够调用 如果是多线程需要同时初始化一个类，仅仅只能允许其中一个线程对其执行初始化操作，其余线程必须等待，只有在活动线程执行完对类的初始化操作之后，才会通知正在等待的其他线程。 因为子类存在对父类的依赖，所以类的加载顺序是先加载父类后加载子类，初始化也一样。不过，父类初始化时，子类静态变量的值也有有的，是默认值。 最终，方法区会存储当前类类信息，包括类的静态变量、类初始化代码（定义静态变量时的赋值语句 和 静态初始化代码块）、实例变量定义、实例初始化代码（定义实例变量时的赋值语句实例代码块和构造方法）和实例方法，还有父类的类信息引用。 创建对象 堆内初始化，栈内引用 1、在堆区分配对象需要的内存分配的内存包括本类和父类的所有实例变量，但不包括任何静态变量 2、对所有实例变量赋默认值将方法区内对实例变量的定义拷贝一份到堆区，然后赋默认值 3、执行实例初始化代码初始化顺序是先初始化父类再初始化子类，初始化时先执行实例代码块然后是构造方法 4、如果有类似于Child c = new Child()形式的c引用的话，在栈区定义Child类型引用变量c，然后将堆区对象的地址赋值给它 需要注意的是，每个子类对象持有父类对象的引用，可在内部通过super关键字来调用父类对象，但在外部不可访问 补充： 通过实例引用调用实例方法的时候，先从方法区中对象的实际类型信息找，找不到的话再去父类类型信息中找。 如果继承的层次比较深，要调用的方法位于比较上层的父类，则调用的效率是比较低的，因为每次调用都要经过很多次查找。这时候大多系统会采用一种称为虚方法表的方法来优化调用的效率。 所谓虚方法表，就是在类加载的时候，为每个类创建一个表，这个表包括该类的对象所有动态绑定的方法及其地址，包括父类的方法，但一个方法只有一条记录，子类重写了父类方法后只会保留子类的。当通过对象动态绑定方法的时候，只需要查找这个表就可以了，而不需要挨个查找每个父类。","categories":[{"name":"Java","slug":"Java","permalink":"https://zsc-cloud.github.io/categories/Java/"},{"name":"JVM","slug":"Java/JVM","permalink":"https://zsc-cloud.github.io/categories/Java/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://zsc-cloud.github.io/tags/JVM/"}]},{"title":"线程通讯","slug":"线程通讯","date":"2021-04-25T07:37:48.000Z","updated":"2022-03-26T03:42:17.339Z","comments":true,"path":"2021/04/24/线程通讯/","link":"","permalink":"https://zsc-cloud.github.io/2021/04/24/%E7%BA%BF%E7%A8%8B%E9%80%9A%E8%AE%AF/","excerpt":"","text":"概述 线程与线程之间不是相互独立的个体，它们彼此之间需要相互通信和协作。 最典型的例子就是生产者-消费者问题：当队列满时，生产者需要等待队列有空间才能继续往里面放入商品，而在等待的期间内，生产者必须释放对临界资源（即队列）的占用权。因为生产者如果不释放对临界资源的占用权，那么消费者就无法消费队列中的商品，就不会让队列有空间，那么生产者就会一直无限等待下去。因此一般情况下，当队列满时，会让生产者交出对临界资源的占用权，并进入挂起状态。然后等待消费者消费了商品，然后消费者通知生产者队列有空间了。同样地，当队列空时，消费者也必须等待，等待生产者通知它队列中有商品了。这种互相通信的过程就是线程间的协作 wait()-notify()wait()、notify() 和 notifyAll()方法是 本地方法，并且为 final 方法，无法被重写； 调用某个对象的 wait() 方法能让 当前线程释放锁并且进入（等待）阻塞，并且当前线程必须拥有此对象的monitor（即锁）； 调用某个对象的 notify() 方法能够唤醒 一个正在等待这个对象的monitor的线程，如果有多个线程都在等待这个对象的monitor，则只能唤醒其中一个线程； 调用notifyAll()方法能够唤醒所有正在等待这个对象的monitor的线程。 在使用这3个方法时，必须处于synchronized代码块或者synchronized方法中，否则就会抛出IllegalMonitorStateException异常，这是因为调用这几个方法前必须拿到当前对象的监视器monitor对象，也就是说notify/notifyAll和wait方法依赖于monitor对象，在前面的分析中，我们知道monitor 存在于对象头的Mark Word 中(存储monitor引用指针)，而synchronized关键字可以获取 monitor ，这也就是为什么notify/notifyAll和wait方法必须在synchronized代码块或者synchronized方法调用的原因。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * @author zsc * @date 2021/5/24 * 两个线程轮流打印A和B */// 定义一个资源类class DataShare&#123; int status = 0; public synchronized void printAAA()&#123; while (status != 0)&#123; try &#123; this.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(&quot;打印的是:AAAA&quot;); this.notifyAll(); status = 1; &#125; public synchronized void printBBB()&#123; while (status == 0)&#123; try &#123; this.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(&quot;打印的是:BBBB&quot;); this.notifyAll(); status = 0; &#125;&#125;public class NotifyDemo &#123; public static void main(String[] args) &#123; DataShare dataShare = new DataShare(); new Thread(()-&gt;&#123; for (int i = 0; i &lt;10 ; i++) &#123; dataShare.printAAA(); &#125; &#125;,&quot;A&quot; ).start(); new Thread(()-&gt;&#123; for (int i = 0; i &lt;10 ; i++) &#123; dataShare.printBBB(); &#125; &#125;,&quot;A&quot; ).start(); &#125;&#125; 虚假唤醒上面演示的Demo中，判断要使用while而不能是if 注意，消费者被唤醒后是从wait()方法（被阻塞的地方）后面执行，而不是重新从同步块开头。 使用if判断之后，代码从wait方法后面执行，此时不会再进行一次if判断，假如这个时候在进来线程，就会出现混乱 而使用while（）之后，执行到while方法内，还会拉回while方法判断一次 ConditionCondition是在java 1.5中出现的，它用来替代传统的Object的wait()/notify()实现线程间的协作，它的使用依赖于 Lock，Condition、Lock 和 Thread 三者之间的关系如下图所示。 相比使用Object的wait()/notify()，使用Condition的await()/signal()这种方式能够更加安全和高效地实现线程间协作。 Condition是个接口，基本的方法就是await()和signal()方法。Condition依赖于Lock接口，生成一个Condition的基本代码是lock.newCondition() 。 必须要注意的是，Condition 的 await()/signal() 使用都必须在lock保护之内，也就是说，必须在lock.lock()和lock.unlock之间才可以使用。 Conditon的await()/signal() 与 Object的wait()-notify() 有着天然的对应关系：**Conditon中的await()对应Object的wait()；Condition中的signal()对应Object的notify()**；Condition中的signalAll()对应Object的notifyAll()。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103/** * @author zsc * @date 2021/5/24 * 使用lock中的线程通知 * 三个线程轮流打印AA BB CC * 使用Condition进行精准通知 */// 定义一个资源类class DataShare1&#123; private final Lock lock = new ReentrantLock(); private Condition conditionA = lock.newCondition(); private Condition conditionB = lock.newCondition(); private Condition conditionC = lock.newCondition(); int status = 0; public void printAAA() throws InterruptedException &#123; try &#123; lock.lock(); while (status != 0)&#123; conditionA.await(); &#125; System.out.println(&quot;打印的是:AAAA&quot;); status = 1; conditionB.signal(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void printBBB() throws InterruptedException &#123; try &#123; lock.lock(); while (status != 1)&#123; conditionB.await(); &#125; System.out.println(&quot;打印的是:BBBB&quot;); status = 2; conditionC.signal(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void printCCC() throws InterruptedException &#123; try &#123; lock.lock(); while (status != 2)&#123; conditionC.await(); &#125; System.out.println(&quot;打印的是:CCCC&quot;); status = 0; conditionA.signal(); &#125; finally &#123; lock.unlock(); &#125; &#125;&#125;public class NotifyDemo &#123; public static void main(String[] args) &#123; DataShare1 dataShare = new DataShare1(); new Thread(()-&gt;&#123; for (int i = 0; i &lt;10 ; i++) &#123; try &#123; dataShare.printAAA(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;,&quot;A&quot; ).start(); new Thread(()-&gt;&#123; for (int i = 0; i &lt;10 ; i++) &#123; try &#123; dataShare.printBBB(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;,&quot;B&quot; ).start(); new Thread(()-&gt;&#123; for (int i = 0; i &lt;10 ; i++) &#123; try &#123; dataShare.printCCC(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;,&quot;C&quot; ).start(); &#125;&#125; 为什么这些操作线程的方法要定义在object类中呢？ Condition实现原理： https://blog.csdn.net/javazejian/article/details/75043422 暂时理解不到位，以后再看，先记录一下 Java中，任何对象都可以作为锁(synchronized)，既然wait是放弃对象锁，当然就要把wait定义在这个对象所属的类中。更通用一些，由于所有类都继承于Object，我们完全可以把wait方法定义在Object类中，这样，当我们定义一个新类，并需要以它的一个对象作为锁时，不需要我们再重新定义wait方法的实现，而是直接调用父类的wait(也就是Object的wait)，此处，用到了Java的继承。 有的人会说，既然是线程放弃对象锁，那也可以把wait定义在Thread类里面啊，新定义的线程继承于Thread类，也不需要重新定义wait方法的实现。然而，这样做有一个非常大的问题，一个线程完全可以持有很多锁，你一个线程放弃锁的时候，到底要放弃哪个锁？当然了，这种设计并不是不能实现，只是管理起来更加复杂。","categories":[{"name":"Java","slug":"Java","permalink":"https://zsc-cloud.github.io/categories/Java/"},{"name":"JUC","slug":"Java/JUC","permalink":"https://zsc-cloud.github.io/categories/Java/JUC/"}],"tags":[{"name":"JUC","slug":"JUC","permalink":"https://zsc-cloud.github.io/tags/JUC/"},{"name":"并发编程","slug":"并发编程","permalink":"https://zsc-cloud.github.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"线程","slug":"线程","permalink":"https://zsc-cloud.github.io/tags/%E7%BA%BF%E7%A8%8B/"}]},{"title":"JMM及Volatile关键字","slug":"JMM及Volatile关键字","date":"2021-04-23T06:48:04.000Z","updated":"2022-03-26T03:42:17.398Z","comments":true,"path":"2021/04/22/JMM及Volatile关键字/","link":"","permalink":"https://zsc-cloud.github.io/2021/04/22/JMM%E5%8F%8AVolatile%E5%85%B3%E9%94%AE%E5%AD%97/","excerpt":"","text":"理解Java内存区域与Java内存模型Java内存区域 Java虚拟机在运行程序时会把其自动管理的内存划分为以上几个区域，每个区域都有的用途以及创建销毁的时机，其中蓝色部分代表的是所有线程共享的数据区域，而绿色部分代表的是每个线程的私有数据区域。 方法区（Method Area）方法区属于线程共享的内存区域，又称Non-Heap（非堆），主要用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据，根据Java 虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError 异常。值得注意的是在方法区中存在一个叫运行时常量池(Runtime Constant Pool）的区域，它主要用于存放编译器生成的各种字面量和符号引用，这些内容将在类加载后存放到运行时常量池中，以便后续使用。 JVM堆（Java Heap）Java 堆也是属于线程共享的内存区域，它在虚拟机启动时创建，是Java 虚拟机所管理的内存中最大的一块，主要用于存放对象实例，几乎所有的对象实例都在这里分配内存，注意Java 堆是垃圾收集器管理的主要区域，因此很多时候也被称做GC 堆，如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError 异常。 程序计数器(Program Counter Register)属于线程私有的数据区域，是一小块内存空间，主要代表当前线程所执行的字节码行号指示器。字节码解释器工作时，通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 虚拟机栈(Java Virtual Machine Stacks)属于线程私有的数据区域，与线程同时创建，总数与线程关联，代表Java方法执行的内存模型。每个方法执行时都会创建一个栈桢来存储方法的的变量表、操作数栈、动态链接方法、返回值、返回地址等信息。每个方法从调用直结束就对于一个栈桢在虚拟机栈中的入栈和出栈过程 本地方法栈(Native Method Stacks)本地方法栈属于线程私有的数据区域，这部分主要与虚拟机用到的 Native 方法相关，一般情况下，我们无需关心此区域。 这里之所以简要说明这部分内容，注意是为了区别Java内存模型与Java内存区域的划分，毕竟这两种划分是属于不同层次的概念。 Java内存模型概述Java内存模型(即Java Memory Model，简称JMM)本身是一种抽象的概念，并不真实存在，它描述的是一组规则或规范，通过这组规范定义了程序中各个变量（包括实例字段，静态字段和构成数组对象的元素）的访问方式。由于JVM运行程序的实体是线程，而每个线程创建时JVM都会为其创建一个工作内存(有些地方称为栈空间)，用于存储线程私有的数据。 而Java内存模型中规定所有变量都存储在主内存，主内存是共享内存区域，所有线程都可以访问，但线程对变量的操作(读取赋值等)必须在工作内存中进行，首先要将变量从主内存拷贝的自己的工作内存空间，然后对变量进行操作，操作完成后再将变量写回主内存，不能直接操作主内存中的变量，工作内存中存储着主内存中的变量副本拷贝，前面说过，工作内存是每个线程的私有数据区域，因此不同的线程间无法访问对方的工作内存，线程间的通信(传值)必须通过主内存来完成，其简要访问过程如下图 需要注意的是，JMM与Java内存区域的划分是不同的概念层次，更恰当说JMM描述的是一组规则，通过这组规则控制程序中各个变量在共享数据区域和私有数据区域的访问方式 JMM是围绕原子性，有序性、可见性展开的。JMM与Java内存区域唯一相似点，都存在共享数据区域和私有数据区域，在JMM中主内存属于共享数据区域，从某个程度上讲应该包括了堆和方法区，而工作内存数据线程私有数据区域，从某个程度上讲则应该包括程序计数器、虚拟机栈以及本地方法栈。或许在某些地方，我们可能会看见主内存被描述为堆内存，工作内存被称为线程栈，实际上他们表达的都是同一个含义。关于JMM中的主内存和工作内存说明如下 主内存主要存储的是Java实例对象，所有线程创建的实例对象都存放在主内存中，不管该实例对象是成员变量还是方法中的本地变量(也称局部变量)，当然也包括了共享的类信息、常量、静态变量。由于是共享数据区域，多条线程对同一个变量进行访问可能会发现线程安全问题。 工作内存主要存储当前方法的所有本地变量信息(工作内存中存储着主内存中的变量副本拷贝)，每个线程只能访问自己的工作内存，即线程中的本地变量对其它线程是不可见的，就算是两个线程执行的是同一段代码，它们也会各自在自己的工作内存中创建属于当前线程的本地变量，当然也包括了字节码行号指示器、相关Native方法的信息。注意由于工作内存是每个线程的私有数据，线程间无法相互访问工作内存，因此存储在工作内存的数据不存在线程安全问题。 弄清楚主内存和工作内存后，接了解一下主内存与工作内存的数据存储类型以及操作方式，根据虚拟机规范，对于一个实例对象中的成员方法而言，如果方法中包含本地变量是基本数据类型（boolean,byte,short,char,int,long,float,double），将直接存储在工作内存的帧栈结构中，但倘若本地变量是引用类型，那么该变量的引用会存储在功能内存的帧栈中，而对象实例将存储在主内存(共享数据区域，堆)中。但对于实例对象的成员变量，不管它是基本数据类型或者包装类型(Integer、Double等)还是引用类型，都会被存储到堆区。至于static变量以及类本身相关信息将会存储在主内存中。需要注意的是，在主内存中的实例对象可以被多线程共享，倘若两个线程同时调用了同一个对象的同一个方法，那么两条线程会将要操作的数据拷贝一份到自己的工作内存中，执行完成操作后才刷新到主内存，简单示意图如下所示： Java内存模型的特地原子性原子性指的是一个操作是不可中断的，即使是在多线程环境下，一个操作一旦开始就不会被其他线程影响。比如对于一个静态变量int x，两条线程同时对他赋值，线程A赋值为1，而线程B赋值为2，不管线程如何运行，最终x的值要么是1，要么是2，线程A和线程B间的操作是没有干扰的，这就是原子性操作，不可被中断的特点。 可见性可见性指的是当一个线程修改了某个共享变量的值，其他线程是否能够马上得知这个修改的值。对于串行程序来说，可见性是不存在的，因为我们在任何一个操作中修改了某个变量的值，后续的操作中都能读取这个变量值，并且是修改过的新值。但在多线程环境中可就不一定了，前面我们分析过，由于线程对共享变量的操作都是线程拷贝到各自的工作内存进行操作后才写回到主内存中的，这就可能存在一个线程A修改了共享变量x的值，还未写回主内存时，另外一个线程B又对主内存中同一个共享变量x进行操作，但此时A线程工作内存中共享变量x对线程B来说并不可见，这种工作内存与主内存同步延迟现象就造成了可见性问题，另外指令重排以及编译器优化也可能导致可见性问题，通过前面的分析，我们知道无论是编译器优化还是处理器优化的重排现象，在多线程环境下，确实会导致程序轮序执行的问题，从而也就导致可见性问题。 有序性有序性是指对于单线程的执行代码，我们总是认为代码的执行是按顺序依次执行的，这样的理解并没有毛病，毕竟对于单线程而言确实如此，但对于多线程环境，则可能出现乱序现象，因为程序编译成机器码指令后可能会出现指令重排现象，重排后的指令与原指令的顺序未必一致，要明白的是，在Java程序中，倘若在本线程内，所有操作都视为有序行为，如果是多线程环境下，一个线程中观察另外一个线程，所有操作都是无序的，前半句指的是单线程内保证串行语义执行的一致性，后半句则指指令重排现象和工作内存与主内存同步延迟现象。 JMM提供的解决方案原子性问题，除了JVM自身提供的对基本数据类型读写操作的原子性外，对于方法级别或者代码块级别的原子性操作，可以使用synchronized关键字或者重入锁(ReentrantLock)保证程序执行的原子性 工作内存与主内存同步延迟现象可见性问题，可以使用synchronized关键字或者volatile关键字解决，它们都可以使一个线程修改后的变量立即对其他线程可见。 对于指令重排导致的可见性问题和有序性问题，则可以利用volatile关键字解决，因为volatile的另外一个作用就是禁止重排序优化，关于volatile稍后会进一步分析。 除了靠sychronized和volatile关键字来保证原子性、可见性以及有序性外，JMM内部还定义一套happens-before 原则来保证多线程环境下两个操作间的原子性、可见性以及有序性。 理解指令重排计算机在执行程序时，为了提高性能，编译器和处理器的常常会对指令做重排，一般分以下3种 编译器优化的重排 编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 指令并行的重排 现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性(即后一个执行的语句无需依赖前面执行的语句的结果)，处理器可以改变语句对应的机器指令的执行顺序 内存系统的重排 由于处理器使用缓存和读写缓存冲区，这使得加载(load)和存储(store)操作看上去可能是在乱序执行，因为三级缓存的存在，导致内存与缓存的数据同步存在时间差。 其中编译器优化的重排属于编译期重排，指令并行的重排和内存系统的重排属于处理器重排，在多线程环境中，这些重排优化可能会导致程序出现内存可见性问题 指令重排遵从两大原则 as-if-serial语义 happens-before规则 as-if-serial语义as-if-serial语义的意思是：不管怎么重排序，单个线程中的程序的执行结果不会改变。编译器、runtime和处理器都必须遵守as-if-serial语义。 为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。 但是，如果操作之间不存在数据依赖关系，这些操作就可能被编译器和处理器重排序。 1234567891011// 这个时候如果多线程的情况下，CPU指令重排可能会先执行int b = 2;在执行int a = 1;// 因为这个程序中不管怎么执行，他的语义都不会变化 int a = 1; int b = 2; -------------------------------------------------------------------------// 这个时候即使是在多线程的情况下，CPU也不会对指令进行重排// 因为下面的语句依赖上面的语句，这种重排序会对程序结果产生影响 int a = 1; int b = a + 1; JMM中的happens-before 原则倘若在程序开发中，仅靠sychronized和volatile关键字来保证原子性、可见性以及有序性，那么编写并发程序可能会显得十分麻烦，幸运的是，在Java内存模型中，还提供了happens-before 原则来辅助保证程序执行的原子性、可见性以及有序性的问题，它是判断数据是否存在竞争、线程是否安全的依据，happens-before 原则内容如下 程序顺序原则，即在一个线程内必须保证语义串行性，也就是说按照代码顺序执行。 锁规则 解锁(unlock)操作必然发生在后续的同一个锁的加锁(lock)之前，也就是说，如果对于一个锁解锁后，再加锁，那么加锁的动作必须在解锁动作之后(同一个锁)。 volatile规则 volatile变量的写，先发生于读，这保证了volatile变量的可见性，简单的理解就是，volatile变量在每次被线程访问时，都强迫从主内存中读该变量的值，而当该变量发生变化时，又会强迫将最新的值刷新到主内存，任何时刻，不同的线程总是能够看到该变量的最新值。 线程启动规则 线程的start()方法先于它的每一个动作，即如果线程A在执行线程B的start方法之前修改了共享变量的值，那么当线程B执行start方法时，线程A对共享变量的修改对线程B可见 传递性 A先于B ，B先于C 那么A必然先于C 线程终止规则 线程的所有操作先于线程的终结，Thread.join()方法的作用是等待当前执行的线程终止。假设在线程B终止之前，修改了共享变量，线程A从线程B的join方法成功返回后，线程B对共享变量的修改将对线程A可见。 线程中断规则 对线程 interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted()方法检测线程是否中断。 对象终结规则 对象的构造函数执行，结束先于finalize()方法 volatile内存语义volatile在并发编程中很常见，但也容易被滥用，现在我们就进一步分析volatile关键字的语义。volatile是Java虚拟机提供的轻量级的同步机制。volatile关键字有如下两个作用 可见性 禁止指令重排序优化 volatile的可见性关于volatile的可见性作用，我们必须意识到被volatile修饰的变量对所有线程总数立即可见的，对volatile变量的所有写操作总是能立刻反应到其他线程中，但是对于volatile变量运算操作在多线程环境并不保证安全性，如下 1234567public class VolatileVisibility &#123; public static volatile int i =0; public static void increase()&#123; i++; &#125;&#125; 正如上述代码所示，i变量的任何改变都会立马反应到其他线程中，但是如此存在多条线程同时调用increase()方法的话，就会出现线程安全问题，毕竟i++;操作并不具备原子性，该操作是先读取值，然后写回一个新值，相当于原来的值加上1，分两步完成，如果第二个线程在第一个线程读取旧值和写回新值期间读取i的域值，那么第二个线程就会与第一个线程一起看到同一个值，并执行相同值的加1操作，这也就造成了线程安全失败，因此对于increase方法必须使用synchronized修饰，以便保证线程安全，需要注意的是一旦使用synchronized修饰方法后，由于synchronized本身也具备与volatile相同的特性，即可见性，因此在这样种情况下就完全可以省去volatile修饰变量。 1234567public class VolatileVisibility &#123; public static int i =0; public synchronized static void increase()&#123; i++; &#125;&#125; 现在来看另外一种场景，可以使用volatile修饰变量达到线程安全的目的，如下 1234567891011121314public class VolatileSafe &#123; volatile boolean close; public void close()&#123; close=true; &#125; public void doWork()&#123; while (!close)&#123; System.out.println(&quot;safe....&quot;); &#125; &#125;&#125; 由于对于boolean变量close值的修改属于原子性操作，因此可以通过使用volatile修饰变量close，使用该变量对其他线程立即可见，从而达到线程安全的目的。那么JMM是如何实现让volatile变量对其他线程立即可见的呢？实际上，当写一个volatile变量时，JMM会把该线程对应的工作内存中的共享变量值刷新到主内存中，当读取一个volatile变量时，JMM会把该线程对应的工作内存置为无效，那么该线程将只能从主内存中重新读取共享变量。volatile变量正是通过这种写-读方式实现对其他线程可见（但其内存语义实现则是通过内存屏障，稍后会说明）。 前我们说过当多个处理器的运算任务都涉及同一块主内存区域时，将可能导致各自的缓存数据不一致，举例说明变量在多个CPU之间的共享。 如果真的发生这种情况，那同步回到主内存时以谁的缓存数据为准呢？ 为了解决一致性的问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作，这类协议有MSI、MESI（IllinoisProtocol）、MOSI、Synapse、Firefly及DragonProtocol等。 MESI（缓存一致性协议）当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。 至于是怎么发现数据是否失效呢？嗅探每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。 总线风暴 由于Volatile的MESI缓存一致性协议，需要不断的从主内存嗅探和cas不断循环，无效交互会导致总线带宽达到峰值。 所以不要大量使用Volatile，至于什么时候去使用Volatile什么时候使用锁，根据场景区分。 volatile禁止重排优化volatile关键字另一个作用就是禁止指令重排优化，从而避免多线程环境下程序出现乱序执行的现象，关于指令重排优化前面已详细分析过，这里主要简单说明一下volatile是如何实现禁止指令重排优化的。 先了解一个概念，内存屏障(Memory Barrier）。内存屏障，又称内存栅栏，是一个CPU指令，它的作用有两个，一是保证特定操作的执行顺序，二是保证某些变量的内存可见性（利用该特性实现volatile的内存可见性）。 由于编译器和处理器都能执行指令重排优化。如果在指令间插入一条Memory Barrier则会告诉编译器和CPU，不管什么指令都不能和这条Memory Barrier指令重排序，也就是说通过插入内存屏障禁止在内存屏障前后的指令执行重排序优化。 Memory Barrier的另外一个作用是强制刷出各种CPU的缓存数据，因此任何CPU上的线程都能读取到这些数据的最新版本。总之，volatile变量正是通过内存屏障实现其在内存中的语义，即可见性和禁止重排优化。 屏障类型 指令示例 说明 LoadLoad Load1;LoadLoad;Load2 保证Load1的读取操作在Load2及后续读取操作之前执行 StoreStore Store1;StoreStore;Store2 在Store2及其后的写操作执行前，保证Store1的写操作已刷新到主内存 LoadStore Load1;LoadStore;Store2 在Store2及其后的写操作执行前，保证Load1的读操作已读取结束 StoreLoad Store1;StoreLoad;Load2 保证load1的写操作已刷新到主内存之后，load2及其后的读操作才能执行 1234567891011121314151617class Singleton &#123; // 可见性和指令重排都保证 private volatile static Singleton instance = null; private Singleton()&#123;&#125; public static Singleton getInstance()&#123; // 第一次检查锁定 if(instance == null)&#123; // 同步锁定代码块 synchronized(Singleton.class)&#123; if(instance == null)&#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; volatile与synchronized的区别volatile只能修饰实例变量和类变量，而synchronized可以修饰方法，以及代码块。 volatile保证数据的可见性，但是不保证原子性(多线程进行写操作，不保证线程安全);而synchronized是一种排他(互斥)的机制。 volatile用于禁止指令重排序：可以解决单例双重检查对象初始化代码执行乱序问题。 volatile可以看做是轻量版的synchronized，volatile不保证原子性，但是如果是对一个共享变量进行多个线程的赋值，而没有其他的操作，那么就可以用volatile来代替synchronized，因为赋值本身是有原子性的，而volatile又保证了可见性，所以就可以保证线程安全了。 总结 volatile修饰符适用于以下场景：某个属性被多个线程共享，其中有一个线程修改了此属性，其他线程可以立即得到修改后的值，比如booleanflag;或者作为触发器，实现轻量级同步。 volatile属性的读写操作都是无锁的，它不能替代synchronized，因为它没有提供原子性和互斥性。因为无锁，不需要花费时间在获取锁和释放锁_上，所以说它是低成本的。 volatile只能作用于属性，我们用volatile修饰属性，这样compilers就不会对这个属性做指令重排序。 volatile提供了可见性，任何一个线程对其的修改将立马对其他线程可见，volatile属性不会被线程缓存，始终从主 存中读取。 volatile提供了happens-before保证，对volatile变量v的写入happens-before所有其他线程后续对v的读操作。 volatile可以使得long和double的赋值是原子的。 volatile可以在单例双重检查中实现可见性和禁止指令重排序，从而保证安全性。","categories":[{"name":"Java","slug":"Java","permalink":"https://zsc-cloud.github.io/categories/Java/"},{"name":"JUC","slug":"Java/JUC","permalink":"https://zsc-cloud.github.io/categories/Java/JUC/"}],"tags":[{"name":"JUC","slug":"JUC","permalink":"https://zsc-cloud.github.io/tags/JUC/"},{"name":"并发编程","slug":"并发编程","permalink":"https://zsc-cloud.github.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"AQS辅助类","slug":"AQS辅助类","date":"2021-04-21T07:43:35.000Z","updated":"2021-06-07T01:17:41.864Z","comments":true,"path":"2021/04/20/AQS辅助类/","link":"","permalink":"https://zsc-cloud.github.io/2021/04/20/AQS%E8%BE%85%E5%8A%A9%E7%B1%BB/","excerpt":"","text":"倒计数器 CountDownLatch一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待。 CountDownLatch是一个辅助同步器类，用来作计数使用， 它的作用有点类似于生活中的倒数计数器，先设定一个计数初始值，当计数降到0时，将会触发一些事件，如火箭的倒数计时。 初始计数值在构造CountDownLatch对象时传入，每调用一次 countDown() 方法，计数值就会减1。 线程可以调用CountDownLatch的await方法进入阻塞，当计数值降到0时，所有之前调用await阻塞的线程都会释放。 注意：CountDownLatch的初始计数值一旦降到0，无法重置。如果需要重置，可以考虑使用CyclicBarrier。 12345678910111213141516171819202122232425262728293031/** * @Description: JUC强大的辅助类 之 倒计数器 * 案例：6个同学陆续离开教室后值班同学才可以关门。 * 1、一个线程 关门 * 2、卡断6次 6个同学出口后 一个线程关门 */public class CountDownLatchDemo &#123; public static void main(String[] args) throws Exception &#123; CountDownLatch countDownLatch = new CountDownLatch(6);//6个同学 //值班同学 要关门 for (int i = 1; i &lt;= 6; i++) &#123; new Thread(() -&gt; &#123; try &#123; Thread.sleep(new Random().nextInt(3000)); System.out.println(&quot;第&quot; + Thread.currentThread().getName() + &quot;同学要离开教室&quot;); countDownLatch.countDown();//倒计数 -1 0 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;, String.valueOf(i)).start(); &#125; //等待 6个同学都离开 // 这里new CountDownLatch(6)的参数是几就表示要等待几次 countDownLatch.await(); System.out.println(Thread.currentThread().getName() + &quot;要关门了&quot;); &#125;&#125; 同步屏障CyclicBarrierDemo123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * @Description: * 从字面上的意思可以知道，这个类的中文意思是“循环栅栏”。大概的意思就是一个可循环利用的屏障。 * 该命令只在每个屏障点运行一次。若在所有参与线程之前更新共享状态，此屏障操作很有用 * * 1.CyclicBarrier(int parties, Runnable barrierAction) 创建一个CyclicBarrier实例，parties指定参与相互等待的线程数， * barrierAction一个可选的Runnable命令，该命令只在每个屏障点运行一次，可以在执行后续业务之前共享状态。该操作由最后一个进入屏障点的线程执行。 * * 2.CyclicBarrier(int parties) 创建一个CyclicBarrier实例，parties指定参与相互等待的线程数。 * * 3.await() 该方法被调用时表示当前线程已经到达屏障点，当前线程阻塞进入休眠状态，直到所有线程都到达屏障点，当前线程才会被唤醒。 * * 参考文章：https://www.cnblogs.com/jelly12345/p/12111094.html */public class CyclicBarrierDemo &#123; public static void main(String[] args) throws Exception&#123; //倒计数器 CountDownLatch countDownLatch = new CountDownLatch(3); CyclicBarrier cyclicBarrier = new CyclicBarrier(3,() -&gt; &#123; System.out.println(&quot;恭喜大家一起过关了&quot;); &#125;); //组队打boss过关卡游戏。 for (int i = 1; i &lt;= 3; i++) &#123; new Thread(() -&gt; &#123; try &#123; System.out.println(&quot;第&quot; + Thread.currentThread().getName() + &quot;号选手开始第一关&quot;); Thread.sleep(new Random().nextInt(3)); System.out.println(&quot;第&quot; + Thread.currentThread().getName() + &quot;号选手开始打第一关Boss&quot;); //只能被调用三次 三次过后 唤醒 cyclicBarrier.await();//第i号选手必须在此等待其它选手一起进入下一关口 System.out.println(&quot;第&quot; + Thread.currentThread().getName() + &quot;号选手开始第二关&quot;); Thread.sleep(new Random().nextInt(3)); System.out.println(&quot;第&quot; + Thread.currentThread().getName() + &quot;号选手开始打第二关Boss&quot;); cyclicBarrier.await();//第i号选手必须在此等待其它选手一起进入下一关口 System.out.println(&quot;第&quot; + Thread.currentThread().getName() + &quot;号选手开始第三关&quot;); Thread.sleep(new Random().nextInt(3)); System.out.println(&quot;第&quot; + Thread.currentThread().getName() + &quot;号选手开始第三关打Boss&quot;); //cyclicBarrier.await();//第i号选手必须在此等待其它选手一起进入下一关口 //减一次 countDownLatch.countDown(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;,String.valueOf(i)).start(); &#125; //等待 减到0时 唤醒 countDownLatch.await(); System.out.println(&quot;恭喜大家吃鸡了&quot;); &#125;&#125; CyclicBarrier和CountDownLatch的区别？ CountDownLatch的计数器只能使用一次，而CyclicBarrier的计数器可以使用reset()方法重置，可以使用多次，所以CyclicBarrier能够处理更为复杂的场景； CountDownLatch允许一个或多个线程等待一组事件的产生，而CyclicBarrier用于等待其他线程运行到栅栏位置。 CountDownLatch 是一个线程(或者多个)，等待另外N个线程完成某个事情之后才能执行；CyclicBarrie是N个线程相互等待，任何一个线程完成之前，所有的线程都必须等待。 信号量 Semaphore12345678910111213141516171819202122232425262728293031323334353637383940/** * @Description: * * 信号量 * Semaphore翻译成字面意思为 信号量，Semaphore可以控制同时访问的线程个数。非常适合需求量大，而资源又很紧张的情况。 * 比如给定一个资源数目有限的资源池，假设资源数目为N，每一个线程均可获取一个资源，但是当资源分配完毕时，后来线程需要阻塞等待， * 直到前面已持有资源的线程释放资源之后才能继续。 * * 案例：6辆车抢占3个车位 * 1、6个线程 * 2、3个车位 3个信号量 * 信号量能增加 public void release() 释放 * * 信号量能减少 public void acquire() * */public class SemaphoreDemo &#123; public static void main(String[] args) &#123; Semaphore semaphore = new Semaphore(3);//3个信号量 for (int i = 1; i &lt;= 6; i++) &#123; new Thread(() -&gt; &#123; try &#123; //抢占停车位 semaphore.acquire();//抢不到 阻塞状态 等待 System.out.println(&quot;第&quot; + Thread.currentThread().getName() + &quot;辆车抢到了车位&quot;); TimeUnit.MILLISECONDS.sleep(new Random().nextInt(1500)); System.out.println(&quot;第&quot; + Thread.currentThread().getName() + &quot;辆离开了车位&quot;); semaphore.release();//归还车位 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;,String.valueOf(i)).start(); &#125; &#125; &#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://zsc-cloud.github.io/categories/Java/"},{"name":"JUC","slug":"Java/JUC","permalink":"https://zsc-cloud.github.io/categories/Java/JUC/"}],"tags":[{"name":"JUC","slug":"JUC","permalink":"https://zsc-cloud.github.io/tags/JUC/"},{"name":"并发编程","slug":"并发编程","permalink":"https://zsc-cloud.github.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"SQL优化","slug":"SQL优化","date":"2021-04-19T08:18:16.000Z","updated":"2022-03-26T03:42:17.366Z","comments":true,"path":"2021/04/19/SQL优化/","link":"","permalink":"https://zsc-cloud.github.io/2021/04/19/SQL%E4%BC%98%E5%8C%96/","excerpt":"","text":"简单的SQL优化 对查询优化，应尽量避免全表扫描，首先应考虑在where以及order by涉及到的列上建立索引.只返回有用的字段，不要全部返回(不要用select * from 返回的字段一点要有用，尽量实现覆盖索引，避免回表操作) 应尽量避免在where子句中对字段进行null值判断，否则将导致放弃使用索引而进行全表扫描.（建议创建字段时设置一个默认值，避免null值,比如字符默认为空串，数字默认为0） 应尽量避免在where子句中使用or来连接条件，否则将导致引擎放弃使用而进行全表扫描 1select id from t where num = 10 or num = 20 可以使用union函数查询，也可以这样查询： 123select id from t where num = 10 union allselect id from t where num = 20 in 和not in要小心使用，避免全表扫描 对于连续的数值，能用 between 就不要用 in 了： 12select id from t where num in(1,2,3) 可能造成全表扫描select id from t where num between 1 and 3 匹配索引 避免在where子句中对字段进行表达式操作 应尽量避免在where子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描 索引遵循最左匹配原则，从左到右命中索引，碰到 &gt;,&lt;,like等等运算操作则会放弃索引，查询尽量避免，如果不能避免，一定要放到最后，尽量命中更多的索引 自己的SQL调优过程 数据库调优其实一般情况都是我们的SQL调优，SQL的调优就可以解决大部分问题了(但是这些调优我们应该尽量在开发时就注意到这些问题，在开发阶段避免大部分的问题)，还有一点比较重要的就是SQL执行环节的调优 SQL的执行过程： 客户端 –&gt; 连接器 –&gt; 分析器 –&gt; 优化器 –&gt; 执行器 –&gt; 引擎 –&gt; 查询结果 我们所谓的调优也就是在，执行器执行之前的分析器，优化器阶段完成的，那我们开发工作中怎么去调优的呢？ 一般在开发涉及SQL的业务都会去本地环境跑一遍SQL，用explain去看一下执行计划，看看分析的结果是否符合自己的预期，用没用到相关的索引，然后再去线上环境跑一下看看执行时间（这里只有查询语句，修改语句也无法在线上执行）。 排除缓存干扰因为在MySQL8.0之前我们的数据库是存在缓存这样的情况的，我之前就被坑过，因为存在缓存，我发现我sql怎么执行都是很快，当然第一次其实不快但是我没注意到，以至于上线后因为缓存经常失效，导致rt（Response time）时高时低。 后面就发现了是缓存的问题，我们在执行SQL的时候，记得加上SQL_NO_CACHE 去跑SQL，这样跑出来的时间就是真实的查询时间了。 我说一下为什么缓存会失效，而且是经常失效。 如果我们当前的MySQL版本支持缓存而且我们又开启了缓存，那每次请求的查询语句和结果都会以key-value的形式缓存在内存中的，大家也看到我们的结构图了，一个请求会先去看缓存是否存在，不存在才会走解析器。 缓存失效比较频繁的原因就是，只要我们一对表进行更新，那这个表所有的缓存都会被清空，其实我们很少存在不更新的表，特别是我之前的电商场景，可能静态表可以用到缓存，但是我们都走大数据离线分析，缓存也就没用了。 大家如果是8.0以上的版本就不用担心这个问题，如果是8.0之下的版本，记得排除缓存的干扰。 Explain最开始提到了用执行计划去分析，explain是SQL调优都会回答到的, 因为这基本上是写SQL的必备操作 使用EXPLAIN关键字可以模拟优化器执行SQL查询语句，从而知道MySQL是如何处理你的SQL语句的。分析你的查询语句或是表结构的性能瓶颈。 通过EXPLAIN，我们可以分析出以下结果：(重要) 表的读取顺序 数据读取操作的操作类型 哪些索引可以使用 哪些索引被实际使用 表之间的引用 每张表有多少行被优化器查询 使用方法就是 EXPLAIN +SQL语句 各个字段的含义 id : select查询的序列号，包含一组数字，表示查询中执行select子句或操作表的顺序 id相同，执行顺序由上至下 id不同，如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行 select_type : 用来表示查询的类型，主要是用于区别普通查询、联合查询、子查询等的复杂查询。 SIMPLE 简单的select查询，查询中不包含子查询或者UNION PRIMARY 查询中若包含任何复杂的子部分，最外层查询则被标记为PRIMARY SUBQUERY 在SELECT或WHERE列表中包含了子查询 DERIVED 在FROM列表中包含的子查询被标记为DERIVED（衍生），MySQL会递归执行这些子查询，把结果放在临时表中 UNION 若第二个SELECT出现在UNION之后，则被标记为UNION：若UNION包含在FROM子句的子查询中，外层SELECT将被标记为：DERIVED UNION RESULT 从UNION表获取结果的SELECT table ：指的就是当前执行的表 type：type所显示的是查询使用了哪种类型，type包含的类型包括如下图所示的几种： 从最好到最差依次是： 1system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; all 一般来说，得保证查询至少达到range级别，最好能达到ref。 system : 表只有一行记录（等于系统表），这是const类型的特列，平时不会出现，这个也可以忽略不计 const : 表示通过索引一次就找到了，const用于比较primary key 或者unique索引。因为只匹配一行数据，所以很快。如将主键置于where列表中，MySQL就能将该查询转换为一个常量。(如where id = 1) eq_ref : ** 唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配**。常见于主键或唯一索引扫描 ref : 非唯一性索引扫描，返回匹配某个单独值的所有行，本质上也是一种索引访问，它返回所有匹配某个单独值的行，然而，它可能会找到多个符合条件的行，所以他应该属于查找和扫描的混合体。 **range: ** 只检索给定范围的行，使用一个索引来选择行，key列显示使用了哪个索引，一般就是在你的where语句中出现between、&lt; 、&gt;、in等的查询，这种范围扫描索引比全表扫描要好，因为它只需要开始于索引的某一点，而结束于另一点，不用扫描全部索引。 index : Full Index Scan，Index与All区别为index类型只遍历索引树。这通常比ALL快，因为索引文件通常比数据文件小。（也就是说虽然all和Index都是读全表，但index是从索引中读取的，而all是从硬盘读取的） all : Full Table Scan 将遍历全表以找到匹配的行 possible_keys : 显示可能应用在这张表中的索引，一个或多个。查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询实际使用。 Key:实际使用的索引，如果为NULL，则没有使用索引。（可能原因包括没有建立索引或索引失效） 查询中若使用了覆盖索引（select 后要查询的字段刚好和创建的索引字段完全相同），则该索引仅出现在key列表中 key_len: 表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度，在不损失精确性的情况下，长度越短越好。key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的。 ref:显示索引的那一列被使用了，如果可能的话，最好是一个常数。哪些列或常量被用于查找索引列上的值。 rows: 根据表统计信息及索引选用情况，大致估算出找到所需的记录所需要读取的行数，也就是说，用的越少越好 Extra:包含不适合在其他列中显式但十分重要的额外信息 统计这个统计的行数就是完全对的么？索引一定会走到最优索引么？ 行数只是一个接近的数字，不是完全正确的，索引也不一定就是走最优的，是可能走错的。 我的总行数大概有10W行，但是我去用explain去分析sql的时候，就会发现只得到了9.4W，为啥行数只是个近视值呢？ 因为MySQL中数据的单位都是页，MySQL又采用了采样统计的方法，采样统计的时候，InnoDB默认会选择N个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。 我们数据是一直在变的，所以索引的统计信息也是会变的，会根据一个阈值，重新做统计。 至于MySQL索引可能走错也很好理解，如果走A索引要扫描100行，B索引有只要20行，但是他可能选择走A索引，你可能会想MySQL是不是有病啊，其实不是的。 一般走错都是因为优化器在选择的时候发现，走A索引没有额外的代价，比如走B索引并不能直接拿到我们的值，还需要回到主键索引才可以拿到，多了一次回表的过程，这个也是会被优化器考虑进去的。 他发现走A索引不需要回表，没有额外的开销，所有他选错了。 如果是上面的统计信息错了，那简单，我们用analyze table tablename 就可以重新统计索引信息了，所以在实践中，如果你发现explain的结果预估的rows值跟实际情况差距比较大，可以采用这个方法来处理。 还有一个方法就是force index强制走正确的索引，或者优化SQL，最后实在不行，可以新建索引，或者删掉错误的索引。 减少回表根据自己返回的字段需要，创建合适的联合索引，实现覆盖索引。就可以减少回表了。 回表就是，辅助索引在查询的时候，不会直接查询到对应的数据行，而是查询到该行的主键ID，然后在通过ID进行主键索引查询，查询到对应的数据行。这个通过主键ID在查一次的过程就叫回表。 如果我们要查询三个字段的值，可以根据这三个字段创建一个联合索引，这样就实现了索引覆盖，查询的数据都在索引行中，这样就不用再进行一次回表操作了 PS: 创建联合索引的时候要遵循 最左匹配原则 索引下推已经知道了前缀索引规则，那我就说一个官方帮我们优化的东西，索引下推。 select * from itemcenter where name like &#39;赵%&#39; and hight = 175 and age = 20; 所以这个语句在搜索索引树的时候，只能用 “敖”，找到第一个满足条件的记录ID1，当然，这还不错，总比全表扫描要好。 然后呢？ 当然是判断其他条件是否满足，比如size。 在MySQL 5.6之前，只能从ID1开始一个个回表，到主键索引上找出数据行，再对比字段值。 而MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。 条件字段函数操作日常开发过程中，大家经常对很多字段进行函数操作，如果对日期字段操作，浮点字符操作等等，大家需要注意的是，如果对字段做了函数计算，就用不上索引了，这是MySQL的规定。 对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。 唯一索引普通索引选择难题核心是需要回答到change buffer，那change buffer又是个什么东西呢？ 当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB会将这些更新操作缓存在change buffer中，这样就不需要从磁盘中读入这个数据页了。 在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中与这个页有关的操作，通过这种方式就能保证这个数据逻辑的正确性。 需要说明的是，虽然名字叫作change buffer，实际上它是可以持久化的数据。也就是说，change buffer在内存中有拷贝，也会被写入到磁盘上。 将change buffer中的操作应用到原数据页，得到最新结果的过程称为merge。 除了访问这个数据页会触发merge外，系统有后台线程会定期merge。在数据库正常关闭（shutdown）的过程中，也会执行merge操作。 显然，如果能够将更新操作先记录在change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用buffer pool的，所以这种方式还能够避免占用内存，提高内存利用率 那么，什么条件下可以使用change buffer呢？ 对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。 要判断表中是否存在这个数据，而这必须要将数据页读入内存才能判断，如果都已经读入到内存了，那直接更新内存会更快，就没必要使用change buffer了。 因此，唯一索引的更新就不能使用change buffer，实际上也只有普通索引可以使用。 change buffer用的是buffer pool里的内存，因此不能无限增大，change buffer的大小，可以通过参数innodb_change_buffer_max_size来动态设置，这个参数设置为50的时候，表示change buffer的大小最多只能占用buffer pool的50%。 将数据从磁盘读入内存涉及随机IO的访问，是数据库里面成本最高的操作之一，change buffer因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。 change buffer的使用场景因为merge的时候是真正进行数据更新的时刻，而change buffer的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做merge之前，change buffer记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。 因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时change buffer的使用效果最好，这种业务模型常见的就是账单类、日志类的系统。 反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在change buffer，但之后由于马上要访问这个数据页，会立即触发merge过程。这样随机访问IO的次数不会减少，反而增加了change buffer的维护代价，所以，对于这种业务模式来说，change buffer反而起到了副作用。 在不考虑数据重复的情况下，数据重复情况，必须使用普通索引 总的来说就是，对于写多读少的业务来说，可以采用普通索引（因为这样每次修改的数据都会记录在changeBuffer中，merge次次数很少） 对于写入马上查询的业务来说，使用唯一索引（因为这个如果使用普通索引，会频繁的造成merge,而且需要维护一个changeBuffer） flush脏页刷新机制数据库调优总结：简单的SQL优化：查询时的返回字段优化，where条件优化，null值判断；创建索引：查询频繁以及数据重复较小的字段创建索引；创建的索引失效情况，联合索引重点突出最左匹配原则 自己优化流程： 分析SQL执行流程 用EXPLAIN分析具体某一条SQL执行流程 排查问题时去掉SQL缓存 怎么样优化： 覆盖索引（减少回表） 联合索引（目的就是为了能够覆盖索引，提高效率）（创建联合索引时遵循最左匹配原则）合理安排SQL顺序 单一索引时 根据业务选择唯一索引还是普通索引（根据change buffer 多写少读用普通索引 写后随即读取用唯一索引） 还有一点要注意的是MySQL选择utf-8字符集要选用uft8mb4 索引字段不要做函数操作 MySQL的引擎Innodb引擎 Innodb引擎提供了对数据库ACID事务的支持，并且实现了SQL标准的四种隔离级别。 该引擎还提供了行级锁和外键约束，它的设计目标是处理大容量数据库系统，它本身其实就是基于MySQL后台的完整数据库系统，MySQL运行时Innodb会在内存中建立缓冲池，用于缓冲数据和索引。 当需要使用数据库事务时，该引擎当然是首选。由于锁的粒度更小，写操作不会锁定全表，所以在并发较高时，使用Innodb引擎会提升效率。 但是使用行级锁也不是绝对的，如果在执行一个SQL语句时MySQL不能确定要扫描的范围，InnoDB表同样会锁全表。 MyIASM引擎 它没有提供对数据库事务的支持，也不支持行级锁和外键，因此当INSERT(插入)或UPDATE(更新)数据时即写操作需要锁定整个表，效率便会低一些。 不过和Innodb不同，MyIASM中存储了表的行数，于是SELECT COUNT(*) FROM TABLE时只需要直接读取已经保存好的值而不需要进行全表扫描。如果表的读操作远远多于写操作且不需要数据库事务的支持，那么MyIASM也是很好的选择。 主要区别： MyIASM是非事务安全的，而InnoDB是事务安全的 MyIASM锁的粒度是表级的，而InnoDB支持行级锁 InnoDB支持外键，而MyISAM不支持。对一个包含外键的InnoDB表转为MYISAM会失败 InnoDB是聚集索引，使用B+Tree作为索引结构，数据文件是和（主键）索引绑在一起的（表数据文件本身就是按B+Tree组织的一个索引结构），必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。 MyISAM是非聚集索引，也是使用B+Tree作为索引结构，索引和数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。 MyIASM表保存成文件形式，跨平台使用更加方便 InnoDB表必须有唯一索引（如主键）（用户没有指定的话会自己找/生产一个隐藏列Row_id来充当默认主键），而Myisam可以没有 如何选择 是否要支持事务，如果要请选择innodb，如果不需要可以考虑MyISAM； 如果表中绝大多数都只是读查询，可以考虑MyISAM，如果既有读也有写，请使用InnoDB。 系统奔溃后，MyISAM恢复起来更困难，能否接受； MySQL5.5版本开始Innodb已经成为Mysql的默认引擎(之前是MyISAM)，说明其优势是有目共睹的，如果你不知道用什么，那就用InnoDB，至少不会差。 InnoDB为什么推荐使用自增ID作为主键？ 答：自增ID可以保证每次插入时B+索引是从右边扩展的，可以避免B+树和频繁合并和分裂（对比使用UUID）。如果使用字符串主键和随机主键，会使得数据随机插入，效率比较差。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://zsc-cloud.github.io/categories/MySQL/"},{"name":"SQL优化","slug":"MySQL/SQL优化","permalink":"https://zsc-cloud.github.io/categories/MySQL/SQL%E4%BC%98%E5%8C%96/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://zsc-cloud.github.io/tags/MySQL/"},{"name":"数据库","slug":"数据库","permalink":"https://zsc-cloud.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"线程池","slug":"线程池","date":"2021-04-16T07:34:23.000Z","updated":"2022-03-26T03:42:17.435Z","comments":true,"path":"2021/04/15/线程池/","link":"","permalink":"https://zsc-cloud.github.io/2021/04/15/%E7%BA%BF%E7%A8%8B%E6%B1%A0/","excerpt":"","text":"线程池的优势总体来说，线程池有如下的优势： （1）降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 （2）提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。 （3）提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 线程池的使用四种构造方法线程池的真正实现类是 ThreadPoolExecutor，其构造方法有如下4种： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler);&#125; public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, defaultHandler);&#125; public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), handler);&#125; public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; 参数corePoolSize（必需）：核心线程数。默认情况下，核心线程会一直存活，但是当将 allowCoreThreadTimeout 设置为 true 时，核心线程也会超时回收。maximumPoolSize（必需）：线程池所能容纳的最大线程数。当活跃线程数达到该数值后，后续的新任务将会阻塞。keepAliveTime（必需）：线程闲置超时时长。如果超过该时长，非核心线程就会被回收。如果将 allowCoreThreadTimeout 设置为 true 时，核心线程也会超时回收。unit（必需）：指定 keepAliveTime 参数的时间单位。常用的有：TimeUnit.MILLISECONDS（毫秒）、TimeUnit.SECONDS（秒）、TimeUnit.MINUTES（分）。workQueue（必需）：任务队列。通过线程池的 execute() 方法提交的 Runnable 对象将存储在该参数中。其采用阻塞队列实现。threadFactory（可选）：线程工厂。用于指定为线程池创建新线程的方式。handler（可选）：拒绝策略。当达到最大线程数时需要执行的饱和策略。线程池的使用流程如下： 线程池的工作原理下面来描述一下线程池工作的原理，同时对上面的参数有一个更深的了解。其工作原理流程图如下： 通过上图，相信大家已经对所有参数有个了解了。下面再对任务队列、线程工厂和拒绝策略做更多的说明。 线程池的参数任务队列（workQueue）任务队列是基于阻塞队列实现的，即采用生产者消费者模式，在 Java 中需要实现 BlockingQueue 接口。但 Java 已经为我们提供了 7 种阻塞队列的实现： ArrayBlockingQueue：一个由数组结构组成的有界阻塞队列（数组结构可配合指针实现一个环形队列）。 LinkedBlockingQueue： 一个由链表结构组成的有界阻塞队列，在未指明容量时，容量默认为 Integer.MAX_VALUE。 PriorityBlockingQueue： 一个支持优先级排序的无界阻塞队列，对元素没有要求，可以实现 Comparable 接口也可以提供 Comparator 来对队列中的元素进行比较。跟时间没有任何关系，仅仅是按照优先级取任务。 DelayQueue：类似于PriorityBlockingQueue，是二叉堆实现的无界优先级阻塞队列。要求元素都实现 Delayed 接口，通过执行时延从队列中提取任务，时间没到任务取不出来。 SynchronousQueue： 一个不存储元素的阻塞队列，消费者线程调用 take() 方法的时候就会发生阻塞，直到有一个生产者线程生产了一个元素，消费者线程就可以拿到这个元素并返回；生产者线程调用 put() 方法的时候也会发生阻塞，直到有一个消费者线程消费了一个元素，生产者才会返回。 LinkedBlockingDeque： 使用双向队列实现的有界双端阻塞队列。双端意味着可以像普通队列一样 FIFO（先进先出），也可以像栈一样 FILO（先进后出）。 LinkedTransferQueue： 它是ConcurrentLinkedQueue、LinkedBlockingQueue 和 SynchronousQueue 的结合体，但是把它用在 ThreadPoolExecutor 中，和 LinkedBlockingQueue 行为一致，但是是无界的阻塞队列。注意有界队列和无界队列的区别：如果使用有界队列，当队列饱和时并超过最大线程数时就会执行拒绝策略；而如果使用无界队列，因为任务队列永远都可以添加任务，所以设置 maximumPoolSize 没有任何意义。 线程工厂（threadFactory）线程工厂指定创建线程的方式，需要实现 ThreadFactory 接口，并实现 newThread(Runnable r) 方法。该参数可以不用指定，Executors 框架已经为我们实现了一个默认的线程工厂： 1234567891011121314151617181920212223242526272829/** * The default thread factory. */private static class DefaultThreadFactory implements ThreadFactory &#123; private static final AtomicInteger poolNumber = new AtomicInteger(1); private final ThreadGroup group; private final AtomicInteger threadNumber = new AtomicInteger(1); private final String namePrefix; DefaultThreadFactory() &#123; SecurityManager s = System.getSecurityManager(); group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); namePrefix = &quot;pool-&quot; + poolNumber.getAndIncrement() + &quot;-thread-&quot;; &#125; public Thread newThread(Runnable r) &#123; Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0); if (t.isDaemon()) t.setDaemon(false); if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t; &#125;&#125; 拒绝策略（handler）当线程池的线程数达到最大线程数时，需要执行拒绝策略。拒绝策略需要实现 RejectedExecutionHandler 接口，并实现 rejectedExecution(Runnable r, ThreadPoolExecutor executor) 方法。不过 Executors 框架已经为我们实现了 4 种拒绝策略： AbortPolicy（默认）：丢弃任务并抛出 RejectedExecutionException 异常。 CallerRunsPolicy：由调用线程处理该任务。 DiscardPolicy：丢弃任务，但是不抛出异常。可以配合这种模式进行自定义的处理方式。 DiscardOldestPolicy：丢弃队列最早的未处理任务，然后重新尝试执行任务。 功能线程池（不推荐使用）嫌上面使用线程池的方法太麻烦？其实Executors已经为我们封装好了 4 种常见的功能线程池，如下： 定长线程池（FixedThreadPool） 定时线程池（ScheduledThreadPool ） 可缓存线程池（CachedThreadPool） 单线程化线程池（SingleThreadExecutor） 定长线程池（FixedThreadPool）创建方法的源码： 1234567891011public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125;public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory);&#125; 特点：只有核心线程，线程数量固定，执行完立即回收，任务队列为链表结构的有界队列。应用场景：控制线程最大并发数。使用示例： 12345678910// 1. 创建定长线程池对象 &amp; 设置线程池线程数量固定为3ExecutorService fixedThreadPool = Executors.newFixedThreadPool(3);// 2. 创建好Runnable类线程对象 &amp; 需执行的任务Runnable task =new Runnable()&#123; public void run() &#123; System.out.println(&quot;执行任务啦&quot;); &#125;&#125;;// 3. 向线程池提交任务fixedThreadPool.execute(task); 定时线程池（ScheduledThreadPool ）创建方法的源码： 123456789101112131415161718192021private static final long DEFAULT_KEEPALIVE_MILLIS = 10L;public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize);&#125;public ScheduledThreadPoolExecutor(int corePoolSize) &#123; super(corePoolSize, Integer.MAX_VALUE, DEFAULT_KEEPALIVE_MILLIS, MILLISECONDS, new DelayedWorkQueue());&#125;public static ScheduledExecutorService newScheduledThreadPool( int corePoolSize, ThreadFactory threadFactory) &#123; return new ScheduledThreadPoolExecutor(corePoolSize, threadFactory);&#125;public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory) &#123; super(corePoolSize, Integer.MAX_VALUE, DEFAULT_KEEPALIVE_MILLIS, MILLISECONDS, new DelayedWorkQueue(), threadFactory);&#125; 特点：核心线程数量固定，非核心线程数量无限，执行完闲置 10ms 后回收，任务队列为延时阻塞队列。应用场景：执行定时或周期性的任务。使用示例： 1234567891011// 1. 创建 定时线程池对象 &amp; 设置线程池线程数量固定为5ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(5);// 2. 创建好Runnable类线程对象 &amp; 需执行的任务Runnable task =new Runnable()&#123; public void run() &#123; System.out.println(&quot;执行任务啦&quot;); &#125;&#125;;// 3. 向线程池提交任务scheduledThreadPool.schedule(task, 1, TimeUnit.SECONDS); // 延迟1s后执行任务scheduledThreadPool.scheduleAtFixedRate(task,10,1000,TimeUnit.MILLISECONDS);// 延迟10ms后、每隔1000ms执行任务 可缓存线程池（CachedThreadPool）创建方法的源码： 1234567891011public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125;public static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;(), threadFactory);&#125; 特点：无核心线程，非核心线程数量无限，执行完闲置 60s 后回收，任务队列为不存储元素的阻塞队列。应用场景：执行大量、耗时少的任务。使用示例： 12345678910// 1. 创建可缓存线程池对象ExecutorService cachedThreadPool = Executors.newCachedThreadPool();// 2. 创建好Runnable类线程对象 &amp; 需执行的任务Runnable task =new Runnable()&#123; public void run() &#123; System.out.println(&quot;执行任务啦&quot;); &#125;&#125;;// 3. 向线程池提交任务cachedThreadPool.execute(task); 单线程化线程池（SingleThreadExecutor）创建方法的源码： 12345678910111213public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125;public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory));&#125; 特点：只有 1 个核心线程，无非核心线程，执行完立即回收，任务队列为链表结构的有界队列。应用场景：不适合并发但可能引起 IO 阻塞性及影响 UI 线程响应的操作，如数据库操作、文件操作等。 使用示例： 12345678910// 1. 创建单线程化线程池ExecutorService singleThreadExecutor = Executors.newSingleThreadExecutor();// 2. 创建好Runnable类线程对象 &amp; 需执行的任务Runnable task =new Runnable()&#123; public void run() &#123; System.out.println(&quot;执行任务啦&quot;); &#125;&#125;;// 3. 向线程池提交任务singleThreadExecutor.execute(task); 对比 总结Executors 的 4 个功能线程池虽然方便，但现在已经不建议使用了，而是建议直接通过使用 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。 其实 Executors 的 4 个功能线程有如下弊端： FixedThreadPool 和 SingleThreadExecutor：主要问题是堆积的请求处理队列均采用 LinkedBlockingQueue，可能会耗费非常大的内存，甚至 OOM。CachedThreadPool 和 ScheduledThreadPool：主要问题是线程数最大数是 Integer.MAX_VALUE，可能会创建数量非常多的线程，甚至 OOM。 线程数量如何设置cpu密集型的任务 一般设置 线程数 = 核心数N + 1 io密集型的任务 一般设置 线程数 = 核心数N*2 + 1 12//获取当前机器的核数public static final int cpuNum = Runtime.getRuntime().availableProcessors(); 封装线程池123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123/** * @author zsc * @date 2020/7/31 */import java.util.LinkedList;import java.util.Queue;import java.util.concurrent.*;/** * 线程池管理(线程统一调度管理) */public final class ThreadPoolManager &#123; private static ThreadPoolManager sThreadPoolManagerManager = new ThreadPoolManager(); // 线程池维护线程的最少数量 private static final int SIZE_CORE_POOL = 3; // 线程池维护线程的最大数量 private static final int SIZE_MAX_POOL = 10; // 线程池维护线程所允许的空闲时间 private static final int TIME_KEEP_ALIVE = 10 * 1000; // 线程池所使用的缓冲队列大小 private static final int SIZE_WORK_QUEUE = 500; // 任务调度周期 private static final int PERIOD_TASK_QOS = 1000; /* * 线程池单例创建方法 */ public static ThreadPoolManager getInstance() &#123; return sThreadPoolManagerManager; &#125; // 任务缓冲队列 private final Queue&lt;Runnable&gt; mTaskQueue = new LinkedList&lt;Runnable&gt;(); /* * 线程池超出界线时将任务加入缓冲队列 */ private final RejectedExecutionHandler mHandler = new RejectedExecutionHandler() &#123; @Override public void rejectedExecution(Runnable task, ThreadPoolExecutor executor) &#123; mTaskQueue.offer(task); &#125; &#125;; /* * 将缓冲队列中的任务重新加载到线程池 */ private final Runnable mAccessBufferThread = new Runnable() &#123; @Override public void run() &#123; if (hasMoreAcquire()) &#123; mThreadPool.execute(mTaskQueue.poll()); &#125; &#125; &#125;; /* * 创建一个调度线程池 */ private final ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(1); /* * 通过调度线程周期性的执行缓冲队列中任务 */ protected final ScheduledFuture&lt;?&gt; mTaskHandler = scheduler.scheduleAtFixedRate(mAccessBufferThread, 0, PERIOD_TASK_QOS, TimeUnit.MILLISECONDS); /* * 线程池 */ private final ThreadPoolExecutor mThreadPool = new ThreadPoolExecutor(SIZE_CORE_POOL, SIZE_MAX_POOL, TIME_KEEP_ALIVE, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(SIZE_WORK_QUEUE), mHandler); /* * 将构造方法访问修饰符设为私有，禁止任意实例化。 */ private ThreadPoolManager() &#123; &#125; public void prepare() &#123; if (mThreadPool.isShutdown() &amp;&amp; !mThreadPool.prestartCoreThread()) &#123; @SuppressWarnings(&quot;unused&quot;) int startThread = mThreadPool.prestartAllCoreThreads(); &#125; &#125; /* * 消息队列检查方法 */ private boolean hasMoreAcquire() &#123; return !mTaskQueue.isEmpty(); &#125; /* * 向线程池中添加任务方法 */ public void executeTask(Runnable task) &#123; if (task != null) &#123; mThreadPool.execute(task); &#125; &#125; protected boolean isTaskEnd() &#123; if (mThreadPool.getActiveCount() == 0) &#123; return true; &#125; else &#123; return false; &#125; &#125; public void shutdown() &#123; mTaskQueue.clear(); mThreadPool.shutdown(); &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://zsc-cloud.github.io/categories/Java/"},{"name":"JUC","slug":"Java/JUC","permalink":"https://zsc-cloud.github.io/categories/Java/JUC/"}],"tags":[{"name":"JUC","slug":"JUC","permalink":"https://zsc-cloud.github.io/tags/JUC/"},{"name":"并发编程","slug":"并发编程","permalink":"https://zsc-cloud.github.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"线程","slug":"线程","permalink":"https://zsc-cloud.github.io/tags/%E7%BA%BF%E7%A8%8B/"}]},{"title":"Synchronized","slug":"Synchronized","date":"2021-04-16T05:47:39.000Z","updated":"2022-03-26T03:42:17.239Z","comments":true,"path":"2021/04/15/Synchronized/","link":"","permalink":"https://zsc-cloud.github.io/2021/04/15/Synchronized/","excerpt":"","text":"前言：造成线程安全问题的主要诱因有两点: 一是存在共享数据(也称临界资源)，二是存在多条线程共同操作共享数据。因此为了解决这个问题，我们可能需要这样一个方案，当存在多个线程操作共享数据时，需要保证同一时刻有且只有一个线程在操作共享数据，其他线程必须等到该线程处理完数据后再进行，这种方式有个高尚的名称叫互斥锁，即能达到互斥访问目的的锁，也就是说当一个共享数据被当前正在访问的线程加上互斥锁后，在同一个时刻，其他线程只能处于等待的状态，直到当前线程处理完毕释放该锁。在 Java 中，关键字 synchronized可以保证在同一个时刻，只有一个线程可以执行某个方法或者某个代码块(主要是对方法或者代码块中存在共享数据的操作)，同时我们还应该注意到synchronized另外一个重要的作用，synchronized可保证一个线程的变化(主要是共享数据的变化)被其他线程所看到（保证可见性，完全可以替代Volatile功能），这点确实也是很重要的。 synchronized的三种应用方式synchronized关键字最主要有以下3种应用方式 修饰实例方法，作用于当前实例加锁，进入同步代码前要获得当前实例的锁 修饰静态方法，作用于当前类对象加锁，进入同步代码前要获得当前类对象的锁 修饰代码块，指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。 1. synchronized作用于实例方法所谓的实例对象锁就是用synchronized修饰实例对象中的实例方法，注意是实例方法不包括静态方法，如下 123456789101112131415161718192021222324252627282930313233343536373839404142/** * @author zsc * @date 2021/5/18 * synchronized作用于实例方法 */public class AccountingSync implements Runnable&#123; //共享资源(临界资源) static int i=0; /** * synchronized 修饰实例方法 */ public synchronized void increase()&#123; i++; &#125; /** * 这里没有synchronized 结果很有可能就小于2000000 i++操作并不具备原子性 */ @Override public void run() &#123; for(int j=0;j&lt;1000000;j++)&#123; increase(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; /** * 锁的是当前实例，也就是AccountingSync的一个实例instance * instance实例的下的所有synchronized修饰的实例方法 * 若此时该实例还有一个实例方式 synchronized test()，线程访问test,也要等待increase方法释放掉锁才可以 */ AccountingSync instance=new AccountingSync(); Thread t1=new Thread(instance); Thread t2=new Thread(instance); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(i); &#125;&#125; 上述代码中，我们开启两个线程操作同一个共享资源即变量i，由于i++;操作并不具备原子性，该操作是先读取值，然后写回一个新值，相当于原来的值加上1，分两步完成 如果第二个线程在第一个线程读取旧值和写回新值期间读取i的域值，那么第二个线程就会与第一个线程一起看到同一个值，并执行相同值的加1操作，这也就造成了线程安全失败，因此对于increase方法必须使用synchronized修饰，以便保证线程安全。 此时我们应该注意到synchronized修饰的是实例方法increase，在这样的情况下，当前线程的锁便是实例对象instance，注意Java中的线程同步锁可以是任意对象。从代码执行结果来看确实是正确的，倘若我们没有使用synchronized关键字，其最终输出结果就很可能小于2000000，这便是synchronized关键字的作用。 这里我们还需要意识到，当一个线程正在访问一个对象的 synchronized 实例方法，那么其他线程不能访问该对象的其他 synchronized 方法，毕竟一个对象只有一把锁。 当一个线程获取了该对象的锁之后，其他线程无法获取该对象的锁，所以无法访问该对象的其他synchronized实例方法，但是其他线程还是可以访问该实例对象的其他非synchronized方法 当然如果是一个线程 A 需要访问实例对象 obj1 的 synchronized 方法 f1(当前对象锁是obj1)，另一个线程 B 需要访问实例对象 obj2 的 synchronized 方法 f2(当前对象锁是obj2)，这样是允许的，因为两个实例对象锁并不同相同，此时如果两个线程操作数据并非共享的，线程安全是有保障的，遗憾的是如果两个线程操作的是共享数据，那么线程安全就有可能无法保证了，如下代码将演示出该现象 123456789101112131415161718192021222324252627282930313233343536373839/** * @author zsc * @date 2021/5/18 * 创建两个实例，t1和t2都会进入各自的对象锁 */public class AccountingSyncBad implements Runnable&#123; static int i=0; public synchronized void increase()&#123; i++; &#125; @Override public void run() &#123; for(int j=0;j&lt;1000000;j++)&#123; increase(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; //new新实例 Thread t1=new Thread(new AccountingSyncBad()); //new新实例 Thread t2=new Thread(new AccountingSyncBad()); t1.start(); t2.start(); //join含义:当前线程A等待thread线程终止之后才能从thread.join()返回 t1.join(); t2.join(); System.out.println(i); &#125; /** * 上述代码与前面不同的是我们同时创建了两个新实例AccountingSyncBad， * 然后启动两个不同的线程对共享变量i进行操作，但很遗憾操作结果是1452317而不是期望结果2000000， * 因为上述代码犯了严重的错误，虽然我们使用synchronized修饰了increase方法，但却new了两个不同的实例对象， * 这也就意味着存在着两个不同的实例对象锁，因此t1和t2都会进入各自的对象锁，也就是说t1和t2线程使用的是不同的锁， * 因此线程安全是无法保证的。解决这种困境的的方式是将synchronized作用于静态的increase方法，这样的话，对象锁就当前类对象， * 由于无论创建多少个实例对象，但对于的类对象拥有只有一个，所有在这样的情况下对象锁就是唯一的。 * ———————————————— */&#125; 2. synchronized作用于静态方法当synchronized作用于静态方法时，其锁就是当前类的class对象锁。由于静态成员不专属于任何一个实例对象，是类成员，因此通过class对象锁可以控制静态 成员的并发操作。需要注意的是如果一个线程A调用一个实例对象的非static synchronized方法，而线程B需要调用这个实例对象所属类的静态 synchronized方法，是允许的，不会发生互斥现象，因为访问静态 synchronized 方法占用的锁是当前类的class对象，而访问非静态 synchronized 方法占用的锁是当前实例对象锁，看如下代码 123456789101112131415161718192021222324252627282930313233343536373839404142/** * @author zsc * @date 2021/5/18 * synchronized作用于静态方法 */public class AccountingSyncClass implements Runnable&#123; static int i=0; /** * 作用于静态方法,锁是当前class对象,也就是 * AccountingSyncClass类对应的class对象 */ public static synchronized void increase()&#123; i++; &#125; /** * 非静态,访问时锁不一样不会发生互斥 */ public synchronized void increase4Obj()&#123; i++; &#125; @Override public void run() &#123; for(int j=0;j&lt;1000000;j++)&#123; increase(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; //new新实例 Thread t1=new Thread(new AccountingSyncClass()); //new新实例 Thread t2=new Thread(new AccountingSyncClass()); //启动线程 t1.start();t2.start(); t1.join();t2.join(); System.out.println(i); &#125;&#125; 由于synchronized关键字修饰的是静态increase方法，与修饰实例方法不同的是，其锁对象是当前类的class对象。注意代码中的increase4Obj方法是实例方法，其对象锁是当前实例对象，如果别的线程调用该方法，将不会产生互斥现象，毕竟锁对象不同，但我们应该意识到这种情况下可能会发现线程安全问题(操作了共享静态变量i)。 3. synchronized同步代码块除了使用关键字修饰实例方法和静态方法外，还可以使用同步代码块，在某些情况下，我们编写的方法体可能比较大，同时存在一些比较耗时的操作，而需要同步的代码又只有一小部分，如果直接对整个方法进行同步操作，可能会得不偿失，此时我们可以使用同步代码块的方式对需要同步的代码进行包裹，这样就无需对整个方法进行同步操作了，同步代码块的使用示例如下： 123456789101112131415161718192021222324252627282930313233/** * @author zsc * @date 2021/5/18 * synchronized同步代码块 */public class AccountingSyncBody implements Runnable&#123; static int i=0; @Override public void run() &#123; // 用类的class对象表示是class对象锁，锁class synchronized(AccountingSyncBody.class)&#123; for(int j=0;j&lt;1000000;j++)&#123; i++; &#125; &#125; // 这里用this代表当前实例对象锁// synchronized(this)&#123;// for(int j=0;j&lt;1000000;j++)&#123;// i++;// &#125;// &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; AccountingSyncBody instance=new AccountingSyncBody(); AccountingSyncBody instance2=new AccountingSyncBody(); Thread t1=new Thread(instance); Thread t2=new Thread(instance2); t1.start();t2.start(); t1.join();t2.join(); System.out.println(i); &#125;&#125; 从代码看出，将synchronized作用于一个给定的实例对象instance，即当前实例对象就是锁对象，每次当线程进入synchronized包裹的代码块时就会要求当前线程持有instance实例对象锁，如果当前有其他线程正持有该对象锁，那么新到的线程就必须等待，这样也就保证了每次只有一个线程执行i++;操作。当然除了instance作为对象外，我们还可以使用this对象(代表当前实例)或者当前类的class对象作为锁 总结： synchronized有三种实现方式，分别为锁实例方法（非static方法），锁静态方法，锁代码块 锁实例方法的时候，JVM会给该实例方法的实例对象加锁，有且只有一个线程可以进入该实例方法，其他线程必须要等待进入的线程执行完代码释放锁才能进入，其他线程也不能进入该实例对象的其他synchronized修饰的实例方法。因为锁是加给该实例对象的。但是同一个线程允许可重入操作。加锁的方式为在对象头通过monitor对象管理实现的，下面会有关于可重入操作和加锁的具体解释 锁静态方法的时候，JVM会给该静态方法的类对象加锁，也就是无论该Class创建多少实例，都会互斥。要注意的是该类的synchronized修饰的静态方法被锁住的时候，其他线程是可以访问该类synchronized修饰的非static方法的。因为static方法加锁加Class对象上，而非static方法加锁在实例上，两者互不干扰 锁代码块的时候，可以指定加锁的类型，synchronized(XXX.class)表示给该代码块加上一个类对象锁。synchronized(this)表示给该代码块加上一个实例对象锁。 Synchronized底层语义原理JVM中的同步(Synchronization)基于Monitor对象实现， 无论是显式同步(有明确的 monitorenter 和 monitorexit 指令,即同步代码块)还是隐式同步都是如此。 在 Java 语言中，同步用的最多的地方可能是被 synchronized 修饰的同步方法。同步方法 并不是由 monitorenter 和 monitorexit 指令来实现同步的，而是由方法调用指令读取运行时常量池中方法的 ACC_SYNCHRONIZED 标志来隐式实现的，关于这点，稍后详细分析。下面先来了解一个概念Java对象头，这对深入理解synchronized实现原理非常关键。 理解Java对象头与Monitor在 JVM 中，对象在内存中分为三块区域： 对象头 （这个是重点）它实现synchronized的锁对象的基础，一般而言，synchronized使用的锁对象是存储在Java对象头里的，jvm中采用2个字来存储对象头(如果对象是数组则会分配3个字，多出来的1个字记录的是数组长度)，其主要结构是由Mark Word 和 Class Metadata Address （也可以说Klass Point，意思一样，都为类型指针）组成 这个字的本意的word, C++中的概念。JVM是C++开发的 Mark Word（标记字段）：默认存储对象的HashCode，分代年龄和锁标志位信息。它会根据对象的状态复用自己的存储空间，也就是说在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。 Klass Point（类型指针）：对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。 实例数据 这部分主要是存放类的数据信息，父类的信息。如果是数组的实例部分还包括数组的长度，这部分内存按4字节对齐。 填充数据 由于虚拟机要求对象起始地址必须是8字节的整数倍，填充数据不是必须存在的，仅仅是为了字节对齐。 ps：不知道大家有没有被问过一个空对象占多少个字节？就是8个字节，是因为对齐填充的关系哈，不到8个字节对其填充会帮我们自动补齐。 重量级锁也就是通常说synchronized的对象锁，其中指针指向的是monitor对象（也称为管程或监视器锁）的起始地址。每个对象都存在着一个 monitor 与之关联，对象与其 monitor 之间的关系有存在多种实现方式，如monitor可以与对象一起创建销毁或当线程试图获取对象锁时自动生成，但当一个 monitor 被某个线程持有后，它便处于锁定状态。在Java虚拟机(HotSpot)中，monitor是由ObjectMonitor实现的，其主要数据结构如下（位于HotSpot虚拟机源码ObjectMonitor.hpp文件，C++实现的） 123456789101112131415161718ObjectMonitor() &#123; _header = NULL; _count = 0; //记录个数 _waiters = 0, _recursions = 0; _object = NULL; _owner = NULL; _WaitSet = NULL; //处于wait状态的线程，会被加入到_WaitSet _WaitSetLock = 0 ; _Responsible = NULL ; _succ = NULL ; _cxq = NULL ; FreeNext = NULL ; _EntryList = NULL ; //处于等待锁block状态的线程，会被加入到该列表 _SpinFreq = 0 ; _SpinClock = 0 ; OwnerIsThread = 0 ; &#125; ObjectMonitor中有两个队列，**_WaitSet （待唤醒的线程）和 _EntryList（也就是等待的线程）**，用来保存ObjectWaiter对象列表( 每个等待锁的线程都会被封装成ObjectWaiter对象)，_owner指向持有ObjectMonitor对象的线程， 当多个线程同时访问一段同步代码时，首先会进入 _EntryList 集合， 当线程获取到对象的monitor 后进入 _Owner 区域并把monitor中的owner变量设置为当前线程同时monitor中的计数器count加1 若线程调用 wait() 方法，将释放当前持有的monitor，owner变量恢复为null，count自减1， 同时该线程进入 WaitSet集合中等待被唤醒。 若当前线程执行完毕也将释放monitor(锁)并复位变量的值，以便其他线程进入获取monitor(锁) 由此看来，monitor对象存在于每个Java对象的对象头中(存储的指针的指向)，synchronized锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因，同时也是notify/notifyAll/wait等方法存在于顶级对象Object中的原因 synchronized代码块底层原理现在我们重新定义一个synchronized修饰的同步代码块，在代码块中操作共享变量i，如下 123456789public class SyncCodeBlock &#123; public int i; public void syncTask()&#123; //同步代码库 synchronized (this)&#123; i++; &#125; &#125;&#125; 编译上述代码并使用javap反编译后得到字节码如下(这里我们省略一部分没有必要的信息)： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849 Last modified 2017-6-2; size 426 bytes MD5 checksum c80bc322c87b312de760942820b4fed5 Compiled from &quot;SyncCodeBlock.java&quot;public class com.zejian.concurrencys.SyncCodeBlock minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPERConstant pool: //........省略常量池中数据 //构造函数 public com.zejian.concurrencys.SyncCodeBlock(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return LineNumberTable: line 7: 0 //===========主要看看syncTask方法实现================ public void syncTask(); descriptor: ()V flags: ACC_PUBLIC Code: stack=3, locals=3, args_size=1 0: aload_0 1: dup 2: astore_1 3: monitorenter //注意此处，进入同步方法 4: aload_0 5: dup 6: getfield #2 // Field i:I 9: iconst_1 10: iadd 11: putfield #2 // Field i:I 14: aload_1 15: monitorexit //注意此处，退出同步方法 16: goto 24 19: astore_2 20: aload_1 21: monitorexit //注意此处，退出同步方法 22: aload_2 23: athrow 24: return Exception table: //略其他字节码.......&#125;SourceFile: &quot;SyncCodeBlock.java&quot; 主要看的字节码代码： 1234563: monitorenter //进入同步方法//..........省略其他 15: monitorexit //退出同步方法16: goto 24//省略其他.......21: monitorexit //退出同步方法 显式同步的流程 从字节码中可知同步语句块的实现使用的是monitorenter 和 monitorexit 指令，其中monitorenter指令指向同步代码块的开始位置，monitorexit指令则指明同步代码块的结束位置 当执行monitorenter指令时，当前线程将试图获取 objectref(即对象锁) 所对应的 monitor 的持有权，当 objectref 的 monitor 的进入计数器为 0，那线程可以成功取得 monitor，并将计数器值设置为 1，取锁成功。 如果当前线程已经拥有 objectref 的 monitor 的持有权，那它可以重入这个 monitor (关于重入性稍后会分析)，重入时计数器的值也会加 1。 倘若其他线程已经拥有 objectref 的 monitor 的所有权，那当前线程将被阻塞，直到正在执行线程执行完毕，即monitorexit指令被执行，执行线程将释放 monitor(锁)并设置计数器值为0 ，其他线程将有机会持有 monitor 。 值得注意的是编译器将会确保无论方法通过何种方式完成，方法中调用过的每条 monitorenter 指令都有执行其对应 monitorexit 指令，而无论这个方法是正常结束还是异常结束。 为了保证在方法异常完成时 monitorenter 和 monitorexit 指令依然可以正确配对执行，编译器会自动产生一个异常处理器，这个异常处理器声明可处理所有的异常，它的目的就是用来执行 monitorexit 指令。从字节码中也可以看出多了一个monitorexit指令，它就是异常结束时被执行的释放monitor 的指令。 synchronized方法底层原理1234567public class SyncMethod &#123; public int i; //共享变量i public synchronized void syncTask()&#123; i++; &#125;&#125; 反编译之后的字节码： 1234567891011121314151617181920212223242526272829 Last modified 2017-6-2; size 308 bytes MD5 checksum f34075a8c059ea65e4cc2fa610e0cd94 Compiled from &quot;SyncMethod.java&quot;public class com.zejian.concurrencys.SyncMethod minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPERConstant pool; //省略没必要的字节码 //==================syncTask方法====================== public synchronized void syncTask(); descriptor: ()V //方法标识ACC_PUBLIC代表public修饰，ACC_SYNCHRONIZED指明该方法为同步方法 flags: ACC_PUBLIC, ACC_SYNCHRONIZED Code: stack=3, locals=1, args_size=1 0: aload_0 1: dup 2: getfield #2 // Field i:I 5: iconst_1 6: iadd 7: putfield #2 // Field i:I 10: return LineNumberTable: line 12: 0 line 13: 10&#125;SourceFile: &quot;SyncMethod.java&quot; 隐式同步 方法级的同步是隐式，即无需通过字节码指令来控制的，它实现在方法调用和返回操作之中。JVM可以从方法常量池中的方法表结构(method_info Structure) 中的 ACC_SYNCHRONIZED 访问标志区分一个方法是否同步方法。这便是synchronized锁在同步代码块和同步方法上实现的基本原理 当方法调用时，调用指令将会 检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先持有monitor（虚拟机规范中用的是管程一词）， 然后再执行方法，最后再方法完成(无论是正常完成还是非正常完成)时释放monitor。 在方法执行期间，执行线程持有了monitor，其他任何线程都无法再获得同一个monitor。 如果一个同步方法执行期间抛 出了异常，并且在方法内部无法处理此异常，那这个同步方法所持有的monitor将在异常抛到同步方法之外时自动释放 ACC_SYNCHRONIZED会去隐式调用刚才的两个指令：monitorenter和monitorexit。 所以归根究底，还是monitor对象的争夺。 同时我们还必须注意到的是在Java早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的Mutex Lock来实现的，而操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的synchronized效率低的原因。庆幸的是在Java 6之后Java官方对从JVM层面对synchronized较大优化，所以现在的synchronized锁效率也优化得很不错了，Java 6之后，为了减少获得锁和释放锁所带来的性能消耗，引入了轻量级锁和偏向锁 Java虚拟机对synchronized的优化锁的状态总共有四种，无锁状态、偏向锁、轻量级锁和重量级锁。随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级的重量级锁，但是锁的升级是单向的，也就是说只能从低到高升级，不会出现锁的降级，关于重量级锁，前面我们已详细分析过，下面我们将介绍偏向锁和轻量级锁以及JVM的其他优化手段 偏向锁偏向锁是Java 6之后加入的新锁，它是一种针对加锁操作的优化手段，经过研究发现，在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，因此为了减少同一线程获取锁(会涉及到一些CAS操作,耗时)的代价而引入偏向锁。偏向锁的核心思想是，如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word 的结构也变为偏向锁结构，当这个线程再次请求锁时，无需再做任何同步操作，即获取锁的过程，这样就省去了大量有关锁申请的操作，从而也就提供程序的性能。所以，对于没有锁竞争的场合，偏向锁有很好的优化效果，毕竟极有可能连续多次是同一个线程申请相同的锁。但是对于锁竞争比较激烈的场合，偏向锁就失效了，因为这样场合极有可能每次申请锁的线程都是不相同的，因此这种场合下不应该使用偏向锁，否则会得不偿失，需要注意的是，偏向锁失败后，并不会立即膨胀为重量级锁，而是先升级为轻量级锁。下面我们接着了解轻量级锁。 轻量级锁倘若偏向锁失败，虚拟机并不会立即升级为重量级锁，它还会尝试使用一种称为轻量级锁的优化手段(1.6之后加入的)，此时Mark Word 的结构也变为轻量级锁的结构。轻量级锁能够提升程序性能的依据是“对绝大部分的锁，在整个同步周期内都不存在竞争”，注意这是经验数据。需要了解的是，轻量级锁所适应的场景是线程交替执行同步块的场合，如果存在同一时间访问同一锁的场合，就会导致轻量级锁膨胀为重量级锁。 自旋锁轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。这是基于在大多数情况下，线程持有锁的时间都不会太长，如果直接挂起操作系统层面的线程可能会得不偿失，毕竟操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，因此自旋锁会假设在不久将来，当前的线程可以获得锁，因此虚拟机会让当前想要获取锁的线程做几个空循环(这也是称为自旋的原因)，一般不会太久，可能是50个循环或100循环，在经过若干次循环后，如果得到锁，就顺利进入临界区。如果还不能获得锁，那就会将线程在操作系统层面挂起，这就是自旋锁的优化方式，这种方式确实也是可以提升效率的。最后没办法也就只能升级为重量级锁了。 关于锁升级的详细内容：https://www.jianshu.com/p/36eedeb3f912 关于synchronized 可能需要了解的关键点synchronized的可重入性从互斥锁的设计上来说，当一个线程试图操作一个由其他线程持有的对象锁的临界资源时，将会处于阻塞状态，但当一个线程再次请求自己持有对象锁的临界资源时，这种情况属于重入锁，请求将会成功，在java中synchronized是基于原子性的内部锁机制，是可重入的，因此在一个线程调用synchronized方法的同时在其方法体内部调用该对象另一个synchronized方法，也就是说一个线程得到一个对象锁后再次请求该对象锁，是允许的，这就是synchronized的可重入性。注意由于synchronized是基于monitor实现的，因此每次重入monitor中的计数器仍会加1。 不可中断性不可中断就是指，一个线程获取锁之后，另外一个线程处于阻塞或者等待状态，前一个不释放，后一个也一直会阻塞或者等待，不可以被中断。 与sleep方法不同的是wait方法调用完成后，线程将被暂停，但wait方法将会释放当前持有的监视器锁(monitor)，直到有线程调用notify/notifyAll方法后方能继续执行，而sleep方法只让线程休眠并不释放锁。同时notify/notifyAll方法调用后，并不会马上释放监视器锁，而是在相应的synchronized(){}/synchronized方法执行结束后才自动释放锁。 synchronized特性： 有序性 : as-if-serial和happens-before 可见性：内存强制刷新 原子性：单一线程持有 可重入性：计数器 有序性参考：https://blog.csdn.net/byhook/article/details/87971081 用synchronized还是Lock呢？我们先看看他们的区别： synchronized是关键字，是JVM层面的底层啥都帮我们做了，而Lock是一个接口，是JDK层面的有丰富的API。 synchronized会自动释放锁，而Lock必须手动释放锁。 synchronized是不可中断的，Lock可以中断也可以不中断。 通过Lock可以知道线程有没有拿到锁，而synchronized不能。 synchronized能锁住方法和代码块，而Lock只能锁住代码块。 Lock可以使用读锁提高多线程读效率。 synchronized是非公平锁，ReentrantLock可以控制是否是公平锁。","categories":[{"name":"Java","slug":"Java","permalink":"https://zsc-cloud.github.io/categories/Java/"},{"name":"JUC","slug":"Java/JUC","permalink":"https://zsc-cloud.github.io/categories/Java/JUC/"}],"tags":[{"name":"JUC","slug":"JUC","permalink":"https://zsc-cloud.github.io/tags/JUC/"},{"name":"并发编程","slug":"并发编程","permalink":"https://zsc-cloud.github.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"锁","slug":"锁","permalink":"https://zsc-cloud.github.io/tags/%E9%94%81/"},{"name":"Java","slug":"Java","permalink":"https://zsc-cloud.github.io/tags/Java/"}]},{"title":"jaxb从xml读取特殊日期格式为null","slug":"jaxb从xml读取特殊日期格式为null","date":"2021-04-15T12:50:49.000Z","updated":"2021-06-06T03:26:59.235Z","comments":true,"path":"2021/04/15/jaxb从xml读取特殊日期格式为null/","link":"","permalink":"https://zsc-cloud.github.io/2021/04/15/jaxb%E4%BB%8Exml%E8%AF%BB%E5%8F%96%E7%89%B9%E6%AE%8A%E6%97%A5%E6%9C%9F%E6%A0%BC%E5%BC%8F%E4%B8%BAnull/","excerpt":"","text":"解决jaxb从xml文件读取 yyyy-MM-dd HH:mm:ss字段数据返回null 的问题 编写DateAdapter类，处理日期格式1234567891011121314151617181920/** * @author zsc * @date 2020/9/30 * jaxb从xml文件读取特殊格式日期（解决读取 yyyy-MM-dd HH:mm:ss返回null 的问题） */public class DateAdapter extends XmlAdapter&lt;String, Date&gt; &#123; // 其中格式可以根据不同的输入来定义不同格式。 private SimpleDateFormat yyyyMMddHHmmss = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); @Override public Date unmarshal(String v) throws Exception &#123; return yyyyMMddHHmmss.parse(v); &#125; @Override public String marshal(Date v) throws Exception &#123; return yyyyMMddHHmmss.format(v); &#125;&#125; 在日期字段中添加注解：@XmlJavaTypeAdapter(DateAdapter.class)1234567@XmlElement(name = &quot;IssuedTime&quot;)@XmlJavaTypeAdapter(DateAdapter.class)private Date issuedTime;@XmlElement(name = &quot;InsuranceDueDate&quot;)@XmlJavaTypeAdapter(DateAdapter.class)private Date insuranceDueDate;","categories":[{"name":"问题随笔","slug":"问题随笔","permalink":"https://zsc-cloud.github.io/categories/%E9%97%AE%E9%A2%98%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"问题随笔","slug":"问题随笔","permalink":"https://zsc-cloud.github.io/tags/%E9%97%AE%E9%A2%98%E9%9A%8F%E7%AC%94/"}]},{"title":"MySQL创建用户","slug":"MySQL创建用户","date":"2021-04-12T12:51:12.000Z","updated":"2021-06-06T03:23:40.403Z","comments":true,"path":"2021/04/12/MySQL创建用户/","link":"","permalink":"https://zsc-cloud.github.io/2021/04/12/MySQL%E5%88%9B%E5%BB%BA%E7%94%A8%E6%88%B7/","excerpt":"","text":"MySQL创建可读用户和指定数据库用户 必须在Root用户下创建 MySQL 赋予用户权限命令的简单格式可概括为：grant 权限 on 数据库对象 to 用户 创建数据库仅可读用户123# reader是用户名,xxxxxx为密码；GRANT后面跟的是用户权限，用户名@后面跟的是可连接的ip地址，%表示任意ip都可登陆GRANT Select ON *.* TO reader@&quot;%&quot; IDENTIFIED BY &quot;xxxxxx&quot;;flush privileges; 创建指定数据库用户123# 创建一个用户xh_dev_user仅访问xh_dev这一个数据库。xxxxxx为密码，xh_dev_user为用户名GRANT select,insert,update,delete ON xh_dev.* TO xh_dev_user@&quot;%&quot; IDENTIFIED BY &quot;xxxxxx&quot;;flush privileges;","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://zsc-cloud.github.io/categories/MySQL/"},{"name":"用户管理","slug":"MySQL/用户管理","permalink":"https://zsc-cloud.github.io/categories/MySQL/%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://zsc-cloud.github.io/tags/MySQL/"}]},{"title":"端口号被占用","slug":"端口号被占用","date":"2021-04-10T12:49:34.000Z","updated":"2022-03-26T03:42:17.313Z","comments":true,"path":"2021/04/10/端口号被占用/","link":"","permalink":"https://zsc-cloud.github.io/2021/04/10/%E7%AB%AF%E5%8F%A3%E5%8F%B7%E8%A2%AB%E5%8D%A0%E7%94%A8/","excerpt":"","text":"我们在启动本地项目的时候，经常出现项目端口被占用的情况。如下所示： 这个时候我们需要在本地结束这个端口占用的进程。 过程如下： 第一步：运行windows的cmd. 查看端口被谁占用，占用者的进程号 cmd输入 netstat -ano|findstr 11006回车，这里的11006指的是被占用端口，如果你的是其他比如8080，就把11006换成8080回车。我这里查询到是17508号进行 第二步：kill掉该进程，释放端口。cmd输入taskkill /pid 17508 /f 回车，17508即占用该端口的进程号，如果你是其他就换掉，（注意进程号后面加空格） 执行完提示你：成功: 已终止 PID 为 17508 的进程。 回到项目重新启动即可。","categories":[{"name":"问题随笔","slug":"问题随笔","permalink":"https://zsc-cloud.github.io/categories/%E9%97%AE%E9%A2%98%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"问题随笔","slug":"问题随笔","permalink":"https://zsc-cloud.github.io/tags/%E9%97%AE%E9%A2%98%E9%9A%8F%E7%AC%94/"}]},{"title":"HashMap解析","slug":"HashMap解析","date":"2021-04-06T07:55:03.000Z","updated":"2021-06-07T01:12:11.187Z","comments":true,"path":"2021/04/05/HashMap解析/","link":"","permalink":"https://zsc-cloud.github.io/2021/04/05/HashMap%E8%A7%A3%E6%9E%90/","excerpt":"","text":"HashMap源码解析JDK1.8先看看hashMap在jdk 1.8的结构，用的是数组+链表+红黑树的结构，也叫哈希桶，在jdk 1.8之前都是数组+链表的结构，因为在链表的查询操作都是O(N)的时间复杂度，而且hashMap中查询操作也是占了很大比例的，如果当节点数量多，转换为红黑树结构，那么将会提高很大的效率，因为红黑树结构中，增删改查都是O(log n)。 哈希桶就是数组里面的一个位置中所占所有数据，例如，下图中，绿色节点所占的该数组的位置，以及它连接的链表，整体为一个哈希桶。 hashMap的属性12345678910111213141516171819202122232425262728public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123; //序列号，序列化的时候使用。 private static final long serialVersionUID = 362498820763181265L; /**默认容量，1向左移位4个，00000001变成00010000，也就是2的4次方为16，使用移位是因为移位是计算机基础运算，效率比加减乘除快。**/ static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; //最大容量，2的30次方。 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; //加载因子，用于扩容使用。 static final float DEFAULT_LOAD_FACTOR = 0.75f; //当某个桶节点数量大于8时，会转换为红黑树。 static final int TREEIFY_THRESHOLD = 8; //当某个桶节点数量小于6时，会转换为链表，前提是它当前是红黑树结构。 static final int UNTREEIFY_THRESHOLD = 6; //当整个hashMap中元素数量大于64时，也会进行转为红黑树结构。 static final int MIN_TREEIFY_CAPACITY = 64; //存储元素的数组，transient关键字表示该属性不能被序列化 transient Node&lt;K,V&gt;[] table; //将数据转换成set的另一种存储形式，这个变量主要用于迭代功能。 transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; //元素数量 transient int size; //统计该map修改的次数 transient int modCount; //临界值，也就是元素数量达到临界值时，会进行扩容。 int threshold; //也是加载因子，只不过这个是变量。 final float loadFactor; 这里讲讲为什么默认容量大小为16，加载因子为0.75，主要原因是这两个常量的值都是经过大量的计算和统计得出来的最优解，仅仅是这样而已。 上面是hashMap的属性，尽量的解释给大家，下面再说说它里面的内部类，并不是所有的内部类，只说常用的。 12345678910static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; boolean red; TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next) &#123; super(hash, key, val, next); &#125;&#125; 使用静态内部类，是为了方便调用，而不用每次调用里面的属性或者方法都需要new一个对象。这是一个红黑树的结构，如果没有学过红黑树的同学，自己去看一下，内容太多，就不在这里阐述了。 12345678910111213 static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125;&#125; 里面还包含了一个结点内部类，是一个单向链表。上面这两个内部类再加上之前的Node&lt;K,V&gt;[] table属性，组成了hashMap的结构，哈希桶。 构造方法大致懂了hashMap的结构，我们来看看构造方法，一共有3个。 1234567891011121314151617181920212223public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; &#125; public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125; public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125; 第一个，空参构造，使用默认的加载因子0.75；第二个，设置初始容量，并使用默认的加载因子；第三个，设置初始容量和加载因子，其实第二个构造方法也是调用了第三个。下面，在看看最后一个构造函数。 1234567891011121314151617181920212223242526272829303132 public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);&#125; final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) &#123; //获取该map的实际长度 int s = m.size(); if (s &gt; 0) &#123; //判断table是否初始化，如果没有初始化 if (table == null) &#123; // pre-size /**求出需要的容量，因为实际使用的长度=容量*0.75得来的，+1是因为小数相除，基本都不会是整数，容量大小不能为小数的，后面转换为int，多余的小数就要被丢掉，所以+1，例如，map实际长度22，22/0.75=29.3,所需要的容量肯定为30，有人会问如果刚刚好除得整数呢，除得整数的话，容量大小多1也没什么影响**/ float ft = ((float)s / loadFactor) + 1.0F; //判断该容量大小是否超出上限。 int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); /**对临界值进行初始化，tableSizeFor(t)这个方法会返回大于t值的，且离其最近的2次幂，例如t为29，则返回的值是32**/ if (t &gt; threshold) threshold = tableSizeFor(t); &#125; //如果table已经初始化，则进行扩容操作，resize()就是扩容。 else if (s &gt; threshold) resize(); //遍历，把map中的数据转到hashMap中。 for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123; K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); &#125; &#125;&#125; 该构造函数，传入一个Map，然后把该Map转为hashMap，resize方法在下面添加元素的时候会详细讲解，在上面中entrySet方法会返回一个Set&lt;Map.Entry&lt;K, V&gt;&gt;，泛型为Map的内部类Entry，它是一个存放key-value的实例，也就是Map中的每一个key-value就是一个Entry实例，为什么使用这个方式进行遍历，因为效率高，具体自己百度一波，putVal方法把取出来的每个key-value存入到hashMap中，待会会仔细讲解。 构造函数和属性讲得差不多了，下面要讲解的是增删改查的操作以及常用的、重要的方法，毕竟里面的方法太多了，其它的就自己去看看吧。 添加元素 在讲解put方法之前，先看看hash方法，看怎么计算哈希值的。 12345 static final int hash(Object key) &#123; int h; /**先获取到key的hashCode，然后进行移位再进行异或运算，为什么这么复杂，不用想肯定是为了减少hash冲突**/ return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 下面来看看put方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566 public V put(K key, V value) &#123; /**四个参数，第一个hash值，第四个参数表示如果该key存在值，如果为null的话，则插入新的value，最后一个参数，在hashMap中没有用，可以不用管，使用默认的即可**/ return putVal(hash(key), key, value, false, true);&#125; final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; //tab 哈希数组，p 该哈希桶的首节点，n hashMap的长度，i 计算出的数组下标 Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //获取长度并进行扩容，使用的是懒加载，table一开始是没有加载的，等put后才开始加载 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; /**如果计算出的该哈希桶的位置没有值，则把新插入的key-value放到此处，此处就算没有插入成功，也就是发生哈希冲突时也会把哈希桶的首节点赋予p**/ if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); //发生哈希冲突的几种情况 else &#123; // e 临时节点的作用， k 存放该当前节点的key Node&lt;K,V&gt; e; K k; //第一种，插入的key-value的hash值，key都与当前节点的相等，e = p，则表示为首节点 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //第二种，hash值不等于首节点，判断该p是否属于红黑树的节点 else if (p instanceof TreeNode) /**为红黑树的节点，则在红黑树中进行添加，如果该节点已经存在，则返回该节点（不为null），该值很重要，用来判断put操作是否成功，如果添加成功返回null**/ e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); //第三种，hash值不等于首节点，不为红黑树的节点，则为链表的节点 else &#123; //遍历该链表 for (int binCount = 0; ; ++binCount) &#123; //如果找到尾部，则表明添加的key-value没有重复，在尾部进行添加 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); //判断是否要转换为红黑树结构 if (binCount &gt;= TREEIFY_THRESHOLD - 1) treeifyBin(tab, hash); break; &#125; //如果链表中有重复的key，e则为当前重复的节点，结束循环 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; //有重复的key，则用待插入值进行覆盖，返回旧值。 if (e != null) &#123; V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; //到了此步骤，则表明待插入的key-value是没有key的重复，因为插入成功e节点的值为null //修改次数+1 ++modCount; //实际长度+1，判断是否大于临界值，大于则扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); //添加成功 return null;&#125; 上面就是具体的元素添加，在元素添加里面涉及到扩容，我们来看看扩容方法resize。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103final Node&lt;K,V&gt;[] resize() &#123; //把没插入之前的哈希数组做我诶oldTal Node&lt;K,V&gt;[] oldTab = table; //old的长度 int oldCap = (oldTab == null) ? 0 : oldTab.length; //old的临界值 int oldThr = threshold; //初始化new的长度和临界值 int newCap, newThr = 0; //oldCap &gt; 0也就是说不是首次初始化，因为hashMap用的是懒加载 if (oldCap &gt; 0) &#123; //大于最大值 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; //临界值为整数的最大值 threshold = Integer.MAX_VALUE; return oldTab; &#125; //标记##，其它情况，扩容两倍，并且扩容后的长度要小于最大值，old长度也要大于16 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) //临界值也扩容为old的临界值2倍 newThr = oldThr &lt;&lt; 1; &#125; /**如果oldCap&lt;0，但是已经初始化了，像把元素删除完之后的情况，那么它的临界值肯定还存在， 如果是首次初始化，它的临界值则为0 **/ else if (oldThr &gt; 0) newCap = oldThr; //首次初始化，给与默认的值 else &#123; newCap = DEFAULT_INITIAL_CAPACITY; //临界值等于容量*加载因子 newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; //此处的if为上面标记##的补充，也就是初始化时容量小于默认值16的，此时newThr没有赋值 if (newThr == 0) &#123; //new的临界值 float ft = (float)newCap * loadFactor; //判断是否new容量是否大于最大值，临界值是否大于最大值 newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; //把上面各种情况分析出的临界值，在此处真正进行改变，也就是容量和临界值都改变了。 threshold = newThr; //表示忽略该警告 @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) //初始化 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; //赋予当前的table table = newTab; //此处自然是把old中的元素，遍历到new中 if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; //临时变量 Node&lt;K,V&gt; e; //当前哈希桶的位置值不为null，也就是数组下标处有值，因为有值表示可能会发生冲突 if ((e = oldTab[j]) != null) &#123; //把已经赋值之后的变量置位null，当然是为了好回收，释放内存 oldTab[j] = null; //如果下标处的节点没有下一个元素 if (e.next == null) //把该变量的值存入newCap中，e.hash &amp; (newCap - 1)并不等于j newTab[e.hash &amp; (newCap - 1)] = e; //该节点为红黑树结构，也就是存在哈希冲突，该哈希桶中有多个元素 else if (e instanceof TreeNode) //把此树进行转移到newCap中 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; /**此处表示为链表结构，同样把链表转移到newCap中，就是把链表遍历后，把值转过去，在置位null**/ Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; //返回扩容后的hashMap return newTab;&#125; 上部分内容就是整个扩容过程的操作，下面再来看看删除方法，remove。 删除元素1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public V remove(Object key) &#123; //临时变量 Node&lt;K,V&gt; e; /**调用removeNode(hash(key), key, null, false, true)进行删除，第三个value为null，表示，把key的节点直接都删除了，不需要用到值，如果设为值，则还需要去进行查找操作**/ return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;&#125;/**第一参数为哈希值，第二个为key，第三个value，第四个为是为true的话，则表示删除它key对应的value，不删除key,第四个如果为false，则表示删除后，不移动节点**/final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; //tab 哈希数组，p 数组下标的节点，n 长度，index 当前数组下标 Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; //哈希数组不为null，且长度大于0，然后获得到要删除key的节点所在是数组下标位置 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; //nodee 存储要删除的节点，e 临时变量，k 当前节点的key，v 当前节点的value Node&lt;K,V&gt; node = null, e; K k; V v; //如果数组下标的节点正好是要删除的节点，把值赋给临时变量node if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; //也就是要删除的节点，在链表或者红黑树上，先判断是否为红黑树的节点 else if ((e = p.next) != null) &#123; if (p instanceof TreeNode) //遍历红黑树，找到该节点并返回 node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; //表示为链表节点，一样的遍历找到该节点 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; /**注意，如果进入了链表中的遍历，那么此处的p不再是数组下标的节点，而是要删除结点的上一个结点**/ p = e; &#125; while ((e = e.next) != null); &#125; &#125; //找到要删除的节点后，判断!matchValue，我们正常的remove删除，!matchValue都为true if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; //如果删除的节点是红黑树结构，则去红黑树中删除 if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); //如果是链表结构，且删除的节点为数组下标节点，也就是头结点，直接让下一个作为头 else if (node == p) tab[index] = node.next; else /**为链表结构，删除的节点在链表中，把要删除的下一个结点设为上一个结点的下一个节点**/ p.next = node.next; //修改计数器 ++modCount; //长度减一 --size; /**此方法在hashMap中是为了让子类去实现，主要是对删除结点后的链表关系进行处理**/ afterNodeRemoval(node); //返回删除的节点 return node; &#125; &#125; //返回null则表示没有该节点，删除失败 return null;&#125; 删除还有clear方法，把所有的数组下标元素都置位null，下面在来看看较为简单的获取元素与修改元素操作。 获取元素 123456789101112131415161718192021222324252627282930313233 public V get(Object key) &#123; Node&lt;K,V&gt; e; //也是调用getNode方法来完成的 return (e = getNode(hash(key), key)) == null ? null : e.value;&#125; final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; //first 头结点，e 临时变量，n 长度,k key Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; //头结点也就是数组下标的节点 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; //如果是头结点，则直接返回头结点 if (first.hash == hash &amp;&amp; ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; //不是头结点 if ((e = first.next) != null) &#123; //判断是否是红黑树结构 if (first instanceof TreeNode) //去红黑树中找，然后返回 return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; //链表节点，一样遍历链表，找到该节点并返回 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; //找不到，表示不存在该节点 return null;&#125; 修改元素 元素的修改也是put方法，因为key是唯一的，所以修改元素，是把新值覆盖旧值。","categories":[{"name":"Java","slug":"Java","permalink":"https://zsc-cloud.github.io/categories/Java/"},{"name":"Java基础","slug":"Java/Java基础","permalink":"https://zsc-cloud.github.io/categories/Java/Java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"JavaSE","slug":"JavaSE","permalink":"https://zsc-cloud.github.io/tags/JavaSE/"},{"name":"集合","slug":"集合","permalink":"https://zsc-cloud.github.io/tags/%E9%9B%86%E5%90%88/"}]},{"title":"HashMap","slug":"HashMap","date":"2021-04-03T07:55:03.000Z","updated":"2022-03-26T03:42:17.392Z","comments":true,"path":"2021/04/02/HashMap/","link":"","permalink":"https://zsc-cloud.github.io/2021/04/02/HashMap/","excerpt":"","text":"前置知识HashHash表Hash表也称散列表，直译为哈希表，hash表是一种根据关键字值（key-value）而直接进行访问的数据结构。 在哈希表的键值对关系中，key到value中间还存在着一个映射值，这个映射值就是数组的下标index，key正是通过映射到数组对应的下标index而访问到value值的，通过一个映射函数f(key)映射到数组下标，这个函数我们称之为哈希函数 Hash冲突哈希表中，每个key通过哈希函数的计算都会得到一个唯一的index，但并不是每个index都对应一个唯一的key，就是说可能有两个以上的key映射到同一个index，这就产生了哈希冲突的问题 一个好的hash算法，应该是尽量避免不同的key映射出相同的index，这样才能减少哈希冲突的出现。比如在HashMap中解决哈希冲突采用的是拉链法，这种方法把冲突于某个数组下标的数据都保存到对应数组单元中一个链表中，如下图所示，这种数据结构中数组单元保存不是单一的数值，而是一个链表。按照这种方式，如果哈希冲突越多，可能造成数组的利用率就越低，因为有些数组单元可能被闲置，而数组单元上的链表可能会越大，这势必影响到Map的性能，所以尽可能地避免哈希冲突很重要 常见的hash算法a. 直接定址法：直接以关键字k或者k加上某个常数（k+c）作为哈希地址（H(k)=ak+b）。 b. 数字分析法：提取关键字中取值比较均匀的数字作为哈希地址（如一组出生日期，相较于年-月，月-日的差别要大得多，可以降低冲突概率） c. 分段叠加法：按照哈希表地址位数将关键字分成位数相等的几部分，其中最后一部分可以比较短。然后将这几部分相加，舍弃最高进位后的结果就是该关键字的哈希地址。 d. 平方取中法：如果关键字各个部分分布都不均匀的话，可以先求出它的平方值，然后按照需求取中间的几位作为哈希地址。 e. 伪随机数法：选择一随机函数，取关键字的随机值作为散列地址，通常用于关键字长度不同的场合。 f. 除留余数法：用关键字k除以某个不大于哈希表长度m的数p，将所得余数作为哈希表地址（H(k)=k%p, p&lt;=m; p一般取m或素数）。 解决hash冲突开放定址法： 所谓的开放定址法就是一旦发生了冲突，就去寻找下一个空的散列地址，只要散列表足够大，空的散列地址总能找到，并将记录存入公式为：fi(key) = (f(key)+di) MOD m (di=1,2,3,……,m-1) 当冲突发生时，使用某种探测技术在散列表中形成一个探测序列。沿此序列逐个单元地查找，直到找到给定的关键字，或者碰到一个开放的地址（即该地址单元为空）为止（若要插入，在探查到开放的地址，则可将待插入的新结点存人该地址单元）。查找时探测到开放的地址则表明表中无待查的关键字，即查找失败。 再哈希法： 再哈希法又叫双哈希法，有多个不同的Hash函数，当发生冲突时，使用第二个，第三个，….，等哈希函数计算地址，直到无冲突。虽然不易发生聚集，但是增加了计算时间。 链地址法： 链地址法的基本思想是：每个哈希表节点都有一个next指针，多个哈希表节点可以用next指针构成一个单向链表，被分配到同一个索引上的多个节点可以用这个单向 链表连接起来，如：键值对k2, v2与键值对k1, v1通过计算后的索引值都为2，这时及产生冲突，但是可以通道next指针将k2, k1所在的节点连接起来，这样就解决了哈希的冲突问题 建立公共溢出区： 这种方法的基本思想是：将哈希表分为基本表和溢出表两部分，凡是和基本表发生冲突的元素，一律填入溢出表 计算符号 &lt;&lt; : 左移运算符，num &lt;&lt; 1,相当于num乘以2 低位补0 &gt;&gt;: 右移运算符 &gt;&gt;&gt; : 无符号右移，忽略符号位，空位都以0补齐 ^ : 位异或 第一个操作数的的第n位于第二个操作数的第n位相反，那么结果的第n为也为1，否则为0 (1^1=0 1^0=1 0^0=0) &amp; : 与运算 第一个操作数的的第n位于第二个操作数的第n位如果都是1，那么结果的第n为也为1，否则为0(1&amp;1=1 1&amp;0=0 0&amp;0=0) | : 或运算 第一个操作数的的第n位于第二个操作数的第n位 只要有一个是1，那么结果的第n为也为1，否则为0(1|1=1 1|0=1 0|0=0) ~ : 非运算 操作数的第n位为1，那么结果的第n位为0，反之，也就是取反运算(一元操作符：只操作一个数)( ~1=0 ~0=1) 正文HashMap组成结构HashMap是我们非常常用的数据结构，由数组和链表组合构成的数据 大概如下，数组里面每个地方都存了Key-Value这样的实例，在Java7叫Entry在Java8中叫Node。 因为他本身所有的位置都为null，在put插入的时候会根据key的hash值去计算一个index值。 因为他本身所有的位置都为null，在put插入的时候会根据key的hash值去计算一个index值。 就比如我put（”张三“，3），我插入了为”帅丙“的元素，这个时候我们会通过哈希函数计算出插入的位置，计算出来index是2那结果如下。 index = index(hash(“张三”))= 2 我们都知道数组长度是有限的，在有限的长度里面我们使用哈希，哈希本身就存在概率性，就是”张三“和”李四“我们都去hash有一定的概率会一样，就像上面的情况我再次哈希”李四“极端情况也会hash到一个值上，那就形成了链表。 每一个节点都会保存自身的hash、key、value、以及下个节点，我看看Node的源码。 1234567static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next;..........&#125; Hash算法index的获取很简单，就是把h对 length-1取模，其中length为数组长度，所以关键的是h是怎么计算得到的，也很简单 就是通过 h = (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16)得到的 123456789static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; //获取index的方法，1.7源码，1.8中用tab[(n - 1) &amp; hash]代替，但原理一样static int indexFor(int h, int length) &#123; return h &amp; (length-1);&#125; 容量为什么是2的幂次方2的幂次方是指数组长度length的大小，假如length等于2的幂次方，那样length-1的二进制数据的低位就全部为1了，比如当数组长度为16，那么15的二进制就为1111，只有这样，在计算数组下标index的时候才能更好地利用h的散列性，举个例子： 1234567891011121314151617181920212223242526比如 length-1=15，二进制即为1111，分别跟三个不同的h值进行与运算，计算如下1111 &amp; 101010100101001001000 结果：1000 = 81111 &amp; 101000101101001001001 结果：1001 = 91111 &amp; 101010101101101001010 结果：1010 = 101111 &amp; 101100100111001101100 结果： 1100 = 12 但是如果length为11的话，那么length-1的二进制则表示为1010，与同样的三个h值与运算，计算如下1010 &amp; 101010100101001001000 结果：1000 = 81010 &amp; 101000101101001001001 结果：1000 = 81010 &amp; 101010101101101001010 结果：1010 = 101010 &amp; 101100100111001101100 结果： 1000 = 8 很明显，当数组长度为16的时候，没有产生哈希冲突，而为11的时候，产生了3次哈希冲突，所以这就说明了为什么HashMap的容量建议为2的幂次方 put方法流程 判断数组是否为空，为空进行初始化; 懒加载，只有真正存值的时候才会创建数组 不为空，计算 k 的 hash 值，通过(n - 1) &amp; hash计算应当存放在数组中的下标 index; 查看 table[index] 是否存在数据，没有数据就构造一个Node节点存放在 table[index] 中； 存在数据，说明发生了hash冲突(存在二个节点key的hash值一样), 继续判断key是否相等，相等，用新的value替换原数据(onlyIfAbsent为false)； 如果不相等，判断当前节点类型是不是树型节点，如果是树型节点，创造树型节点插入红黑树中；(如果当前节点是树型节点证明当前已经是红黑树了) 如果不是树型节点，创建普通Node加入链表中；判断链表长度是否大于 8并且数组长度大于64， 大于的话链表转换为红黑树； 插入完成之后判断当前节点数是否大于阈值，如果大于开始扩容为原数组的二倍。 get方法流程 调用key的hashcode方法，得到一个hashcode，通过hashcode计算下标index定位到map中数组对应的下标，就是定位到HashMap中的具体的某一个桶。 判断这个桶是否为空，如果是，就结束判断，返回null；如果不是空，就转到第三步。 判断桶中对象的key值与传入的key值是否相等并且用equals方法判断他们是否为同一个对象，如果判断结果为真，就返回这个对象的value值；如果为假，就转到第四步。 判断这个对象它指向下一个对象的next指针的是不是为空，如果是空，就结束判断，返回null；如果next指针不是空，就取出它所指对象，重复上面第三步的判断操作，直到取出对应的value值，或者直到桶中的对象被遍历完，返回一个null值。 插入链表方式java8之前是头插法，就是说新来的值会取代原有的值，原有的值就顺推到链表中去，就像上面的例子一样，因为写这个代码的作者认为后来的值被查找的可能性更大一点，提升查找的效率。 扩容有两个因素： Capacity：HashMap当前长度。 LoadFactor：负载因子，默认值0.75f 当HashMap的当前长度达到总长度的0.75。触发扩容。扩容时，新建一个空HashMap，长度为原Map的2倍，然后对数据重新Hash,存入新的Map 头插法造成的问题我们要在容量为2的容器里面用不同线程插入A，B，C，假如我们在resize之前打个短点，那意味着数据都插入了但是还没resize那扩容前可能是这样的。 我们可以看到链表的指向A-&gt;B-&gt;C 因为resize的赋值方式，也就是使用了单链表的头插入方式，同一位置上新元素总会被放在链表的头部位置，在旧数组中同一条Entry链上的元素，通过重新计算索引位置后，有可能被放到了新数组的不同位置上。 就可能出现下面的情况，大家发现问题没有？ B的下一个指针指向了A 一旦几个线程都调整完成，就可能出现环形链表 JDK1.8尾插法因为java8之后链表有红黑树的部分，大家可以看到代码已经多了很多if else的逻辑判断了，红黑树的引入巧妙的将原本O(n)的时间复杂度降低到了O(logn)。 JDK1.8中，当链表的长度大于8，数组长度大于等于 64,这个链表就会进化为红黑树。当红黑树的个数小于6，就会退化为链表 当hash冲突很多的时候，红黑树查询效率比链表要高 使用头插会改变链表的上的顺序，但是如果使用尾插，在扩容时会保持链表元素原本的顺序，就不会出现链表成环的问题了。 就是说原本是A-&gt;B，在扩容后那个链表还是A-&gt;B Java7在多线程操作HashMap时可能引起死循环，原因是扩容转移后前后链表顺序倒置，在转移过程中修改了原来链表中节点的引用关系。 Java8在同样的前提下并不会引起死循环，原因是扩容转移后前后链表顺序不变，保持之前节点的引用关系。 我认为即使不会出现死循环，但是通过源码看到put/get方法都没有加同步锁，多线程情况最容易出现的就是：无法保证上一秒put的值，下一秒get的时候还是原值，所以线程安全还是无法保证。 HashMap总结 组成结构：本质是一个哈希表，JDK1.7是数组加链表，JDK1.8是数组+链表+红黑树，当时链表长度&gt;8并且数组长度&gt;64的时候链表进化成树，目的是保证查询效率。JDK1.7是头插法，1.8是尾插法。头插法扩容容易造成死循环 index的下标计算：先根据hash函数计算出hashcode，在对数组长度大小-1取模，目的是让index更加的散列 长度为什么是二次幂：也是为了让index更加的散列。因为计算index是根据len-1进行取模。 put方法：如果是hashmap为空，第一次进行初始化。根据key计算出来index,构建一个Note节点放入数组中，如果该节点有值，说说明产生了hash冲突，判断key是否相等，相等则替换。不等则判断该节点是树还是链表，加入进对应的树或者链表，判断需不需要扩容操作。 get方法：判断是否为空，为空直接返回null，根据key计算到index，若index没有Note，则返回null，若存在节点， equals判断是否相等，相等返回该值，不等则遍历该节点下的树或者链表。 扩容：负载因子0.75，超过这个阈值则扩容，长度翻倍。里面的数据，重新hash存值。 HashMap线程安全问题在并发的情况下，我们一般都会使用HashTable或者ConcurrentHashMap，但是因为前者的并发度的原因基本上没啥使用场景了，所以存在线程不安全的场景我们都使用的是ConcurrentHashMap。 HashTable实现安全很简单，直接get/put加锁 HashTableHashTable和HashMap的区别 Hashtable 是不允许键或值为 null 的，HashMap 的键值则都可以为 null。 实现方式不同：Hashtable 继承了 Dictionary类，而 HashMap 继承的是 AbstractMap 类。 初始化容量不同：HashMap 的初始容量为：16，Hashtable 初始容量为：11，两者的负载因子默认都是：0.75。 扩容机制不同：当现有容量大于总容量 * 负载因子时，HashMap 扩容规则为当前容量翻倍，Hashtable 扩容规则为当前容量翻倍 + 1。 迭代器不同：HashMap 中的 Iterator 迭代器是 fail-fast 的，而 Hashtable 的 Enumerator 不是 fail-fast 的。 所以，当其他线程改变了HashMap 的结构，如：增加、删除元素，将会抛出ConcurrentModificationException 异常，而 Hashtable 则不会。 ConcurrentHashMapConcurrentHashMap 底层是基于 数组 + 链表 组成的，不过在 jdk1.7 和 1.8 中具体实现稍有不同。 JDK1.7先说一下他在1.7中的数据结构吧： 如图所示，是由 Segment 数组、HashEntry 组成，和 HashMap 一样，仍然是数组加链表。 Segment 是 ConcurrentHashMap 的一个内部类 HashEntry跟HashMap差不多的，但是不同点是，他使用volatile去修饰了他的数据Value还有下一个节点next。 关于分段锁分段Segment继承了重入锁ReentrantLock，有了锁的功能，每个锁控制的是一段，当每个Segment越来越大时，锁的粒度就变得有些大了。 分段锁的优势在于保证在操作不同段 map 的时候可以并发执行，操作同段 map 的时候，进行锁的竞争和等待。这相对于直接对整个map同步synchronized是有优势的。 理论上 ConcurrentHashMap 支持 CurrencyLevel (Segment 数组数量)的线程并发。Segment 指定大小就是不可变的，默认是16。 JDK1.8抛弃了原有的 Segment 分段锁，而采用了 CAS + synchronized 来保证并发安全性。 跟HashMap很像，也把之前的HashEntry改成了Node，但是作用不变，把值和next采用了volatile去修饰，保证了可见性，并且也引入了红黑树，在链表大于一定值的时候会转换（默认是8）。 put操作 ConcurrentHashMap在进行put操作的还是比较复杂的，大致可以分为以下步骤： 根据 key 计算出 hashcode 。 判断是否需要进行初始化。 即为当前 key 定位出的 Node，如果为空表示当前位置可以写入数据，利用 CAS 尝试写入，失败则自旋保证成功。 如果当前位置的 hashcode == MOVED == -1,则需要进行扩容。 如果都不满足，则利用 synchronized 锁写入数据。 如果数量大于 TREEIFY_THRESHOLD 则要转换为红黑树。 get操作 根据计算出来的 hashcode 寻址，如果就在桶上那么直接返回值。 如果是红黑树那就按照树的方式获取值。 就不满足那就按照链表的方式遍历获取值。 为什么放弃了分段锁缺点在于分成很多段时会比较**浪费内存空间(**不连续，碎片化); 操作map时竞争同一个分段锁的概率非常小时，分段锁反而会造成更新等操作的长时间等待; 当某个段很大时，分段锁的性能会下降。 为什么不用ReentrantLock而用synchronized ? 减少内存开销:如果使用ReentrantLock则需要节点继承AQS来获得同步支持，增加内存开销，而1.8中只有头节点需要进行同步。 内部优化:synchronized则是JVM直接支持的，JVM能够在运行时作出相应的优化措施：锁粗化、锁消除、锁自旋等等。 总结1.8 在 1.7 的数据结构上做了大的改动，采用红黑树之后可以保证查询效率（O(logn)），甚至取消了 ReentrantLock 改为了 synchronized，这样可以看出在新版的 JDK 中对 synchronized 优化是很到位的。 jdk8 放弃了分段锁而是用了Node锁，减低锁的粒度，提高性能，并使用CAS操作来确保Node的一些操作的原子性，取代了锁。 参考文章：https://my.oschina.net/pingpangkuangmo/blog/817973","categories":[{"name":"Java","slug":"Java","permalink":"https://zsc-cloud.github.io/categories/Java/"},{"name":"Java基础","slug":"Java/Java基础","permalink":"https://zsc-cloud.github.io/categories/Java/Java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"JavaSE","slug":"JavaSE","permalink":"https://zsc-cloud.github.io/tags/JavaSE/"},{"name":"集合","slug":"集合","permalink":"https://zsc-cloud.github.io/tags/%E9%9B%86%E5%90%88/"}]},{"title":"反射","slug":"反射","date":"2021-04-02T07:57:43.000Z","updated":"2022-03-26T03:42:17.325Z","comments":true,"path":"2021/04/01/反射/","link":"","permalink":"https://zsc-cloud.github.io/2021/04/01/%E5%8F%8D%E5%B0%84/","excerpt":"","text":"如何通过反射创建对象简单的说，反射机制就是在程序的运行过程中被允许对程序本身进行操作，比如自我检查，进行装载，还可以获取类本身，类的所有成员变量和方法，类的对象，还可以在运行过程中动态的创建类的实例，通过实例来调用类的方法，这就是反射机制一个比较重要的功能了。那么要通过程序来理解反射机制，首先要理解类的加载过程 在Java程序执行的时候，要经历三个步骤：加载、连接和初始化。首先程序要加载到JVM的方法区中，然后进行连接，最后初始化。这里就主要介绍一下类的加载。如上图，首先，JVM会从硬盘中读取Java源文件并将其加载到方法区中同时生成类名.class文件，也就是类对象，这个类对象中包含了我们创建类的实例时所需要的模板信息，也就是源代码中的成员变量和方法等。Class本身也是一个类，它的主要功能之一就是生成类加载时的class文件，为类的初始化及实例化做准备。而我们在程序中通过关键字new创建的对象创建的是类的对象，而不是类对象，二者的区别如图中所示。 反射的作用和意义1、反射的应用场合：在编译时根本无法知道该对象或类可能属于哪些类，程序只依靠运行时信息来发现该对象和类的真实信息. 2、反射的作用：通过反射可以使程序代码访问装载到JVM 中的类的内部信息 获取已装载类的成员变量信息 获取已装载类的方法 获取已装载类的构造方法信息 利用反射机制可以获取类对象（也就是我们前面介绍的类对象，获取类对象之后我们便获取了类的模板，可以对类进行一些操作），有以下三种方法： 1.类名.class() 2.对象名.getClass() 3.Class.forName(具体的类名) 用反射创建一个对象： 1234567891011/** * 示例 */public class Demo &#123; public static void main(String[] args) throws Exception &#123; Class clz = Class.forName(&quot;cn.itcast_01.User&quot;); Object obj = clz.newInstance(); // 创建一个对象 System.out.println(obj); &#125;&#125; 反射机制在我们所学习的框架中有很大的应用，而在我们实际开发中用的并不多 IOC运用反射机制和工厂模式的概念 在传统的开发过程中，对象是程序使用使用new创建出来的；但是在spring中是通过IOC容器创建，再推送给调用者。 Spring 中的反射: 创建 Bean 实例时的反射： 1234// 通过类加载器，根据 class 路径，得到其类对象Class&lt;?&gt; clz = Thread.currentThread().getContextClassLoader().loadClass(&quot;org.deppwang.litespring.v1.service.PetStoreService&quot;);// 根据类对象生成 Bean 实例return clz.newInstance(); 构造方法依赖注入时的反射： 1234567// 通过反射获取当前类所有的构造方法信息（Constructor 对象）Constructor&lt;?&gt;[] candidates = beanClass.getDeclaredConstructors();// 设置构造方法参数实例Object[] argsToUse = new Object[parameterTypes.length];argsToUse[i] = getBean(beanNames.get(i));// 使用带有参数的 Constructor 对象实现实例化 Bean。此时使用反射跟上面一样（newInstance0），只是多了参数return constructorToUse.newInstance(argsToUse); setter() 方法依赖注入时的反射 123456// 通过反射获取当前类所有的方法信息（Method 对象）Method[] methods = bean.getClass().getDeclaredMethods();// 获得方法参数实例Object propertyBean = getBean(propertyName);// 通过反射执行调用 setter() 方法。invoke：调用方法，propertyBean 作为方法的参数method.invoke(bean, propertyBean); @Autowired 依赖注入时的反射 12345678// 通过反射得到当前类所有的字段信息（Field 对象）Field[] fields = bean.getClass().getDeclaredFields();// 判断字段是否有 @Autowired 注解Annotation ann = field.getAnnotation(Autowired.class);// 设置字段可连接，相当于将非 public（private、default、protect）更改为 publicfield.setAccessible(true);// 通过反射设置字段的值field.set(bean, getBean(field.getName()));","categories":[{"name":"Java","slug":"Java","permalink":"https://zsc-cloud.github.io/categories/Java/"},{"name":"Java基础","slug":"Java/Java基础","permalink":"https://zsc-cloud.github.io/categories/Java/Java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"JavaSE","slug":"JavaSE","permalink":"https://zsc-cloud.github.io/tags/JavaSE/"}]},{"title":"MySQL中show profile详解","slug":"MySQL中show-profile详解","date":"2021-03-31T03:02:24.000Z","updated":"2022-03-26T03:42:17.379Z","comments":true,"path":"2021/03/30/MySQL中show-profile详解/","link":"","permalink":"https://zsc-cloud.github.io/2021/03/30/MySQL%E4%B8%ADshow-profile%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"当我们在优化sql的时候可以使用explain来查看执行计划，可当根据执行计划优化完毕之后我们的sql的运行时间还是比较长，这时我们可以使用show profile更细粒度的分析，show-profile，可以提高用来分析当前会话中语句执行的资源消耗情况,可以用于sql调优的测量. Show Profile官方文档地址 1. 基本语法： 查看是否开启：show variables like &quot;%pro%&quot;; 开启：set profiling = 1 查看SQL执行时间：show profiles; 查看记录中第一条SQL详细时间：show profile for query 1; 关于show Profile的基本用法请看上篇文章：通过Query Profiler查看MySQL语句运行时间 2. 通过type指定显示其他信息我们看一下官方提供的profile语法： 123456789101112131415SHOW PROFILE [type [, type] ... ] [FOR QUERY n] [LIMIT row_count [OFFSET offset]]type: &#123; ALL 显示所有信息 | BLOCK IO 显示块输入和输出操作的数量 | CONTEXT SWITCHES 显示自愿上下文切换和非自愿上下文切换的数量 | CPU 显示用户和系统的CPU使用时间 | IPC 显示已发送和已接收消息（messages）的数量 | MEMORY -- 尚未生效 | PAGE FAULTS 显示主要和次要页面错误的数量 | SOURCE 显示源代码中函数名称以及该函数所在文件的名称和行号 | SWAPS 显示SWAP数量&#125; 3. show profile返回的行和列如下图所示，是执行一个show profile all for query 3;命令显示的结果集。我们根据行和列分别来分析一个每个字段的含义。 行字段的含义：12345678910111213141516171819202122+---------------------+--------------+------+-----+----------+-------+| Field | Type | Null | Key | Default | Extra |+---------------------+--------------+------+-----+----------+-------+| QUERY_ID | int(20) | NO | | 0 | | # 语句ID| STATE | varchar(30) | NO | | | | # 状态| DURATION | decimal(9,6) | NO | | 0.000000 | | # 持续时间，单位s| CPU_USER | decimal(9,6) | YES | | NULL | | # 用户态CPU时间，单位s| CPU_SYSTEM | decimal(9,6) | YES | | NULL | | # 系统态CPU时间，单位s| CONTEXT_VOLUNTARY | int(20) | YES | | NULL | | # 自愿上下文切换次数| CONTEXT_INVOLUNTARY | int(20) | YES | | NULL | | # 非自愿上下文切换次数| BLOCK_OPS_IN | int(20) | YES | | NULL | | # 块输入次数| BLOCK_OPS_OUT | int(20) | YES | | NULL | | # 块输出次数| MESSAGES_SENT | int(20) | YES | | NULL | | # 发送的消息数量| MESSAGES_RECEIVED | int(20) | YES | | NULL | | # 接收的消息数量| PAGE_FAULTS_MAJOR | int(20) | YES | | NULL | | # 主要页面错误数量| PAGE_FAULTS_MINOR | int(20) | YES | | NULL | | # 次要页面错误数量| SWAPS | int(20) | YES | | NULL | | # 交换次数| SOURCE_FUNCTION | varchar(30) | YES | | NULL | | # 源代码函数| SOURCE_FILE | varchar(20) | YES | | NULL | | # 源代码文件| SOURCE_LINE | int(20) | YES | | NULL | | # 源代码行数+---------------------+--------------+------+-----+----------+-------+ 列字段的含义：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214* Sending data (最重要的一个过程★★★★★) 线程正在读取和处理一条SELECT语句的行，并且将数据发送至客户端。由于在此期间会执行大量 的磁盘访问（读操作）， 这个状态在一个指定查询的生命周期中经常是耗时最长的。 这个字段才是SQL真正运行采集+相应数据的时间，而非executing； --以下按照首字母顺序依次排序 * After create 这个状态当线程创建一个表（包括内部临时表）时，在这个建表功能结束时出现。即使某些错误导致建表失败，也会使用这个状态。* Analyzing 当计算MyISAM表索引分布时。（比如进行ANALYZE TABLE时）* checking permissions 这个线程检查服务器是否有具有执行该语句的所需权限。* Checking table 线程正在执行表检查操作。* cleaning up 线程处理一个命令，并正准备释放内存和重置某些状态变量。* closing tables 线程正在将变更的表中的数据刷新到磁盘上并正在关闭使用过的表。这应该是一个快速的操作。如果不是这样的话 则应该检查硬盘空间是否已满或者硬盘IO是否达到瓶颈。 * converting HEAP to MyISAM 线程将一个内部临时表转换为磁盘上的MyISAM表。* copy to tmp table 线程正在处理一个ALTER TABLE语句。这个状态发生在新的表结构已经创建之后，但是在数据被复制进入之前。* Copying to group table 如果一个语句有不同的ORDER BY和GROUP BY条件，数据会被复制到一个临时表中并且按组排序。* Copying to tmp table 线程将数据写入内存中的临时表。 正在创建临时表以存放部分查询结果* Copying to tmp table on disk 线程正在将数据写入磁盘中的临时表。临时表的结果集过大。所以线程将临时表由基于内存模式改为基于磁盘模式，以节省内存。 但是这个过程会异常的缓慢！！* Creating index 线程正在对一个MyISAM表执行ALTER TABLE ... ENABLE KEYS语句。* Creating sort index 线程正在使用内部临时表处理一个SELECT 操作。* creating table 线程正在创建一个表，包括创建临时表。* Creating tmp table 线程正在创建一个临时表在内存或者磁盘上。 如果这个表创建在内存上但是之后被转换到磁盘上，这个状态在运行Copying to tmp table on disk 的时候保持。* deleting from main table 线程正在执行多表删除的第一部分，只从第一个表中删除。并且保存列和偏移量用来从其他（参考）表删除。* deleting from reference tables 线程正在执行多表删除的第二部分，并从其他表中删除匹配的行。* discard_or_import_tablespace 线程正在执行ALTER TABLE ... DISCARD TABLESPACE 或 ALTER TABLE ... IMPORT TABLESPACE语句。* end 这个状态出现在结束时，但是在对ALTER TABLE, CREATE VIEW, DELETE, INSERT, SELECT, 或者 UPDATE 语句进行清理之前。* executing 该线程已开始执行一条语句。* Execution of init_command 线程正在执行处于init_command系统变量的值中的语句。* freeing items* 线程已经执行了命令。在这个状态中涉及的查询缓存可以得到一些释放。这个状态通常后面跟随cleaning up状态。* Flushing tables 线程正在执行FLUSH TABLES 并且等待所有线程关闭他们的表。* FULLTEXT initialization 服务器正在准备进行自然语言全文检索。* init 这个状态出现在线程初始化ALTER TABLE, DELETE, INSERT, SELECT, 或 UPDATE语句之前。 服务器在这种状态下进行的操作，包括：刷新全日志、Innodb日志，和一些查询缓存清理操作。* Killed 程序对线程发送了KILL语句，并且它应该放弃下一次对KILL标记的检查。 这个标记在每一个MySQL的主要循环中被检查，但在某些情况下，它可能需要令线程在很短的时间内死亡。 如果这个线程被其他线程锁住了，这个KILL操作会在其他线程释放锁的瞬时执行。* logging slow query 这个线程正在将语句写入慢查询日志。* NULL 没有操作的状态。* login 线程连接的初始状态。直到客户端已经成功验证。* manage keys 服务器启用或禁用表索引。* Opening tables, Opening table 线程正试图打开一张表* optimizing 服务器执行查询的初步优化。* preparing 在查询优化过程中出现这个状态。* Purging old relay logs 线程正在移除不必要的中继日志文件。* query end 这个状态出现在处理一个查询之后，但是在freeing items状态之前。* Reading from net 服务器正在从网络阅读数据包。* Removing duplicates 查询正在使用SELECT DISTINCT，这种情况下MySQL不能在早期阶段优化掉一些distinct操作。 因此，MySQL需要一个额外的阶段，在将结果发送到客户端之前删除所有重复的行。* removing tmp table 线程正在移除一个内置临时表，在执行一条SELECT语句之后。 如果没有临时表产生，那么这个状态不被使用。* rename* 线程正在重命名一张表。* rename result table 线程正在处理ALTER TABLE语句，创建新的表，并且重命名它来代替原有的表。* Reopen tables 线程获得了表锁，但是在取得表锁之后才发现该表的底层结构已经发生了变化。线程释放这个锁，关闭表，并试图重新打开该表。* Repair by sorting 修复代码正在使用一个分类来创建索引。* Repair done 线程完成一个多线程的MyISAM表的修复。* Repair with keycache 修复代码正在通过索引缓存一个接一个地使用创建索引。这比通过分类修复要慢很多。* Rolling back 线程正在回滚一个事务* Searching rows for update 线程正在进行第一阶段，在更新前寻找所有匹配的行。如果update正在更改用于查找相关行的索引，则必须这么做。* setup 线程正开始进行一个ALTER TABLE操作。* Sorting for group 线程正在执行一个由GROUP BY指定的排序。* Sorting for order 线程正在执行一个由ORDER BY指定的排序。* Sorting index 线程正在对索引页进行排序，为了对MyISAM表进行操作时获得更优的性能。* Sorting result 对于一个SELECT语句，这与创建排序索引相似，但是是对非临时表。* statistics 服务器计算统计去规划一个查询。如果一个线程长时间处于这个状态，这个服务器的磁盘可能在执行其他工作。* System lock 这个线程正在请求或者等待一个内部的或外部的系统表锁。如果这个状态是由于外部锁的请求产生的，并且你没有使用多个正在访问相同的表的mysql服务器 * Waiting for table level lock 系统锁定后的下一个线程状态。线程已获得外部锁并且将请求内部表锁。* Updating 线程寻找更新匹配的行并进行更新。* updating main table 线程正在执行多表更新的第一部分，只从第一个表中更新。并且保存列和偏移量用来从其他（参考）表更新。* updating reference tables 线程正在执行多表更新的第二部分，并从其他表中更新匹配的行。* User lock 线程正在请求或等待一个GET_LOCK()调用所要求的咨询锁。对于SHOW PROFILE，这个状态意味这线程正在请求锁。（而非等待）* User sleep 线程调用了一个SLEEP()。* Waiting for commit lock 一个显式或隐式语句在提交时等待释放读锁* Waiting for global read lock 等待全局读锁。* Waiting for release of readlock 等待释放读锁。* Waiting for tables, Waiting for table, Waiting for table flush 线程获得一个通知，底层表结构已经发生变化，它需要重新打开表来获取新的结构。然而，重新打开表，它必须等到所有其他线程关闭这个有问题的表。 这个通知产生通常因为另一个线程对问题表执行了FLUSH TABLES或者以下语句之一： FLUSH TABLES tbl_name, ALTER TABLE, RENAME TABLE, REPAIR TABLE, ANALYZE TABLE, or OPTIMIZE TABLE.* Waiting for lock_type lock 等待各个种类的表锁。* Waiting on cond 一个普通的状态，线程正在等待一个条件为真。没有特定的状态信息可用。* Writing to net 服务器正在写一个网络数据包。 3. SQL执行过程中可能导致时间慢的原因1234567891011121314151617181920212223242526271. Sending data (最重要的一个过程★★★★★) 线程正在读取和处理一条SELECT语句的行，并且将数据发送至客户端。由于在此期间会执行大量 的磁盘访问（读操作），这个状态在一个指定查询的生命周期中经常是耗时最长的。 对于一个普通查询来说，这个参数过大可分为两种情况 1. 第一种是SQL本身，比如没有建立正确的索引，索引失效等等情况，这种数据体现在CPU_user 和CPU_sysyem字段 时间过长； 2. 第二种是相应数据量过大，导致CPU调度时上下文频繁切换。这种数据体现在CONTEXT_INVOLUNTARY和CONTEXT_VOLUNTARY字段 时间过长; 像：外网使用Navicat连接到远程数据库中。查询一个普通的SQL，在本地MySQL执行速度很快，但是使用远程服务器的MySQL就异常的缓慢。 这时若查询profile详情，就会发现大量相应数据传输IO导致频繁的上下文切换消耗了大量的时间。 2. converting HEAP to MyISAM 原译指的是：线程将一个内部临时表转换为磁盘上的MyISAM表。 我们实际操作中可能出现的问题就是查询结果太大了导致内存不够，往磁盘上搬。3.Creating tmp table 创建了临时表4.Coping to tmp table on disk 把内存中临时表复制到磁盘5.locked 加锁------------------------------------------------ 2，4 可以修改一下tmp_table_size和max_heap_table_size两个参数来调整 show profile语句已经弃用，并将在以后版本中移除，建议使用 Performance Schema Performance Schema文档","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://zsc-cloud.github.io/categories/MySQL/"},{"name":"SQL优化","slug":"MySQL/SQL优化","permalink":"https://zsc-cloud.github.io/categories/MySQL/SQL%E4%BC%98%E5%8C%96/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://zsc-cloud.github.io/tags/MySQL/"}]},{"title":"通过Query Profiler查看MySQL语句运行时间","slug":"通过Query-Profiler查看MySQL语句运行时间","date":"2021-03-21T03:02:04.000Z","updated":"2022-03-26T03:42:17.294Z","comments":true,"path":"2021/03/20/通过Query-Profiler查看MySQL语句运行时间/","link":"","permalink":"https://zsc-cloud.github.io/2021/03/20/%E9%80%9A%E8%BF%87Query-Profiler%E6%9F%A5%E7%9C%8BMySQL%E8%AF%AD%E5%8F%A5%E8%BF%90%E8%A1%8C%E6%97%B6%E9%97%B4/","excerpt":"","text":"前言 Query Profiler是MYSQL自带的一种query诊断分析工具，通过它可以分析出一条SQL语句的性能瓶颈在什么地方。通常我们是使用的explain,以及slow query log都无法做到精确分析， 但是Query Profiler却可以定位出一条SQL语句执行的各种资源消耗情况，比如CPU，IO等，以及该SQL执行所耗费的时间等。 Show profiles是5.0.37之后添加的，要想使用此功能，要确保版本在5.0.37之后。 登录MySQL查看数据库版本方法登录：mysql -u username -p使用想选择的数据库： use databses查看版本：show variables like &quot;%version%&quot;; 或者 select version(); 查看profile是否开启，数据库默认是不开启的 查看方法： show variables like &quot;%pro%&quot;; 设置开启方法： set profiling = 1; 可以开始执行一些想要分析的sql语句了 执行完后 ，查询SQL的执行时间： show profiles； 即可查看所有sql的总的执行时间。Query_ID：SQL编号ID；Duration：SQL执行时间；Query：SQL语句。 show profile for query 1 即可查看第1个sql语句的执行的各个操作的耗时详情。 查看出一条SQL语句执行的各种资源消耗情况，比如CPU，IO等: show profile cpu, block io, memory,swaps,context switches,source for query 1 关于show profile all 返回行和列的详解请见下篇文章：MySQL中show profile详解测试完毕后，关闭参数：set profiling=0","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://zsc-cloud.github.io/categories/MySQL/"},{"name":"SQL优化","slug":"MySQL/SQL优化","permalink":"https://zsc-cloud.github.io/categories/MySQL/SQL%E4%BC%98%E5%8C%96/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://zsc-cloud.github.io/tags/MySQL/"}]},{"title":"Gitee+PicGo+Typora实现高速图床","slug":"Gitee-PicGo-Typora实现高速图床","date":"2021-03-16T03:32:12.000Z","updated":"2022-03-26T03:42:17.352Z","comments":true,"path":"2021/03/15/Gitee-PicGo-Typora实现高速图床/","link":"","permalink":"https://zsc-cloud.github.io/2021/03/15/Gitee-PicGo-Typora%E5%AE%9E%E7%8E%B0%E9%AB%98%E9%80%9F%E5%9B%BE%E5%BA%8A/","excerpt":"","text":"之前使用GitHub搭建床图，我们都知道GitHub在国内速度感人，图片经常刷不出来，而且上传巨慢，今天我们用国内Gitee搭建床图，实现秒级上传，而且配和Typora笔记集成实现自动上传 Gitee创建图床仓库注册登录码云账户，并创建一个仓库 注意这里一定要选择开源，否则最后生成的图片地址访问不到！ 获取仓库的私人令牌token这个token需要配置在PicGo中，用于自动上传使用，很重要 进入Gitee首页点击头像，进入设置，在安全设置中找到私人令牌 生成新的令牌： 这里全选就可以，提交之后就生成一个token，这个要保存好，因为这个token只有在第一次生成的时候才会显示，关闭页面之后就无法显示。以后忘记了只能重新生成 安装配置PicGo安装node.jspicGo依赖于node.js，所以我们要先安装node.js 下载地址：https://nodejs.org/zh-cn/ node.js安装很简单，在这里就不演示，基本直接下一步就OK，node.js会自动配置环境变量 安装好在cmd中输入：node -v 出现版本号就说明安装成功了。安装之后最好是重启一下。 node.js安装教程 下载PicGo官网下载地址 git下载很慢 百度云下载：链接：https://pan.baidu.com/s/1yYaw01mIUIIgyhQ324Q-xQ 提取码：8888 安装成功页面如下： 安装插件在插件设置中搜索gitee，找到gitee-upload并安装 配置Gitee在首页 —&gt;图床设置中找到gitee repo：用户名/仓库名称,也就是仓库的URL，比如我自己的仓库zhao_shu_chao/img branch：分支，这里写上master token：这里填入刚刚我们申请的码云的私人令牌，也就是那个token path：路径，我这里写的是blog customPath：提交消息，这一项和下一项customURL都不用填。在提交到码云后，会显示提交消息，插件默认提交的是 Upload 图片名 by picGo - 时间 生成的格式 配置到这里基本就可以使用了。剩下的就是一些额外说明 在这里我们可以测试上传一张图片试试效果，上传之后再相册中查看照片路径 这个支持五种返回的链接的格式，前三种都是我们常用的 格式实例： 生成时链接格式选择markdown: 1![](https://zsc-cloud-1305849843.cos.ap-beijing.myqcloud.com/img/20210522184639.jpeg) 生成时链接选择URL： 1https://zsc-cloud-1305849843.cos.ap-beijing.myqcloud.com/img/20210522184639.jpeg 生成时链接选择HTML： 1&lt;img src=&quot;https://zsc-cloud-1305849843.cos.ap-beijing.myqcloud.com/img/20210522184639.jpeg&quot;/&gt; 时间戳自动命名在PicGo设置中打开时间戳命名即可 配置完毕集成Typora到这里我们配置完毕了。很多人都使用Tppora在本地写博客文章，下面就演示一下Typora集成刚刚我们配置的床图，实现截图放在Typora或者上传本地图片自动上传到我们的床图 Typora下载地址：https://typora.io/ 进入Typora的偏好设置，选择图像。 在这里页面我们需要配置的是 插入图片时选择：上传图片 对本地和网络图片进行勾选，这里千万不要对第五个勾选，也就是转义URL，会导致图片乱码不可读。 上传服务选择PicGo(app),选项里面还有一个pic(core)，不要选错了。 配置好picGo的安装路径即可 到这里就完毕配置完毕，我们可以测试一下。我们随便截图一张图片，直接复制到笔记中，我们可以看到这个图片的地址变成了我们配置的图床网络地址了。这就说明Typora配置已经生效，自动帮助我们上传到了Gitee啦。 我们回到gitee仓库中，就可以看到我们的提交记录：","categories":[{"name":"工具","slug":"工具","permalink":"https://zsc-cloud.github.io/categories/%E5%B7%A5%E5%85%B7/"},{"name":"图床","slug":"工具/图床","permalink":"https://zsc-cloud.github.io/categories/%E5%B7%A5%E5%85%B7/%E5%9B%BE%E5%BA%8A/"}],"tags":[{"name":"工具","slug":"工具","permalink":"https://zsc-cloud.github.io/tags/%E5%B7%A5%E5%85%B7/"}]},{"title":"Hexo使用Volantis主题","slug":"Hexo使用Volantis主题","date":"2021-03-04T03:06:14.000Z","updated":"2022-03-26T03:42:17.423Z","comments":true,"path":"2021/03/03/Hexo使用Volantis主题/","link":"","permalink":"https://zsc-cloud.github.io/2021/03/03/Hexo%E4%BD%BF%E7%94%A8Volantis%E4%B8%BB%E9%A2%98/","excerpt":"","text":"更换主题这里采用的是Volantis5主题和 Hexo 5.0.2，不用复制什么主题到theme文件夹下，直接使用npm安装即可 在 blog/_config.yml 文件中找到并修改： 1theme: volantis 下载主题 123456# 安装npm i hexo-theme-volantis# 安装 Hexo 搜索的依赖包npm i hexo-generator-search hexo-generator-json-content# 安装 Stylus 渲染器：npm i hexo-renderer-stylus 执行到这里主题就更换成功了。重新部署一下即可 主题配置 新版的配置文件不在theme目录中，而是在根目录的node_modules\\hexo-theme-volantis文件夹下的_config.yml文件中 把这个文件复制到自己的根目录下，重命名为 _config.volantis.yml 即可，这个文件中的配置信息优先级高于主题文件夹中的配置文件。以后再这里配置即可 具体每一项配置参考官方文档，很详细:官方配置文档 创建页面发布文章之前，我们要把分类以及标签页面创建出来，默认是不创建的,创建好之后会生成一个新的在source目录下生成新的对应的文件夹，里面是一个md文档 创建分类：hexo new page &quot;categories&quot; 修改文件夹中的md内容为 123layout: categoryindex: truetitle: 所有分类 创建标签：hexo new page &quot;tags&quot; 123layout: tagindex: truetitle: 所有标签 创建关于我：hexo new page &quot;about&quot; 123456layout: docsseo_title: 关于bottom_meta: falsesidebar: []valine: placeholder: 有什么想对我说的呢？ 创建友链：hexo new page &quot;friends&quot; 发布文章直接在在根目录中执行 1hexo new &#x27;xxxxx&#x27; 要删除文章直接在目录中找到对应的md文档删除即可，但是里面最少要有一个，如果删除的是最后一个，会出现异常 1234#本地运行hexo clean &amp;&amp; hexo g &amp;&amp; hexo s# 部署到git或者自己的域名hexo clean &amp;&amp; hexo g &amp;&amp; hexo d","categories":[{"name":"Hexo","slug":"Hexo","permalink":"https://zsc-cloud.github.io/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://zsc-cloud.github.io/tags/Hexo/"}]},{"title":"使用Hexo搭建个人博客，绑定GitHub以及个人域名","slug":"使用Hexo搭建个人博客，绑定GitHub以及个人域名","date":"2021-03-01T12:47:20.000Z","updated":"2022-03-26T03:42:17.346Z","comments":true,"path":"2021/03/01/使用Hexo搭建个人博客，绑定GitHub以及个人域名/","link":"","permalink":"https://zsc-cloud.github.io/2021/03/01/%E4%BD%BF%E7%94%A8Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%EF%BC%8C%E7%BB%91%E5%AE%9AGitHub%E4%BB%A5%E5%8F%8A%E4%B8%AA%E4%BA%BA%E5%9F%9F%E5%90%8D/","excerpt":"","text":"前言 关于Hexo博客搭建由于网上的教程很多都是旧版本，有时候跟新版不一致装错还得删除再来一遍很让人很难受 文章会基于win10系统开始搭建一个属于自己的博客。从本地启动，到部署到github,然后在到自己的域名 本次搭建使用到的软件以及工具：Git，node.js，GitHub，Hexo 安装Git点击Git官网下载对应的版本 上图红框内的选项是默认勾选的，建议不要动。绿色框1是决定是否在桌面创建快捷方式的。绿色框2是决定在所有控制台窗口中使用TrueType字体和是否每天检查Git是否有Windows更新的。这些根据自己需要选择。 接下来一路next就可以了 安装完成之后我们在cmd控制台运行git，显示一大坨东西就OK了 安装Nodejs 下载地址：node.js下载地址 (Node.js 版本需不低于 10.13，建议使用 Node.js 12.0 及以上版本) node.js安装很简单，在这里就不演示，基本直接下一步就OK，node.js会自动配置环境变量 安装好在cmd中输入：node -v和npm -v出现版本号就说明安装成功了。安装之后最好是重启一下。 node.js安装教程 安装Hexo 官方文档：hexo 创建一个根目录前面git和nodejs安装好后，就可以安装hexo博客框架了。 首先创建一个文件夹,我的名字是Blog，这个文件夹在后续就是用来存放你所创建博客的所有文件。这个文件也称根目录。因为我已经安装过了，所以里面是有内容的 安装Hexo 12// 在git base执行npm install -g hexo-cli 等待安装完毕即可 验证安装是否成功12hexo -v#输入显示版本号即可 初始化网址1npm install 这一步稍微需要等待一下 出现 Start blogging with Hexo 代表初始化成功 安装网址依赖1npm install 然后Blog根目录就会出现一些文件夹，如安装Hexo展示都图片所示 因为我配置过主题，所以目录多了一些文件 node_modules: 依赖包public：存放生成的页面source：用来存放你的文章themes：主题_config.yml: 博客的配置文件 开启本地服务12hexo g//生成静态网址hexo s//开启本地服务器 运行结果提示running就OK了 在浏览器输入网址http://localhost:4000就可以查看你的本地博客网页了 托管到Git 让我们的博客想让别人访问到在本地运行肯定是不行的 这里我们先选择托管到github上，github提供一个git pages功能，代码提交上去会给我们自动生成一个网络地址，供我们使用 git pages功能码云也有，但是很不巧的是，这段时间码云的gitpages在维护，并且长达3个月 首先登陆到我们github，点击 New repository 这里要注意的是仓库名称一定要是自己的用户名+ .github.io别的名字是无效的！！！ 仓库选择public即可 这里我已经有这个仓库了，所以提醒我exists on this account 配置git的SSH如果不配置ssh key 每次部署都需要输入github 账号密码，太麻烦 回到根目录下的git bash窗口中，执行 12git config --global user.name &quot;yourname&quot;//yourname填写你的github用户名git config --global user.email &quot;youremail&quot;//youremail填写你的github的邮箱 查询刚刚执行的结果 12git config user.namegit config user.email 最关键的一步，生成秘钥 1ssh-keygen -t rsa -C &quot;youremail&quot; //youremail填写你的github的邮箱 执行了这个命令会提示存储路径和密码以及确认密码，你连续按三次Enter就好 照着上面的存储路径打开id_rsa.pub，将里面所有的内容全部复制出来。 id_rsa是你这台电脑的私人秘钥，不能给别人看的，id_rsa.pub是公共秘钥，可以随便给别人看。把这个公钥放在GitHub上，这样当你链接GitHub自己的账户时，它就会根据公钥匹配你的私钥，当能够相互匹配时，才能够顺利的通过git上传你的文件到GitHub上。 在github上配置秘钥github点击头像，setting -&gt; SSH and GPG keys，新建SSH key。 这里的title随便填写。key填写我们刚刚复制的id_rsa.pub内容。点击 add ssh key就OK了 测试我们的秘钥配置 1ssh -T git@github.com 按照提示输入yes,看到successfully我们就知道配置成功了 托管到GitHub配置仓库地址这一步是将hexo和Github关联起来，在你的博客根目录下找到 _config.yml,最下面的deploy中配置你的repo 这里一个大坑，很多文章都写的分支branch为master，这里GitHub很早就更新默认分支为main了。这里写了master还有在github上面配置默认分支，所以这里直接填写main接口 还有一个需要注意：hexo以及主题的配置的yml格式的。不熟悉yml配置的时候注意缩进和：后面跟个空格 这里配置repo我们选择ssh链接即可，不要复制错了 hexo安装部署的命令12# 需要先安装deploy-git ，也就是部署的命令,这样你才能用命令部署到GitHubnpm install hexo-deployer-git --save 123456#部署命令 注意g和d都是缩写，hexo cleanhexo ghexo d# 也可以用一个命令拼接起来hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 验证打开浏览器，输入xxxx.github.io，这里将请按照 你的github用户名.github.io 输入，就可以访问你的博客 部署到自己的域名 我们部署到github上就可以访问了，部署到自己的域名是可以选择的。但是总感觉每次访问的时候是自己的域名有一种高级感，哈哈哈。当然部署起来也很简单，其实也不算真正的部署，也是一个GitHub提供的映射服务 购买域名域名购买我是在阿里云上购买的。教程就不展示了，直接登陆阿里云搜索域名即可购买（购买的时候要实名认证，很快提交之后基本一个小时就认证成功） Github绑定域名进入阿里云控制台找到域名管理，进入解析 进入页面点击添加记录即可；要添加两个记录值，记录类型分别为A和CNAME，填写如下。 第一个 记录类型为A 主机记录为：@ 记录值为自己git.io那个ip地址。IP地址在cmd中ping一下即可; 一般都是这个:185.199.110.153 第二个 记录类型为CNAME 主机记录为www 记录值为自己的github访问地址。我这里填写 zsc-cloud.github.io 到这里阿里云上的配置就结束了 Hexo配置域名在自己博客的跟目录source文件夹下创建一个名字CNAME记事本 内容输入自己的个人域名，保存关闭。删除后缀.txt 仓库绑定域名在GitHub中找到自己的博客仓库，点击setting，拉到最下面找到GitHub Pages点进去 在Custom domain输入自己的域名save一下即可，效果如下就说明配置成功了 Https如果GitHub上可以开启Https直接开启即可，如果不能的话可以在阿里云申请一个免费的SSL证书 在这里就不展开说明了，按照提示操作即可。 大功告成绑定自己的域名耐心等待几分钟访问自己的域名即可！ 下一篇我们讲解主题更换以及发布文章！","categories":[{"name":"Hexo","slug":"Hexo","permalink":"https://zsc-cloud.github.io/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://zsc-cloud.github.io/tags/Hexo/"}]}],"categories":[{"name":"Git","slug":"Git","permalink":"https://zsc-cloud.github.io/categories/Git/"},{"name":"鸡汤语录","slug":"鸡汤语录","permalink":"https://zsc-cloud.github.io/categories/%E9%B8%A1%E6%B1%A4%E8%AF%AD%E5%BD%95/"},{"name":"MySQL","slug":"MySQL","permalink":"https://zsc-cloud.github.io/categories/MySQL/"},{"name":"MyCat","slug":"MySQL/MyCat","permalink":"https://zsc-cloud.github.io/categories/MySQL/MyCat/"},{"name":"计算机网络","slug":"计算机网络","permalink":"https://zsc-cloud.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"SQL语句","slug":"MySQL/SQL语句","permalink":"https://zsc-cloud.github.io/categories/MySQL/SQL%E8%AF%AD%E5%8F%A5/"},{"name":"问题随笔","slug":"问题随笔","permalink":"https://zsc-cloud.github.io/categories/%E9%97%AE%E9%A2%98%E9%9A%8F%E7%AC%94/"},{"name":"Java","slug":"Java","permalink":"https://zsc-cloud.github.io/categories/Java/"},{"name":"Redis","slug":"Java/Redis","permalink":"https://zsc-cloud.github.io/categories/Java/Redis/"},{"name":"索引","slug":"MySQL/索引","permalink":"https://zsc-cloud.github.io/categories/MySQL/%E7%B4%A2%E5%BC%95/"},{"name":"事务","slug":"MySQL/事务","permalink":"https://zsc-cloud.github.io/categories/MySQL/%E4%BA%8B%E5%8A%A1/"},{"name":"JUC","slug":"Java/JUC","permalink":"https://zsc-cloud.github.io/categories/Java/JUC/"},{"name":"JVM","slug":"Java/JVM","permalink":"https://zsc-cloud.github.io/categories/Java/JVM/"},{"name":"SQL优化","slug":"MySQL/SQL优化","permalink":"https://zsc-cloud.github.io/categories/MySQL/SQL%E4%BC%98%E5%8C%96/"},{"name":"用户管理","slug":"MySQL/用户管理","permalink":"https://zsc-cloud.github.io/categories/MySQL/%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86/"},{"name":"Java基础","slug":"Java/Java基础","permalink":"https://zsc-cloud.github.io/categories/Java/Java%E5%9F%BA%E7%A1%80/"},{"name":"工具","slug":"工具","permalink":"https://zsc-cloud.github.io/categories/%E5%B7%A5%E5%85%B7/"},{"name":"图床","slug":"工具/图床","permalink":"https://zsc-cloud.github.io/categories/%E5%B7%A5%E5%85%B7/%E5%9B%BE%E5%BA%8A/"},{"name":"Hexo","slug":"Hexo","permalink":"https://zsc-cloud.github.io/categories/Hexo/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://zsc-cloud.github.io/tags/Git/"},{"name":"MyCat","slug":"MyCat","permalink":"https://zsc-cloud.github.io/tags/MyCat/"},{"name":"分库分表","slug":"分库分表","permalink":"https://zsc-cloud.github.io/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"},{"name":"计算机网络","slug":"计算机网络","permalink":"https://zsc-cloud.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"MySQL","slug":"MySQL","permalink":"https://zsc-cloud.github.io/tags/MySQL/"},{"name":"数据库","slug":"数据库","permalink":"https://zsc-cloud.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Linux","slug":"Linux","permalink":"https://zsc-cloud.github.io/tags/Linux/"},{"name":"Redis","slug":"Redis","permalink":"https://zsc-cloud.github.io/tags/Redis/"},{"name":"索引","slug":"索引","permalink":"https://zsc-cloud.github.io/tags/%E7%B4%A2%E5%BC%95/"},{"name":"微信小程序","slug":"微信小程序","permalink":"https://zsc-cloud.github.io/tags/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F/"},{"name":"JUC","slug":"JUC","permalink":"https://zsc-cloud.github.io/tags/JUC/"},{"name":"并发编程","slug":"并发编程","permalink":"https://zsc-cloud.github.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"锁","slug":"锁","permalink":"https://zsc-cloud.github.io/tags/%E9%94%81/"},{"name":"JVM","slug":"JVM","permalink":"https://zsc-cloud.github.io/tags/JVM/"},{"name":"GC","slug":"GC","permalink":"https://zsc-cloud.github.io/tags/GC/"},{"name":"线程","slug":"线程","permalink":"https://zsc-cloud.github.io/tags/%E7%BA%BF%E7%A8%8B/"},{"name":"Java","slug":"Java","permalink":"https://zsc-cloud.github.io/tags/Java/"},{"name":"问题随笔","slug":"问题随笔","permalink":"https://zsc-cloud.github.io/tags/%E9%97%AE%E9%A2%98%E9%9A%8F%E7%AC%94/"},{"name":"JavaSE","slug":"JavaSE","permalink":"https://zsc-cloud.github.io/tags/JavaSE/"},{"name":"集合","slug":"集合","permalink":"https://zsc-cloud.github.io/tags/%E9%9B%86%E5%90%88/"},{"name":"工具","slug":"工具","permalink":"https://zsc-cloud.github.io/tags/%E5%B7%A5%E5%85%B7/"},{"name":"Hexo","slug":"Hexo","permalink":"https://zsc-cloud.github.io/tags/Hexo/"}]}